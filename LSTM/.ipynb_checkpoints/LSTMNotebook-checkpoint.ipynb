{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "\n",
    "This notebook is used to develop an LSTM model for predicting Dow Jones stocks.  \n",
    "\n",
    "We will begin with the Walmart stock data as a beginning test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "First, we load important packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some useful packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Now, we can load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Walmart Stock Data\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get rid of columns we do not need and set the index as the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnessecary columns\n",
    "df.drop(['volume', 'unadjustedVolume', 'change', 'changePercent', 'vwap', 'label', 'changeOverTime'], 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index\n",
    "df.set_index('date', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot close price\n",
    "df.plot(y='close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Split Data\n",
    "\n",
    "We need to create a train/test split.  To do so, we will assume we feed sequences of some length and predict at some point in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data as a matrix\n",
    "data = df.values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sequence length and time in the future\n",
    "#we will start with 30 days and 5 days in the future (about 1 month and 1 week)\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get X data (30 day sequences)\n",
    "X = []\n",
    "#get all sequences up to (sequence length + future point) days out of last point (can then predict last point)\n",
    "for index in range(len(data) - seq_length - fut_point):\n",
    "    X.append(data[index: index + seq_length])\n",
    "#get X as a numpy array\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Y data (close price for all days except first (sequence length + future point) days)\n",
    "y = data[(seq_length + fut_point):, -1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split of 0.85/0.15\n",
    "train_split = 0.85\n",
    "last_row = int(train_split * X.shape[0])\n",
    "X_train = X[:last_row]\n",
    "X_test = X[last_row:]\n",
    "y_train = y[:last_row]\n",
    "y_test = y[last_row:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data\n",
    "We scale the data using the MinMaxScaler fit for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scalers\n",
    "X_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range = (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data so it can be fit\n",
    "X_train_reshaped = np.reshape(X_train, (-1, 4))\n",
    "X_test_reshaped = np.reshape(X_test, (-1, 4))\n",
    "y_train_reshaped = np.reshape(y_train, (-1, 1))\n",
    "y_test_reshaped = np.reshape(y_test, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit scalers\n",
    "X_scaler.fit(X_train_reshaped)\n",
    "y_scaler.fit(y_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform and rescale\n",
    "X_train_scaled = np.reshape(X_scaler.transform(X_train_reshaped), X_train.shape)\n",
    "X_test_scaled = np.reshape(X_scaler.transform(X_test_reshaped), X_test.shape)\n",
    "y_train_scaled = np.reshape(y_scaler.transform(y_train_reshaped), y_train.shape[0])\n",
    "y_test_scaled = np.reshape(y_scaler.transform(y_test_reshaped), y_test.shape[0])\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model\n",
    "Now, we build a basic LSTM network model.\n",
    "\n",
    "We build several LSTM layers together, adding Dropout layers and a few dense layers to summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import layers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "#add first LSTM layer and dropout layer\n",
    "model.add(LSTM(256, return_sequences = True, input_shape = (seq_length, features)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#add second LSTM layer and dropout layer\n",
    "model.add(LSTM(256, return_sequences = False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#add an reLU layer\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "#add a final layer\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model\n",
    "model.fit(X_train_scaled, y_train_scaled, epochs = 100, batch_size = 64, validation_split = 0.15, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Make Predictions\n",
    "\n",
    "We load the model from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('first_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the scores and root mean square errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score models\n",
    "import math\n",
    "train_score = model.evaluate(X_train_scaled, y_train_scaled, verbose = 0)\n",
    "test_score = model.evaluate(X_test_scaled, y_test_scaled, verbose = 0)\n",
    "train_rmse = math.sqrt(train_score[0])\n",
    "test_rmse = math.sqrt(test_score[0])\n",
    "print(f\"Training Set- Score: {train_score[0]}, RMSE: {train_rmse}\")\n",
    "print(f\"Test Set- Score: {test_score[0]}, RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model on training set and test set\n",
    "y_train_preds_scaled = model.predict(X_train_scaled)\n",
    "y_test_preds_scaled = model.predict(X_test_scaled)\n",
    "y_train_preds_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results\n",
    "We now wish to visualize our results.\n",
    "\n",
    "First, we need to denormalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale results\n",
    "y_train_preds_denormed = y_scaler.inverse_transform(y_train_preds_scaled)\n",
    "y_test_preds_denormed = y_scaler.inverse_transform(y_test_preds_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can reshape to the same shape as the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape results for plotting\n",
    "y_train_preds = np.reshape(y_train_preds_denormed, y_train.shape[0])\n",
    "y_test_preds = np.reshape(y_test_preds_denormed, y_test.shape[0])\n",
    "y_train_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create x arrays (just day indices)\n",
    "days1 = np.arange(len(y_train))\n",
    "days2 = np.arange(len(y_train), len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(days1, y_train, 'b', label = 'Training Set Actual')\n",
    "ax.plot(days1, y_train_preds, 'r', label = 'Training Set Predictions')\n",
    "ax.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "ax.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "ax.legend()\n",
    "ax.set_title('Walmart Stock Predictions')\n",
    "ax.set_xlabel('Day Index')\n",
    "ax.set_ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot only the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot test set only\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "ax2.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "ax2.legend()\n",
    "ax2.set_title('Walmart Test Set Predictions')\n",
    "ax2.set_xlabel('Day Index')\n",
    "ax2.set_ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Arbitrary Size, Number of Neurons, and Future Time Point\n",
    "We wish to create functions that allow for some more arbitrary settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create training and test data from a dataframe\n",
    "def train_test_splitter(df, seq_length, fut_point, train_split):\n",
    "    #save data as a matrix\n",
    "    data = df.values\n",
    "    \n",
    "    #save number of features\n",
    "    features = data.shape[1]\n",
    "    \n",
    "    #get X data (30 day sequences)\n",
    "    X = []\n",
    "    #get all sequences up to (sequence length + future point) days out of last point (can then predict last point)\n",
    "    for index in range(len(data) - seq_length - fut_point):\n",
    "        X.append(data[index: index + seq_length])\n",
    "    #get X as a numpy array\n",
    "    X = np.array(X)\n",
    "    \n",
    "    #get Y data (close price for all days except first (sequence length + future point) days)\n",
    "    y = data[(seq_length + fut_point):, -1]\n",
    "    \n",
    "    #create train/test splits using chosing training split (between 0 and 1)\n",
    "    last_row = int(train_split * X.shape[0])\n",
    "    X_train = X[:last_row]\n",
    "    X_test = X[last_row:]\n",
    "    y_train = y[:last_row]\n",
    "    y_test = y[last_row:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function with 180 days sequence and 80 days future point\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_splitter(df, 180, 80, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create scaled data and scalers\n",
    "def create_scalers_and_normalize(X_train, X_test, y_train, y_test):\n",
    "    #instantiate scalers\n",
    "    X_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #reshape data so it can be fit\n",
    "    X_train_reshaped = np.reshape(X_train, (-1, features))\n",
    "    X_test_reshaped = np.reshape(X_test, (-1, features))\n",
    "    y_train_reshaped = np.reshape(y_train, (-1, 1))\n",
    "    y_test_reshaped = np.reshape(y_test, (-1, 1))\n",
    "    \n",
    "    #fit scalers\n",
    "    X_scaler.fit(X_train_reshaped)\n",
    "    y_scaler.fit(y_train_reshaped)\n",
    "    \n",
    "    #transform and rescale\n",
    "    X_train_scaled = np.reshape(X_scaler.transform(X_train_reshaped), X_train.shape)\n",
    "    X_test_scaled = np.reshape(X_scaler.transform(X_test_reshaped), X_test.shape)\n",
    "    y_train_scaled = np.reshape(y_scaler.transform(y_train_reshaped), y_train.shape[0])\n",
    "    y_test_scaled = np.reshape(y_scaler.transform(y_test_reshaped), y_test.shape[0])\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled2, X_test_scaled2, y_train_scaled2, y_test_scaled2, X_scaler2, y_scaler2 = create_scalers_and_normalize(\n",
    "    X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an LSTM model with different neuron sizes\n",
    "def create_generic_LSTM_model(neurons, dropout, seq_length, features):\n",
    "    #create an LSTM model\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first LSTM layer and dropout layer\n",
    "    model.add(LSTM(neurons[0], return_sequences = True, input_shape = (seq_length, features)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #add second LSTM layer and dropout layer\n",
    "    model.add(LSTM(neurons[1], return_sequences = False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #add an reLU layer\n",
    "    model.add(Dense(neurons[2], activation = 'relu'))\n",
    "\n",
    "    #add a final layer\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    #compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "new_model = create_generic_LSTM_model([256, 256, 32], 0.2, 180, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "new_model.save('second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "new_model = load_model('second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate score and return predictions for a given model path\n",
    "import math\n",
    "def make_preds(model_path, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, y_scaler):\n",
    "    #load model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    #score models\n",
    "    train_score = model.evaluate(X_train_scaled, y_train_scaled, verbose = 0)\n",
    "    test_score = model.evaluate(X_test_scaled, y_test_scaled, verbose = 0)\n",
    "    train_rmse = math.sqrt(train_score[0])\n",
    "    test_rmse = math.sqrt(test_score[0])\n",
    "    print(f\"Training Set- Score: {train_score[0]}, RMSE: {train_rmse}\")\n",
    "    print(f\"Test Set- Score: {test_score[0]}, RMSE: {test_rmse}\")\n",
    "    \n",
    "    #evaluate model on training set and test set\n",
    "    y_train_preds_scaled = model.predict(X_train_scaled)\n",
    "    y_test_preds_scaled = model.predict(X_test_scaled)\n",
    "    \n",
    "    #rescale results\n",
    "    y_train_preds_denormed = y_scaler.inverse_transform(y_train_preds_scaled)\n",
    "    y_test_preds_denormed = y_scaler.inverse_transform(y_test_preds_scaled)\n",
    "    \n",
    "    #reshape results for plotting\n",
    "    y_train_preds = np.reshape(y_train_preds_denormed, len(y_train_scaled))\n",
    "    y_test_preds = np.reshape(y_test_preds_denormed, len(y_test_scaled))\n",
    "    \n",
    "    return y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "y_train_preds, y_test_preds, train_score, test_score =  make_preds('first_model.h5', X_train_scaled, \n",
    "                                                                   X_test_scaled, y_train_scaled, y_test_scaled, \n",
    "                                                                   y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create, compile, fit a model, and make predictions\n",
    "def fit_generic_LSTM_model(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, \n",
    "                           validation_split, model_path):\n",
    "    \n",
    "    #get train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_splitter(df, seq_length, fut_point, train_split)\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #get scalers and normalized data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler = create_scalers_and_normalize(\n",
    "        X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #create model\n",
    "    model = create_generic_LSTM_model(neurons, dropout, seq_length, features)\n",
    "    \n",
    "    #fit model\n",
    "    model.fit(X_train_scaled, y_train_scaled, epochs = epochs, \n",
    "              batch_size = batch_size, validation_split = validation_split, verbose = 1)\n",
    "    \n",
    "    #save model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    #evaluate model and get predictions\n",
    "    y_train_preds, y_test_preds, train_score, test_score = make_preds(model_path, \n",
    "                                                                      X_train_scaled, X_test_scaled, \n",
    "                                                                      y_train_scaled, y_test_scaled, y_scaler)\n",
    "    \n",
    "    #return necessary variables to create predictions\n",
    "    return y_train, y_test, y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "seq_length = 180\n",
    "fut_point = 80\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'third_model.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot results\n",
    "def make_results_plot(y_train, y_test, y_train_preds, y_test_preds):\n",
    "    #create x arrays (just day indices)\n",
    "    days1 = np.arange(len(y_train))\n",
    "    days2 = np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "    \n",
    "    #plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(days1, y_train, 'b', label = 'Training Set Actual')\n",
    "    ax.plot(days1, y_train_preds, 'r', label = 'Training Set Predictions')\n",
    "    ax.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "    ax.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "    ax.legend()\n",
    "    ax.set_title('Walmart Stock Predictions')\n",
    "    ax.set_xlabel('Day Index')\n",
    "    ax.set_ylabel('Closing Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "y_train_preds3, y_test_preds3, train_score3, test_score3 = make_preds('third_model.h5', \n",
    "                                                                                         X_train_scaled2, \n",
    "                                                                                         X_test_scaled2, \n",
    "                                                                                         y_train_scaled2, \n",
    "                                                                                         y_test_scaled2, y_scaler2)\n",
    "make_results_plot(y_train2, y_test2, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Interval Testing\n",
    "\n",
    "One day future point, 20 days past information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "seq_length = 20\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'first_one_day_model.h5'\n",
    "y_train5, y_test5, y_train_preds5, y_test_preds5, train_score5, test_score5 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train5, y_test5, y_train_preds5, y_test_preds5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try even lengths:  20 days and 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "seq_length = 20\n",
    "fut_point = 20\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'four_week_model.h5'\n",
    "y_train6, y_test6, y_train_preds6, y_test_preds6, train_score6, test_score6 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train6, y_test6, y_train_preds6, y_test_preds6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict one day ahead with last week's data\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'one_day_model.h5'\n",
    "y_train4, y_test4, y_train_preds4, y_test_preds4, train_score4, test_score4 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train4, y_test4, y_train_preds4, y_test_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different numbers of features\n",
    "\n",
    "We will read in the dataframe again and consider another couple features (volume traded and vwap).\n",
    "\n",
    "We test compared to the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Walmart Stock Data\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "new_df = pd.read_csv(filepath)\n",
    "\n",
    "#drop unnessecary columns\n",
    "new_df.drop(['unadjustedVolume', 'change', 'changePercent', 'label', 'changeOverTime'], 1, inplace = True)\n",
    "\n",
    "#set index\n",
    "new_df.set_index('date', inplace = True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first run the functions for 30 days sequence and 5 days of future point for the old number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for old number of features\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for new number of features\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features_real_long.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(new_df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with 5 days sequence 1 day future point\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features_real.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(new_df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Now, we attempt to tune hyperparameters of the model.\n",
    "\n",
    "First, we will look at number of neurons.  For all of these first trials, we will use a sequence length of thirty \n",
    "and a future point of five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at number of neurons\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "#neurons = [256, 256, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "neuron_lengths = [[256, 256, 32], [256, 256, 16], [128, 128, 32], [128, 128, 16], [64, 64, 32], [64, 64, 16]]\n",
    "\n",
    "#create lists to store results\n",
    "neurons = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for neuron_length in neuron_lengths:\n",
    "    neurons.append(f\"{neuron_length}\")\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neuron_length, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Neuron Lengths': neurons, 'Train Scores': train_scores})\n",
    "\n",
    "results.plot.bar(x = 'Neuron Lengths', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model for 128, 128, 16 and visualize\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'low_neurons.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there is a bit of randomness in the training scores (likely due to different starting weights and which variables are dropped in dropout layers during fitting).  They seem to score about the same.  As a simpler network seems to work, we will use it (128, 128, 16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Epochs\n",
    "\n",
    "We will look at how the number of epochs affects our error.  The inbuilt fit function in keras has a way of doing this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_history(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, \n",
    "                           validation_split, model_path):\n",
    "    \n",
    "    #get train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_splitter(df, seq_length, fut_point, train_split)\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #get scalers and normalized data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler = create_scalers_and_normalize(\n",
    "        X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #create model\n",
    "    model = create_generic_LSTM_model(neurons, dropout, seq_length, features)\n",
    "    \n",
    "    #fit model\n",
    "    history = model.fit(X_train_scaled, y_train_scaled, epochs = epochs, \n",
    "              batch_size = batch_size, validation_split = validation_split, verbose = 1)\n",
    "    \n",
    "    #save model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do so\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'epoch_test.h5'\n",
    "history = see_history(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, validation_split,\n",
    "                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss history by epoch\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the loss history by reading it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read into dataframe\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at columns\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.plot(y = ['val_loss', 'loss'], title = 'Loss History by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss in general seems to decrease a great deal, but the validation loss is very noisy after about 100 epochs.  We will use 100 epochs going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Amount\n",
    "\n",
    "Now, we consider dropout amount (percentage of weights dropped in each iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at dropout\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "dropout_list = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "#create lists to store results\n",
    "dropouts = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for dropout in dropout_list:\n",
    "    dropouts.append(dropout)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neuron_length, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Dropouts': dropouts, 'Train Scores': train_scores})\n",
    "\n",
    "results.plot(x = 'Dropouts', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results\n",
    "results.plot(x = 'Dropouts', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dropout value of 0.30 is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Split\n",
    "\n",
    "We try several different train/test split sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at train/test split\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "dropout = 0.3\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "split_list = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "#create lists to store results\n",
    "train_splits = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for train_split in split_list:\n",
    "    train_splits.append(train_split)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Train_Test_Splits': train_splits, 'Train Scores': train_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results\n",
    "results.plot.bar(x = 'Train_Test_Splits', y = 'Train Scores', color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the way train/test split works with this time series data, we will actually take a look at a graph for this one after training a model.  It may be that training/test performance is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model with 0.75 train/test split\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.75\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.3\n",
    "model_path = 'three_quarters_split.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a 0.75 train/test split actually does not do well as the scale is wrong for the test set.  We will still use a split of 0.85 going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try several different validation set splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at validation split\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "dropout = 0.3\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "train_split = 0.85\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "split_list = [0.1, 0.15, 0.2, 0.25]\n",
    "\n",
    "#create lists to store results\n",
    "validation_splits = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for validation_split in split_list:\n",
    "    validation_splits.append(validation_split)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Validation Split': train_splits, 'Train Scores': train_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Validation Split': validation_splits, 'Train Scores': train_scores})\n",
    "results.plot.bar(x = 'Validation Split', y = 'Train Scores', color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a validation split of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Size\n",
    "Finally, we will try a few different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at batch size\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "dropout = 0.3\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "validation_split = 0.1\n",
    "train_split = 0.85\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "sizes = [16, 32, 64]\n",
    "\n",
    "#create lists to store results\n",
    "batch_sizes = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for batch_size in sizes:\n",
    "    batch_sizes.append(batch_size)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Batch Size': train_splits, 'Train Scores': train_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Batch Size': batch_sizes, 'Train Scores': train_scores})\n",
    "results.plot(x = 'Batch Size', y = 'Train Scores', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a batch size of 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-visiting Time Windows\n",
    "\n",
    "With selected hyperparameters, we can now look at and graph results for different sequence lengths and future points.\n",
    "\n",
    "We begin with our standard 30 day sequence length and a 5 day future point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model with\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to do well enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try 5 days sequence 1 day ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model with 5 days sequence, 1 day future point\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model_short.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also now has the range in a good place.\n",
    "\n",
    "We now use 30 days to predict 30 days out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model with 30 days sequence, 30 day future point\n",
    "seq_length = 30\n",
    "fut_point = 30\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model_months.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That this is not completely bad is nice.\n",
    "\n",
    "Now, for a very long conmparison, 180 days sequence for 80 days in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model with 180 days sequence, 80 day future point\n",
    "seq_length = 180\n",
    "fut_point = 80\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model_long.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Stock\n",
    "\n",
    "There are actually 30 Dow Jones Stocks.  We need a function to produce a model for a generic filepath.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to produce predictions for a generic filepath\n",
    "def generic_stock_predictions(filepath, stock_name, seq_length, fut_point):\n",
    "    \n",
    "    #define variables\n",
    "    train_split = 0.85\n",
    "    neurons = [128, 128, 16]\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    validation_split = 0.1\n",
    "    dropout = 0.3\n",
    "    \n",
    "    #define model path\n",
    "    model_path = stock_name + '_model.h5'\n",
    "    \n",
    "    #read in data frame and drop unnescessary columns\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.drop(['volume', 'unadjustedVolume', 'change', 'changePercent', 'vwap', 'label', \n",
    "             'changeOverTime'], 1, inplace = True)\n",
    "    df.set_index('date', inplace = True)\n",
    "    \n",
    "    #fit model\n",
    "    y_train, y_test, y_train_preds, y_test_preds, train_score, test_score = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    #return\n",
    "    return y_train, y_test, y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "y_train4, y_test4, y_train_preds4, y_test_preds4, train_score4, test_score4 = generic_stock_predictions(filepath,\n",
    "                                                                                                       'WMT',\n",
    "                                                                                                       30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "make_results_plot(y_train4, y_test4, y_train_preds4, y_test_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to have a function that looks at predicted profitability on the last day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted profitability function\n",
    "def predicted_profit(filepath, stock_name, seq_length, fut_point):\n",
    "    \n",
    "    #fit model\n",
    "    y_train, y_test, y_train_preds, y_test_preds, train_score, test_score = generic_stock_predictions(\n",
    "        filepath, stock_name, seq_length, fut_point)\n",
    "    \n",
    "    #get values\n",
    "    start_close = y_test[-1-fut_point]\n",
    "    end_close = y_test[-1]\n",
    "    pred_close = y_test_preds[-1]\n",
    "    actual_profit = (end_close - start_close)*100/start_close\n",
    "    pred_profit = (pred_close - start_close)*100/start_close\n",
    "    \n",
    "    #create dictionary for output\n",
    "    stock_dictionary = {'Stock': stock_name, 'Start Close': start_close, 'End Close': end_close, \n",
    "                       'Predicted Close': pred_close, 'Actual Profit': actual_profit, 'Predicted Profit': pred_profit}\n",
    "    \n",
    "    return stock_dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "dictionary = predicted_profit(filepath, 'WMT', 30, 5)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation\n",
    "\n",
    "There is variation observed in these results.  As a quick test, let us look at the results of doing this 10 times with the profitability function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do function 10 times appending to list\n",
    "dicts = []\n",
    "for i in range(0, 10):\n",
    "    print(f\"Iteration {i}\")\n",
    "    dictionary = predicted_profit(filepath, 'WMT', 30, 5)\n",
    "    dictionary['Iteration'] = i\n",
    "    dicts.append(dictionary)\n",
    "    \n",
    "#create dataframe and display\n",
    "variation_df = pd.DataFrame(dicts)\n",
    "\n",
    "variation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe predicted close\n",
    "variation_df['Predicted Close'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is variation in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
