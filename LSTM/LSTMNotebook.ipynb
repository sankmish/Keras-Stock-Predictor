{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "\n",
    "### Description\n",
    "\n",
    "Predicting the stock market is inherently difficult.  However, it does present an interesting and challenging approach for machine learning.  As well, compared to other machine learning tasks, the stock market is unique as it is inherently time series data, rather than several independent events.  This leads to a somewhat different typical approach, for example in choice of train set and test set.\n",
    "\n",
    "As this project is at the beginning and exploration phase, we chose to use an easily available data set.  We chose a dataset from Kaggle, which used to be found [here](https://www.kaggle.com/timoboz/stock-data-dow-jones) which was accessed in January 2019 of end-of-day data for all stocks in the Dow Jones industrial average.  As of April 2019, unfortunately, the data does not seem to be accessible, though Kaggle contains other Dow Jones stock data, such as [here](https://www.kaggle.com/jmwithro/dow-jones-index-data-set).  Note that all accessed csv files are accessible in this repository.\n",
    "\n",
    "### Method\n",
    "\n",
    "This notebook is used to develop a Long-Short Term Memory (LSTM) nerual network model for predicting Dow Jones stocks.  LSTM network layers are designed to \"remember\" previous input and are used for tasks such as natural language processing where the relationship of data in sequence is important.  The possible appeal for the stock market, where recent history is probably very important is therefore obvious.\n",
    "\n",
    "We develop the LSTM neural network here using the Keras library, which is built to handle Tensorflow.  For a description of LSTM networks and Keras, see [here](https://adventuresinmachinelearning.com/keras-lstm-tutorial/).\n",
    "\n",
    "As this project actually involves comparison to several other machine learning methods, it was necessary to develop all methods using a similar data source.  Thus, the Wal-Mart data was randomly chosen as a starting point.  So, this notebook primarily involves building and training a model on the Wal-Mart data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "First, we load important packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some useful packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Now, we can load the Wal-Mart stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "      <td>9105139</td>\n",
       "      <td>9105139</td>\n",
       "      <td>-0.235889</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>64.7739</td>\n",
       "      <td>Jan 27, 14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "      <td>6035231</td>\n",
       "      <td>6035231</td>\n",
       "      <td>0.454305</td>\n",
       "      <td>0.701</td>\n",
       "      <td>65.3045</td>\n",
       "      <td>Jan 28, 14</td>\n",
       "      <td>0.007013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>8440854</td>\n",
       "      <td>8440854</td>\n",
       "      <td>-0.497990</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>61.0517</td>\n",
       "      <td>Jan 29, 14</td>\n",
       "      <td>-0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "      <td>6742046</td>\n",
       "      <td>6742046</td>\n",
       "      <td>0.567883</td>\n",
       "      <td>0.877</td>\n",
       "      <td>65.2975</td>\n",
       "      <td>Jan 30, 14</td>\n",
       "      <td>0.008092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "      <td>10665285</td>\n",
       "      <td>10665285</td>\n",
       "      <td>-0.061155</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>65.3223</td>\n",
       "      <td>Jan 31, 14</td>\n",
       "      <td>0.007147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open     high      low    close    volume  unadjustedVolume  \\\n",
       "0  2014-01-27  64.7650  64.9747  64.5029  64.7825   9105139           9105139   \n",
       "1  2014-01-28  64.8786  65.8746  64.7388  65.2368   6035231           6035231   \n",
       "2  2014-01-29  65.7785  65.8484  64.7126  64.7388   8440854           8440854   \n",
       "3  2014-01-30  65.1232  65.6037  64.9660  65.3067   6742046           6742046   \n",
       "4  2014-01-31  64.5816  65.6911  64.3369  65.2455  10665285          10665285   \n",
       "\n",
       "     change  changePercent     vwap       label  changeOverTime  \n",
       "0 -0.235889         -0.363  64.7739  Jan 27, 14        0.000000  \n",
       "1  0.454305          0.701  65.3045  Jan 28, 14        0.007013  \n",
       "2 -0.497990         -0.763  61.0517  Jan 29, 14       -0.000675  \n",
       "3  0.567883          0.877  65.2975  Jan 30, 14        0.008092  \n",
       "4 -0.061155         -0.094  65.3223  Jan 31, 14        0.007147  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Walmart Stock Data\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get rid of columns we do not need and set the index as the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open     high      low    close\n",
       "0  2014-01-27  64.7650  64.9747  64.5029  64.7825\n",
       "1  2014-01-28  64.8786  65.8746  64.7388  65.2368\n",
       "2  2014-01-29  65.7785  65.8484  64.7126  64.7388\n",
       "3  2014-01-30  65.1232  65.6037  64.9660  65.3067\n",
       "4  2014-01-31  64.5816  65.6911  64.3369  65.2455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnessecary columns\n",
    "df.drop(['volume', 'unadjustedVolume', 'change', 'changePercent', 'vwap', 'label', 'changeOverTime'], 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-27</th>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-28</th>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-29</th>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-30</th>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close\n",
       "date                                          \n",
       "2014-01-27  64.7650  64.9747  64.5029  64.7825\n",
       "2014-01-28  64.8786  65.8746  64.7388  65.2368\n",
       "2014-01-29  65.7785  65.8484  64.7126  64.7388\n",
       "2014-01-30  65.1232  65.6037  64.9660  65.3067\n",
       "2014-01-31  64.5816  65.6911  64.3369  65.2455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set index\n",
    "df.set_index('date', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration, let's just take a look at the close price over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107dce668>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot close price\n",
    "df.plot(y='close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Split Data\n",
    "\n",
    "We need to create a train/test split.  In most machine learning problems, we want to randomize the points (the different days in our data set) for proper methodology.  In time series problems, where days depend on past points inherently, we take a different approach.  We take the first percentage (preferably at least 70%) as the training set and use the remaining more recent data as the test set.  \n",
    "\n",
    "For the output, we use the close price of the day.  For the input data, we use a certain window of data to predict a certain point in the future.  For example, we start with a 30 x 4 matrix here (30 days of open/high/low/close prices).  We predict a point one week in the future (5 business days).  As our data set is simply of sequential days the stock exchange is open, we pretend as if holidays and weekends do not exist.\n",
    "\n",
    "So in this example, we would need sets of 35 days for each data point.  Thus the exact data set size will depend on our sequence lengths and future points.\n",
    "\n",
    "We now go with this process to develop a train/test split.  Due to the requirements of Keras, we need to first convert data to a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save data as a matrix\n",
    "data = df.values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sequence length and time in the future\n",
    "#we will start with 30 days and 5 days in the future (about 1 month and 1 week)\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "features = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get the input (X) and output (Y) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224, 30, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get X data (30 day sequences)\n",
    "X = []\n",
    "#get all sequences up to (sequence length + future point) days out of last point (can then predict last point)\n",
    "for index in range(len(data) - seq_length - fut_point):\n",
    "    X.append(data[index: index + seq_length])\n",
    "#get X as a numpy array\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get Y data (close price for all days except first (sequence length + future point) days)\n",
    "y = data[(seq_length + fut_point):, -1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with an 85/15 percent train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040, 30, 4)\n",
      "(184, 30, 4)\n",
      "(1040,)\n",
      "(184,)\n"
     ]
    }
   ],
   "source": [
    "#train/test split of 0.85/0.15\n",
    "train_split = 0.85\n",
    "last_row = int(train_split * X.shape[0])\n",
    "X_train = X[:last_row]\n",
    "X_test = X[last_row:]\n",
    "y_train = y[:last_row]\n",
    "y_test = y[last_row:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data\n",
    "\n",
    "We need to normalize this data for machine learning purposes.  We use Scikit-Learn's MinMaxScaler to get a normalized scale from the training data and then apply it to scale both the training and test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scalers\n",
    "X_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range = (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data so it can be fit\n",
    "X_train_reshaped = np.reshape(X_train, (-1, 4))\n",
    "X_test_reshaped = np.reshape(X_test, (-1, 4))\n",
    "y_train_reshaped = np.reshape(y_train, (-1, 1))\n",
    "y_test_reshaped = np.reshape(y_test, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(-1, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit scalers\n",
    "X_scaler.fit(X_train_reshaped)\n",
    "y_scaler.fit(y_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 30, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform and rescale\n",
    "X_train_scaled = np.reshape(X_scaler.transform(X_train_reshaped), X_train.shape)\n",
    "X_test_scaled = np.reshape(X_scaler.transform(X_test_reshaped), X_test.shape)\n",
    "y_train_scaled = np.reshape(y_scaler.transform(y_train_reshaped), y_train.shape[0])\n",
    "y_test_scaled = np.reshape(y_scaler.transform(y_test_reshaped), y_test.shape[0])\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model\n",
    "\n",
    "Now, we build a basic LSTM network model.  We choose to use two different LSTM layers.  After each, we add a Dropout layer.  A dropout layer randomly ignores a certain amount of weights during each training epoch.  Final weights are then weighted by the amount of time each was used in training.  To end, we add a dense neural network layer and then a final layer with a linear output (because we are predicting one close point for each data point).\n",
    "\n",
    "We begin by importing the required functions and then building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import layers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 30, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create an LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "#add first LSTM layer and dropout layer\n",
    "model.add(LSTM(256, return_sequences = True, input_shape = (seq_length, features)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#add second LSTM layer and dropout layer\n",
    "model.add(LSTM(256, return_sequences = False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#add an reLU layer\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "#add a final layer\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit the model and save it using Keras's save function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0414 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1195 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1158 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1006 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1492 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1585 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1257 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1759 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1639 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1575 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1970 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1993 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2106 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2743 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3165 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3284 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2847 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2807 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2751 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3121 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3393 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3016 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3178 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3454 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2965 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2698 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2687 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2809 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2962 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2996 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2953 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3403 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3739 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3225 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2832 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3172 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2520 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2757 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2118 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2121 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1783 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1917 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2183 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1880 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2428 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2015 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1670 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0753 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0431 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0064\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0064\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0064\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0667 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0939 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1705 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0935 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0704 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1804 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0395 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2283 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1566 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2052 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.3024 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0827 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0442 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1895 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1653 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0832 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1042 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1650 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1021 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1816 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1134 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0473 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0992 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0419 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1026 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1041 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0489 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0729 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1664 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0852 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0485 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0942 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0519 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0450 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0529 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0518 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0441 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1042 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1534 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1656 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1421 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0939 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0746 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2634 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1803 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1030 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1715 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1012 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1021 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2188 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.3478 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1879 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.5154 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.7714 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2814 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.4096 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.5145 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 1.1115 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 1.1323 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 1.1300 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.8911 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 1.0515 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2283 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1000 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0064\n",
      "Epoch 300/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1371 - val_acc: 0.0064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2861e6d8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "model.fit(X_train_scaled, y_train_scaled, epochs = 300, batch_size = 64, validation_split = 0.15, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Make Predictions\n",
    "\n",
    "We load the model from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 30, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('first_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the scores and root mean square errors.  Essentially, the lower the RMSE, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set- Score: 0.02296979169343383, RMSE: 0.15155788232036574\n",
      "Test Set- Score: 0.11483484830545343, RMSE: 0.3388729087806422\n"
     ]
    }
   ],
   "source": [
    "#score models\n",
    "import math\n",
    "train_score = model.evaluate(X_train_scaled, y_train_scaled, verbose = 0)\n",
    "test_score = model.evaluate(X_test_scaled, y_test_scaled, verbose = 0)\n",
    "train_rmse = math.sqrt(train_score[0])\n",
    "test_rmse = math.sqrt(test_score[0])\n",
    "print(f\"Training Set- Score: {train_score[0]}, RMSE: {train_rmse}\")\n",
    "print(f\"Test Set- Score: {test_score[0]}, RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make predictions that we can compare to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model on training set and test set\n",
    "y_train_preds_scaled = model.predict(X_train_scaled)\n",
    "y_test_preds_scaled = model.predict(X_test_scaled)\n",
    "y_train_preds_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results\n",
    "We now wish to visualize our results.\n",
    "\n",
    "First, we need to denormalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale results\n",
    "y_train_preds_denormed = y_scaler.inverse_transform(y_train_preds_scaled)\n",
    "y_test_preds_denormed = y_scaler.inverse_transform(y_test_preds_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can reshape to the same shape as the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape results for plotting\n",
    "y_train_preds = np.reshape(y_train_preds_denormed, y_train.shape[0])\n",
    "y_test_preds = np.reshape(y_test_preds_denormed, y_test.shape[0])\n",
    "y_train_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create x arrays (just day indices)\n",
    "days1 = np.arange(len(y_train))\n",
    "days2 = np.arange(len(y_train), len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(days1, y_train, 'b', label = 'Training Set Actual')\n",
    "ax.plot(days1, y_train_preds, 'r', label = 'Training Set Predictions')\n",
    "ax.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "ax.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "ax.legend()\n",
    "ax.set_title('Walmart Stock Predictions')\n",
    "ax.set_xlabel('Day Index')\n",
    "ax.set_ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot only the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot test set only\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "ax2.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "ax2.legend()\n",
    "ax2.set_title('Walmart Test Set Predictions')\n",
    "ax2.set_xlabel('Day Index')\n",
    "ax2.set_ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we can get the general trend somewhat OK, though the end is very bad and there is a persistent magnitude error.  This is probably due to the fact that the latest stock prices were all higher than the earliest part of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Arbitrary Size, Number of Neurons, and Future Time Point\n",
    "\n",
    "We might wish to train the model on different input lengths and future time points, or to train the hyperparameters of the model.  In this case, it is convenient to have functions that allow easy variation of such variables.\n",
    "\n",
    "We begin with a function for train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create training and test data from a dataframe\n",
    "def train_test_splitter(df, seq_length, fut_point, train_split):\n",
    "    #save data as a matrix\n",
    "    data = df.values\n",
    "    \n",
    "    #save number of features\n",
    "    features = data.shape[1]\n",
    "    \n",
    "    #get X data (30 day sequences)\n",
    "    X = []\n",
    "    #get all sequences up to (sequence length + future point) days out of last point (can then predict last point)\n",
    "    for index in range(len(data) - seq_length - fut_point):\n",
    "        X.append(data[index: index + seq_length])\n",
    "    #get X as a numpy array\n",
    "    X = np.array(X)\n",
    "    \n",
    "    #get Y data (close price for all days except first (sequence length + future point) days)\n",
    "    y = data[(seq_length + fut_point):, -1]\n",
    "    \n",
    "    #create train/test splits using chosing training split (between 0 and 1)\n",
    "    last_row = int(train_split * X.shape[0])\n",
    "    X_train = X[:last_row]\n",
    "    X_test = X[last_row:]\n",
    "    y_train = y[:last_row]\n",
    "    y_test = y[last_row:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function with 180 days sequence and 80 days future point\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_splitter(df, 180, 80, 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a function to handle normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create scaled data and scalers\n",
    "def create_scalers_and_normalize(X_train, X_test, y_train, y_test):\n",
    "    #instantiate scalers\n",
    "    X_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #reshape data so it can be fit\n",
    "    X_train_reshaped = np.reshape(X_train, (-1, features))\n",
    "    X_test_reshaped = np.reshape(X_test, (-1, features))\n",
    "    y_train_reshaped = np.reshape(y_train, (-1, 1))\n",
    "    y_test_reshaped = np.reshape(y_test, (-1, 1))\n",
    "    \n",
    "    #fit scalers\n",
    "    X_scaler.fit(X_train_reshaped)\n",
    "    y_scaler.fit(y_train_reshaped)\n",
    "    \n",
    "    #transform and rescale\n",
    "    X_train_scaled = np.reshape(X_scaler.transform(X_train_reshaped), X_train.shape)\n",
    "    X_test_scaled = np.reshape(X_scaler.transform(X_test_reshaped), X_test.shape)\n",
    "    y_train_scaled = np.reshape(y_scaler.transform(y_train_reshaped), y_train.shape[0])\n",
    "    y_test_scaled = np.reshape(y_scaler.transform(y_test_reshaped), y_test.shape[0])\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled2, X_test_scaled2, y_train_scaled2, y_test_scaled2, X_scaler2, y_scaler2 = create_scalers_and_normalize(\n",
    "    X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create and test a function to create an LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an LSTM model with different neuron sizes\n",
    "def create_generic_LSTM_model(neurons, dropout, seq_length, features):\n",
    "    #create an LSTM model\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first LSTM layer and dropout layer\n",
    "    model.add(LSTM(neurons[0], return_sequences = True, input_shape = (seq_length, features)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #add second LSTM layer and dropout layer\n",
    "    model.add(LSTM(neurons[1], return_sequences = False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #add an reLU layer\n",
    "    model.add(Dense(neurons[2], activation = 'relu'))\n",
    "\n",
    "    #add a final layer\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    #compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "new_model = create_generic_LSTM_model([256, 256, 32], 0.2, 180, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "new_model.save('second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "new_model = load_model('second_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create and test a function that loads a pre-trained model and makes predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate score and return predictions for a given model path\n",
    "import math\n",
    "def make_preds(model_path, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, y_scaler):\n",
    "    #load model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    #score models\n",
    "    train_score = model.evaluate(X_train_scaled, y_train_scaled, verbose = 0)\n",
    "    test_score = model.evaluate(X_test_scaled, y_test_scaled, verbose = 0)\n",
    "    train_rmse = math.sqrt(train_score[0])\n",
    "    test_rmse = math.sqrt(test_score[0])\n",
    "    print(f\"Training Set- Score: {train_score[0]}, RMSE: {train_rmse}\")\n",
    "    print(f\"Test Set- Score: {test_score[0]}, RMSE: {test_rmse}\")\n",
    "    \n",
    "    #evaluate model on training set and test set\n",
    "    y_train_preds_scaled = model.predict(X_train_scaled)\n",
    "    y_test_preds_scaled = model.predict(X_test_scaled)\n",
    "    \n",
    "    #rescale results\n",
    "    y_train_preds_denormed = y_scaler.inverse_transform(y_train_preds_scaled)\n",
    "    y_test_preds_denormed = y_scaler.inverse_transform(y_test_preds_scaled)\n",
    "    \n",
    "    #reshape results for plotting\n",
    "    y_train_preds = np.reshape(y_train_preds_denormed, len(y_train_scaled))\n",
    "    y_test_preds = np.reshape(y_test_preds_denormed, len(y_test_scaled))\n",
    "    \n",
    "    return y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set- Score: 0.02296979169343383, RMSE: 0.15155788232036574\n",
      "Test Set- Score: 0.11483484830545343, RMSE: 0.3388729087806422\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "y_train_preds, y_test_preds, train_score, test_score =  make_preds('first_model.h5', X_train_scaled, \n",
    "                                                                   X_test_scaled, y_train_scaled, y_test_scaled, \n",
    "                                                                   y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a function that handles everything through predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create, compile, fit a model, and make predictions\n",
    "def fit_generic_LSTM_model(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, \n",
    "                           validation_split, model_path):\n",
    "    \n",
    "    #get train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_splitter(df, seq_length, fut_point, train_split)\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #get scalers and normalized data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler = create_scalers_and_normalize(\n",
    "        X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #create model\n",
    "    model = create_generic_LSTM_model(neurons, dropout, seq_length, features)\n",
    "    \n",
    "    #fit model\n",
    "    model.fit(X_train_scaled, y_train_scaled, epochs = epochs, \n",
    "              batch_size = batch_size, validation_split = validation_split, verbose = 1)\n",
    "    \n",
    "    #save model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    #evaluate model and get predictions\n",
    "    y_train_preds, y_test_preds, train_score, test_score = make_preds(model_path, \n",
    "                                                                      X_train_scaled, X_test_scaled, \n",
    "                                                                      y_train_scaled, y_test_scaled, y_scaler)\n",
    "    \n",
    "    #return necessary variables to create predictions\n",
    "    return y_train, y_test, y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 128 samples\n",
      "Epoch 1/300\n",
      "721/721 [==============================] - 13s 18ms/step - loss: 0.1062 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0737 - acc: 0.0000e+00 - val_loss: 0.3066 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0699 - acc: 0.0000e+00 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0704 - acc: 0.0000e+00 - val_loss: 0.3028 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0708 - acc: 0.0000e+00 - val_loss: 0.2989 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0703 - acc: 0.0000e+00 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.2983 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0678 - acc: 0.0000e+00 - val_loss: 0.3113 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.3135 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0717 - acc: 0.0014 - val_loss: 0.2933 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0688 - acc: 0.0014 - val_loss: 0.2803 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.2786 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0676 - acc: 0.0000e+00 - val_loss: 0.2839 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0674 - acc: 0.0014 - val_loss: 0.3007 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0652 - acc: 0.0000e+00 - val_loss: 0.9151 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0636 - acc: 0.0000e+00 - val_loss: 4.7593 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.1447 - acc: 0.0000e+00 - val_loss: 0.4065 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0686 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0679 - acc: 0.0000e+00 - val_loss: 0.2823 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0663 - acc: 0.0000e+00 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 0.2838 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0653 - acc: 0.0000e+00 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.2881 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.2940 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0639 - acc: 0.0000e+00 - val_loss: 0.3290 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.3915 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0610 - acc: 0.0000e+00 - val_loss: 0.8590 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.9307 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.4470 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 0.4549 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0421 - acc: 0.0014 - val_loss: 0.2581 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0386 - acc: 0.0014 - val_loss: 0.4858 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0333 - acc: 0.0014 - val_loss: 0.4760 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0324 - acc: 0.0014 - val_loss: 0.5090 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0304 - acc: 0.0014 - val_loss: 0.5627 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0291 - acc: 0.0014 - val_loss: 0.6472 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0278 - acc: 0.0014 - val_loss: 0.6994 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0339 - acc: 0.0014 - val_loss: 0.4277 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.4038 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.2825 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.2593 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0653 - acc: 0.0000e+00 - val_loss: 0.2636 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0649 - acc: 0.0000e+00 - val_loss: 0.2669 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.2843 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0641 - acc: 0.0000e+00 - val_loss: 0.3122 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.2829 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.7358 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 1.0746 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.9497 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0661 - acc: 0.0000e+00 - val_loss: 1.2637 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0617 - acc: 0.0000e+00 - val_loss: 1.4186 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 1.1666 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0593 - acc: 0.0000e+00 - val_loss: 1.3303 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.8406 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0386 - acc: 0.0014 - val_loss: 0.5413 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0350 - acc: 0.0014 - val_loss: 0.5526 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0328 - acc: 0.0014 - val_loss: 0.5714 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0309 - acc: 0.0014 - val_loss: 0.5161 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 2.7609 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0692 - acc: 0.0000e+00 - val_loss: 3.8245 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0706 - acc: 0.0000e+00 - val_loss: 3.0924 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0699 - acc: 0.0000e+00 - val_loss: 1.5305 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0661 - acc: 0.0000e+00 - val_loss: 0.8577 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0672 - acc: 0.0000e+00 - val_loss: 0.6036 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.6170 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0644 - acc: 0.0000e+00 - val_loss: 0.6031 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.7469 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.6561 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.3975 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.5290 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0643 - acc: 0.0014 - val_loss: 0.4120 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.3760 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0623 - acc: 0.0000e+00 - val_loss: 0.3025 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0618 - acc: 0.0000e+00 - val_loss: 0.3221 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0617 - acc: 0.0000e+00 - val_loss: 0.3211 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0597 - acc: 0.0000e+00 - val_loss: 0.3443 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0579 - acc: 0.0014 - val_loss: 0.4831 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.6668 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.4014 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 1.8851 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0681 - acc: 0.0000e+00 - val_loss: 3.5749 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0567 - acc: 0.0014 - val_loss: 1.8414 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0366 - acc: 0.0014 - val_loss: 1.9048 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0310 - acc: 0.0014 - val_loss: 3.4883 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0303 - acc: 0.0014 - val_loss: 2.6318 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0282 - acc: 0.0014 - val_loss: 2.3632 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0340 - acc: 0.0014 - val_loss: 0.7314 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0305 - acc: 0.0014 - val_loss: 0.6156 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0282 - acc: 0.0014 - val_loss: 0.5376 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0288 - acc: 0.0014 - val_loss: 1.8888 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 2.1659 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0276 - acc: 0.0014 - val_loss: 0.4858 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0304 - acc: 0.0014 - val_loss: 0.4309 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0236 - acc: 0.0014 - val_loss: 3.4463 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0229 - acc: 0.0014 - val_loss: 3.5607 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0194 - acc: 0.0014 - val_loss: 0.4478 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0172 - acc: 0.0014 - val_loss: 1.1057 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0150 - acc: 0.0014 - val_loss: 0.5913 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0159 - acc: 0.0014 - val_loss: 0.7242 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0155 - acc: 0.0014 - val_loss: 1.0891 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0146 - acc: 0.0014 - val_loss: 1.9457 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0144 - acc: 0.0014 - val_loss: 1.7432 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0195 - acc: 0.0014 - val_loss: 0.6968 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0337 - acc: 0.0014 - val_loss: 0.9751 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0407 - acc: 0.0014 - val_loss: 0.3062 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 0.3979 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 1.2933 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0645 - acc: 0.0000e+00 - val_loss: 1.8025 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.9559 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.7505 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0484 - acc: 0.0014 - val_loss: 1.2136 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0388 - acc: 0.0014 - val_loss: 1.6171 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0332 - acc: 0.0014 - val_loss: 1.6586 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0291 - acc: 0.0014 - val_loss: 2.0963 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0283 - acc: 0.0014 - val_loss: 2.2332 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0262 - acc: 0.0014 - val_loss: 2.7511 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0217 - acc: 0.0014 - val_loss: 2.3657 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0336 - acc: 0.0014 - val_loss: 1.4498 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0273 - acc: 0.0014 - val_loss: 0.9754 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0228 - acc: 0.0014 - val_loss: 2.1310 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0239 - acc: 0.0014 - val_loss: 2.0108 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.1576 - acc: 0.0014 - val_loss: 1.0154 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.1464 - acc: 0.0014 - val_loss: 0.5773 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.1079 - acc: 0.0014 - val_loss: 0.6549 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.1026 - acc: 0.0000e+00 - val_loss: 0.5807 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0954 - acc: 0.0000e+00 - val_loss: 0.5684 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0907 - acc: 0.0000e+00 - val_loss: 0.6417 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0918 - acc: 0.0000e+00 - val_loss: 0.5325 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0923 - acc: 0.0000e+00 - val_loss: 0.5415 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0927 - acc: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0876 - acc: 0.0000e+00 - val_loss: 0.5992 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0877 - acc: 0.0000e+00 - val_loss: 0.6044 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0851 - acc: 0.0000e+00 - val_loss: 0.5195 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0846 - acc: 0.0000e+00 - val_loss: 0.6129 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0816 - acc: 0.0000e+00 - val_loss: 0.5528 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0745 - acc: 0.0000e+00 - val_loss: 0.4595 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0673 - acc: 0.0014 - val_loss: 0.3360 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0780 - acc: 0.0000e+00 - val_loss: 0.3950 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0788 - acc: 0.0000e+00 - val_loss: 0.4950 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0843 - acc: 0.0000e+00 - val_loss: 0.3467 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0756 - acc: 0.0000e+00 - val_loss: 0.4983 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0696 - acc: 0.0000e+00 - val_loss: 0.4336 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.5222 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0902 - acc: 0.0000e+00 - val_loss: 0.6334 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0894 - acc: 0.0000e+00 - val_loss: 0.5862 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0903 - acc: 0.0000e+00 - val_loss: 0.6680 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0904 - acc: 0.0000e+00 - val_loss: 0.6449 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0884 - acc: 0.0000e+00 - val_loss: 0.5735 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0885 - acc: 0.0000e+00 - val_loss: 0.5837 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0824 - acc: 0.0000e+00 - val_loss: 0.4859 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0804 - acc: 0.0000e+00 - val_loss: 0.4555 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0856 - acc: 0.0000e+00 - val_loss: 0.4751 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "721/721 [==============================] - 10s 15ms/step - loss: 0.0777 - acc: 0.0000e+00 - val_loss: 0.3704 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0767 - acc: 0.0000e+00 - val_loss: 0.3126 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0767 - acc: 0.0000e+00 - val_loss: 0.4492 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0774 - acc: 0.0000e+00 - val_loss: 0.4718 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0771 - acc: 0.0000e+00 - val_loss: 0.3738 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0724 - acc: 0.0000e+00 - val_loss: 0.4012 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0769 - acc: 0.0000e+00 - val_loss: 0.4242 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0726 - acc: 0.0000e+00 - val_loss: 0.3476 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0711 - acc: 0.0000e+00 - val_loss: 0.3436 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0728 - acc: 0.0014 - val_loss: 0.3834 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0734 - acc: 0.0000e+00 - val_loss: 0.3580 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.3397 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0686 - acc: 0.0000e+00 - val_loss: 0.3684 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0692 - acc: 0.0000e+00 - val_loss: 0.3483 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0724 - acc: 0.0014 - val_loss: 0.3519 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0688 - acc: 0.0000e+00 - val_loss: 0.3765 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0692 - acc: 0.0000e+00 - val_loss: 0.3622 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0678 - acc: 0.0000e+00 - val_loss: 0.3693 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0683 - acc: 0.0000e+00 - val_loss: 0.3830 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0698 - acc: 0.0000e+00 - val_loss: 0.3652 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0649 - acc: 0.0000e+00 - val_loss: 0.4082 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.4580 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0542 - acc: 0.0014 - val_loss: 0.3672 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0662 - acc: 0.0014 - val_loss: 0.4534 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0589 - acc: 0.0014 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0610 - acc: 0.0014 - val_loss: 0.3870 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0514 - acc: 0.0014 - val_loss: 0.3329 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0437 - acc: 0.0014 - val_loss: 0.3198 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0404 - acc: 0.0014 - val_loss: 0.3830 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0407 - acc: 0.0014 - val_loss: 0.3568 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0383 - acc: 0.0014 - val_loss: 0.3916 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0352 - acc: 0.0014 - val_loss: 0.4063 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0423 - acc: 0.0014 - val_loss: 0.4629 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0417 - acc: 0.0014 - val_loss: 0.3395 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0487 - acc: 0.0014 - val_loss: 0.3875 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0404 - acc: 0.0014 - val_loss: 0.3128 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.0014 - val_loss: 0.3809 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0347 - acc: 0.0014 - val_loss: 0.4594 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0341 - acc: 0.0014 - val_loss: 0.3439 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0328 - acc: 0.0014 - val_loss: 0.4449 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0358 - acc: 0.0014 - val_loss: 0.3874 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0332 - acc: 0.0014 - val_loss: 0.5034 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0320 - acc: 0.0014 - val_loss: 0.3928 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0312 - acc: 0.0014 - val_loss: 0.4301 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0341 - acc: 0.0014 - val_loss: 0.4765 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0335 - acc: 0.0014 - val_loss: 0.3684 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0313 - acc: 0.0014 - val_loss: 0.3534 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0309 - acc: 0.0014 - val_loss: 0.4338 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0314 - acc: 0.0014 - val_loss: 0.5610 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0297 - acc: 0.0014 - val_loss: 0.3581 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0304 - acc: 0.0014 - val_loss: 0.5068 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0286 - acc: 0.0014 - val_loss: 0.6265 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0293 - acc: 0.0014 - val_loss: 0.6513 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0301 - acc: 0.0014 - val_loss: 0.5640 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0263 - acc: 0.0014 - val_loss: 0.7243 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0254 - acc: 0.0014 - val_loss: 0.6481 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0243 - acc: 0.0014 - val_loss: 0.7119 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.0014 - val_loss: 0.7305 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0547 - acc: 0.0014 - val_loss: 0.3052 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0478 - acc: 0.0014 - val_loss: 0.3399 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "721/721 [==============================] - 11s 16ms/step - loss: 0.0345 - acc: 0.0014 - val_loss: 0.3168 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0325 - acc: 0.0014 - val_loss: 0.3376 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0318 - acc: 0.0014 - val_loss: 0.4294 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0347 - acc: 0.0014 - val_loss: 0.4723 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0303 - acc: 0.0014 - val_loss: 0.4408 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0282 - acc: 0.0014 - val_loss: 0.4595 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0263 - acc: 0.0014 - val_loss: 0.5282 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0256 - acc: 0.0014 - val_loss: 0.5090 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0244 - acc: 0.0014 - val_loss: 0.5439 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0263 - acc: 0.0014 - val_loss: 0.4667 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0255 - acc: 0.0014 - val_loss: 0.5903 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0270 - acc: 0.0014 - val_loss: 0.5210 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0244 - acc: 0.0014 - val_loss: 0.6046 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0254 - acc: 0.0014 - val_loss: 0.5381 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0233 - acc: 0.0014 - val_loss: 0.5788 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0223 - acc: 0.0014 - val_loss: 0.5446 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0261 - acc: 0.0014 - val_loss: 0.6807 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0228 - acc: 0.0014 - val_loss: 0.6310 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0218 - acc: 0.0014 - val_loss: 0.6779 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0238 - acc: 0.0014 - val_loss: 0.6438 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0231 - acc: 0.0014 - val_loss: 0.5744 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0212 - acc: 0.0014 - val_loss: 0.6059 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0222 - acc: 0.0014 - val_loss: 0.6473 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0219 - acc: 0.0014 - val_loss: 0.6115 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0226 - acc: 0.0014 - val_loss: 0.6702 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0212 - acc: 0.0014 - val_loss: 0.6813 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0188 - acc: 0.0014 - val_loss: 0.7475 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0178 - acc: 0.0014 - val_loss: 0.7054 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0216 - acc: 0.0014 - val_loss: 0.5333 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0367 - acc: 0.0014 - val_loss: 0.4468 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0404 - acc: 0.0014 - val_loss: 0.4334 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0246 - acc: 0.0014 - val_loss: 0.6791 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0210 - acc: 0.0014 - val_loss: 0.7543 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0206 - acc: 0.0014 - val_loss: 0.6628 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0258 - acc: 0.0014 - val_loss: 0.7553 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0455 - acc: 0.0014 - val_loss: 0.3399 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0292 - acc: 0.0014 - val_loss: 0.3359 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0237 - acc: 0.0014 - val_loss: 0.4471 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0197 - acc: 0.0014 - val_loss: 0.4288 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0192 - acc: 0.0014 - val_loss: 0.5406 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0187 - acc: 0.0014 - val_loss: 0.5861 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0183 - acc: 0.0014 - val_loss: 0.5984 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0171 - acc: 0.0014 - val_loss: 0.6217 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0266 - acc: 0.0014 - val_loss: 0.6151 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0251 - acc: 0.0014 - val_loss: 0.5343 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0228 - acc: 0.0014 - val_loss: 0.3820 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0208 - acc: 0.0014 - val_loss: 0.6331 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0184 - acc: 0.0014 - val_loss: 0.6488 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0168 - acc: 0.0014 - val_loss: 0.6880 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0170 - acc: 0.0014 - val_loss: 0.6798 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0173 - acc: 0.0014 - val_loss: 0.6203 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0162 - acc: 0.0014 - val_loss: 0.5952 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0176 - acc: 0.0014 - val_loss: 0.6485 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0160 - acc: 0.0014 - val_loss: 0.6832 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0163 - acc: 0.0014 - val_loss: 0.5996 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0158 - acc: 0.0014 - val_loss: 0.5979 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0138 - acc: 0.0014 - val_loss: 0.6107 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0138 - acc: 0.0014 - val_loss: 0.4885 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0165 - acc: 0.0014 - val_loss: 0.5356 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0141 - acc: 0.0014 - val_loss: 0.6439 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0134 - acc: 0.0014 - val_loss: 0.6313 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0171 - acc: 0.0014 - val_loss: 0.6329 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0164 - acc: 0.0014 - val_loss: 0.5478 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0159 - acc: 0.0014 - val_loss: 0.5310 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0175 - acc: 0.0014 - val_loss: 0.6475 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0197 - acc: 0.0014 - val_loss: 0.5265 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0170 - acc: 0.0014 - val_loss: 0.7241 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0156 - acc: 0.0014 - val_loss: 0.5819 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0129 - acc: 0.0014 - val_loss: 0.6491 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0184 - acc: 0.0014 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0200 - acc: 0.0014 - val_loss: 0.4391 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0225 - acc: 0.0014 - val_loss: 0.6162 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0162 - acc: 0.0014 - val_loss: 0.6132 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0150 - acc: 0.0014 - val_loss: 0.5867 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0143 - acc: 0.0014 - val_loss: 0.7379 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0207 - acc: 0.0014 - val_loss: 0.5317 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0150 - acc: 0.0014 - val_loss: 0.5797 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0168 - acc: 0.0014 - val_loss: 0.5886 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0146 - acc: 0.0014 - val_loss: 0.5194 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0127 - acc: 0.0014 - val_loss: 0.7028 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0101 - acc: 0.0014 - val_loss: 0.5850 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0082 - acc: 0.0014 - val_loss: 0.5940 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0087 - acc: 0.0014 - val_loss: 0.6511 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "721/721 [==============================] - 11s 16ms/step - loss: 0.0085 - acc: 0.0014 - val_loss: 0.5939 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0078 - acc: 0.0014 - val_loss: 0.6630 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.10574903501498265, RMSE: 0.3251907671121409\n",
      "Test Set- Score: 1.2414444414774577, RMSE: 1.1142012571692144\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seq_length = 180\n",
    "fut_point = 80\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'third_model.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a function that plots results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot results\n",
    "def make_results_plot(y_train, y_test, y_train_preds, y_test_preds):\n",
    "    #create x arrays (just day indices)\n",
    "    days1 = np.arange(len(y_train))\n",
    "    days2 = np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "    \n",
    "    #plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(days1, y_train, 'b', label = 'Training Set Actual')\n",
    "    ax.plot(days1, y_train_preds, 'r', label = 'Training Set Predictions')\n",
    "    ax.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "    ax.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "    ax.legend()\n",
    "    ax.set_title('Walmart Stock Predictions')\n",
    "    ax.set_xlabel('Day Index')\n",
    "    ax.set_ylabel('Closing Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set- Score: 0.10574903501498265, RMSE: 0.3251907671121409\n",
      "Test Set- Score: 1.2414444414774577, RMSE: 1.1142012571692144\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test function\n",
    "y_train_preds3, y_test_preds3, train_score3, test_score3 = make_preds('third_model.h5', \n",
    "                                                                                         X_train_scaled2, \n",
    "                                                                                         X_test_scaled2, \n",
    "                                                                                         y_train_scaled2, \n",
    "                                                                                         y_test_scaled2, y_scaler2)\n",
    "make_results_plot(y_train2, y_test2, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This testing was done with a 180 day set of input data predicting 80 days in the future (about 4 months).  Clearly, this is much worse than before.  It indicates that predicting too far out may not be possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Interval Testing\n",
    "\n",
    "We now take a look at training our model for different sets of input lengths and future test points.  We begin with 20 days input and one day in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 894 samples, validate on 158 samples\n",
      "Epoch 1/300\n",
      "894/894 [==============================] - 5s 5ms/step - loss: 0.0366 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1241 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1724 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1925 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2092 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2094 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2230 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2460 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2418 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2486 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2579 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2699 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2840 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2783 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2780 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2681 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.3025 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.3252 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.3251 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3321 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3182 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.3030 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.3038 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3173 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3104 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2959 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2962 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3047 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2994 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3202 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3209 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3108 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2925 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3000 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2985 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3027 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3226 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3297 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.3209 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3252 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2884 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2703 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2798 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2913 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3215 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3547 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.3311 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3010 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2745 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2606 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2634 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3320 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3259 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3127 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2969 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3037 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2806 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2628 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2793 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2995 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.3007 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2603 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2745 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.3070 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3026 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2892 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2822 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2423 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2232 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2057 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2425 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3564 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3302 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2935 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2716 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2606 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2679 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2761 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2671 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2638 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2527 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3172 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3108 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2799 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2831 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2383 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2587 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2333 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2525 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2145 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2492 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2650 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2557 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2544 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2554 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3213 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.3262 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.3056 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.2822 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2754 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2672 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2390 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2461 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2267 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2254 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2665 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2466 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.2186 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1988 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.2025 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1955 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1620 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1831 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2035 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2420 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2490 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1553 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1655 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1754 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1226 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1612 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1569 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1598 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1918 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2061 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2458 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1288 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1771 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1541 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1574 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1388 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1603 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1812 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1794 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0959 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1888 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1916 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1014 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1012 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1121 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1281 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1176 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1070 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0923 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1398 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0969 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0990 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1398 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1425 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0887 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1136 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1040 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0799 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0573 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0651 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1354 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1130 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.018251367610925277, RMSE: 0.13509762252136517\n",
      "Test Set- Score: 0.12118753662673376, RMSE: 0.3481200031982273\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seq_length = 20\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'first_one_day_model.h5'\n",
    "y_train5, y_test5, y_train_preds5, y_test_preds5, train_score5, test_score5 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train5, y_test5, y_train_preds5, y_test_preds5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see trends somewhat captured but very off in magnitude.  Now, we try even lengths:  20 days and 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0563 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0185 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0151 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.0011 - val_loss: 0.1313 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0130 - acc: 0.0011 - val_loss: 0.1329 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.0011 - val_loss: 0.1557 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.0011 - val_loss: 0.1538 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.1733 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.1863 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.1987 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.0011 - val_loss: 0.2170 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.2518 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.2767 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0130 - acc: 0.0011 - val_loss: 0.2752 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.2944 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.3098 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3502 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.4169 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.4232 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.4427 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3840 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.3788 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.3782 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3828 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.4302 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0132 - acc: 0.0011 - val_loss: 0.3801 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3353 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.3663 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.4300 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.4615 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.5194 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 0.6283 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 0.7072 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.6827 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.6740 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 0.7128 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.9465 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.7946 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.6335 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.8144 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.9689 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 1.1514 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 1.0689 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.0288 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.1169 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.1098 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 1.0971 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.5388 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.4372 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.5139 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.6901 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 1.5512 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.4288 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 1.3138 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.0991 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 2.0653 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 1.2695 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 1.8494 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.3152 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.7054 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.0743 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 1.5021 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.4398 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.6452 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.5851 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.3124 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 1.5007 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.7726 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.9313 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 2.1830 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.9801 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 2.2262 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.8976 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 2.3025 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 2.0072 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.0011 - val_loss: 1.6428 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.7466 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 2.5954 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.0343 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.4500 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.6938 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.6747 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 1.2102 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 1.3674 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.8075 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 1.9461 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.6211 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.1732 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.9146 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.9268 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 1.9754 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 1.5007 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 1.9965 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.4946 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 2.0592 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.6318 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.1056 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.6440 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 2.2226 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.2494 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.6039 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.9905 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.3729 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.5444 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.5557 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.4498 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.8040 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 2.2223 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.9444 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.8672 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.2102 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.3349 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.7300 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 0.7397 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 2.0087 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.4404 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.6584 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.7111 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.5468 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.4080 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.6662 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 0.8267 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.3064 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.2546 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.4917 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 0.3408 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.1966 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.2982 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.2846 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.3477 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 0.3714 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.8127 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.0011 - val_loss: 0.3102 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.4972 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.4913 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.3115 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.3648 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 0.1922 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.4853 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.0011 - val_loss: 0.4018 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3190 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4081 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.4168 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.3063 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.4388 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.3425 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4327 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4610 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.4550 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3102 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.3929 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3289 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3721 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.3671 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.3279 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4743 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.6663 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3647 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.3601 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.3413 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.4825 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.4758 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.4932 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.3132 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.4481 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.3750 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3800 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.2610 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.0011 - val_loss: 0.3171 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.2465 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.3696 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.3504 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.4255 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.2336 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.2063 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3565 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.2432 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3979 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.3238 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.5329 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.3794 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.4269 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.3312 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.5068 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3201 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3300 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.5666 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.5148 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.4600 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.6063 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.5378 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.2860 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.2774 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.3522 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.4637 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3237 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.6189 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.7263 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.6355 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.5242 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.2403 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.2113 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.6915 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.3190 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.2791 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.4405 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.4078 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.7121 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.3357 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.4101 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.4705 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.1404 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3708 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.2763 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.3362 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.3129 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.3919 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.4237 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.3949 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.2450 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.3550 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3028 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.1590 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3049 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.3395 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.2250 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.2399 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.2128 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.2566 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.1281 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3259 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.2302 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.2362 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.0011 - val_loss: 0.1676 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.1650 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.1543 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.1729 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.2064 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1417 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1098 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1280 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.0011 - val_loss: 0.2600 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.2141 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.0011 - val_loss: 0.1841 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0081 - acc: 0.0011 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.1698 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.1632 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.2681 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.3532 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.2865 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.2543 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.2096 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "880/880 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.2108 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.1862 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.2167 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.2085 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1969 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.2032 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.2742 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.2150 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.2291 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.039451694439621966, RMSE: 0.19862450614066224\n",
      "Test Set- Score: 0.2755998133635912, RMSE: 0.5249760121792149\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seq_length = 20\n",
    "fut_point = 20\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'four_week_model.h5'\n",
    "y_train6, y_test6, y_train_preds6, y_test_preds6, train_score6, test_score6 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train6, y_test6, y_train_preds6, y_test_preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the magnitude is off.  We now try one day ahead with one last week (5 days) of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 905 samples, validate on 160 samples\n",
      "Epoch 1/300\n",
      "905/905 [==============================] - 3s 4ms/step - loss: 0.0426 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "905/905 [==============================] - 0s 476us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1239 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "905/905 [==============================] - 1s 622us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1176 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "905/905 [==============================] - 0s 516us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "905/905 [==============================] - 1s 598us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1163 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "905/905 [==============================] - 0s 526us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "905/905 [==============================] - 1s 718us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "905/905 [==============================] - 1s 597us/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "905/905 [==============================] - 1s 677us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "905/905 [==============================] - 1s 747us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "905/905 [==============================] - 1s 663us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "905/905 [==============================] - 1s 627us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "905/905 [==============================] - 1s 681us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "905/905 [==============================] - 1s 674us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "905/905 [==============================] - 1s 611us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "905/905 [==============================] - 1s 741us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "905/905 [==============================] - 1s 664us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1733 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "905/905 [==============================] - 1s 588us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1778 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1823 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "905/905 [==============================] - 1s 689us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1830 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "905/905 [==============================] - 1s 731us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1862 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "905/905 [==============================] - 1s 682us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "905/905 [==============================] - 1s 690us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "905/905 [==============================] - 1s 674us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1811 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "905/905 [==============================] - 1s 666us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "905/905 [==============================] - 1s 720us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1749 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1801 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "905/905 [==============================] - 1s 600us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1817 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "905/905 [==============================] - 1s 607us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1785 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "905/905 [==============================] - 1s 586us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1873 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "905/905 [==============================] - 1s 591us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1725 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1735 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1763 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1775 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "905/905 [==============================] - 1s 569us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1734 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1752 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1796 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1804 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1761 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1816 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1828 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1807 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1831 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1742 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1618 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1730 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "905/905 [==============================] - 1s 567us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1683 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1664 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "905/905 [==============================] - 0s 530us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1792 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1617 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "905/905 [==============================] - 0s 533us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1659 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1639 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "905/905 [==============================] - 0s 537us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1611 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "905/905 [==============================] - 0s 533us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1602 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1575 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1615 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "905/905 [==============================] - 0s 527us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1680 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1776 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "905/905 [==============================] - 1s 605us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1680 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "905/905 [==============================] - 0s 533us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1267 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1563 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "905/905 [==============================] - 1s 603us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1506 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1519 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "905/905 [==============================] - 1s 631us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "905/905 [==============================] - 1s 672us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "905/905 [==============================] - 1s 710us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1412 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "905/905 [==============================] - 1s 615us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1588 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1532 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "905/905 [==============================] - 1s 619us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "905/905 [==============================] - 1s 593us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1577 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "905/905 [==============================] - 1s 569us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1732 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "905/905 [==============================] - 1s 583us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1613 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1652 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "905/905 [==============================] - 1s 571us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1218 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "905/905 [==============================] - 1s 567us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1384 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1452 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1233 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 0s 551us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "905/905 [==============================] - 1s 575us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1250 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "905/905 [==============================] - 0s 534us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1546 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "905/905 [==============================] - 0s 539us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1504 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "905/905 [==============================] - 0s 530us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "905/905 [==============================] - 0s 535us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1317 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1607 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1565 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "905/905 [==============================] - 1s 665us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1425 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "905/905 [==============================] - 1s 588us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "905/905 [==============================] - 1s 685us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1437 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "905/905 [==============================] - 1s 698us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1442 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "905/905 [==============================] - 1s 593us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1357 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "905/905 [==============================] - 1s 600us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1534 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "905/905 [==============================] - 1s 624us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1468 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "905/905 [==============================] - 0s 523us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1544 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "905/905 [==============================] - 0s 467us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1407 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "905/905 [==============================] - 1s 644us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1396 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1393 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "905/905 [==============================] - 0s 523us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1109 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "905/905 [==============================] - 0s 519us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "905/905 [==============================] - 0s 519us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "905/905 [==============================] - 1s 607us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1250 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "905/905 [==============================] - 1s 604us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1412 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1369 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "905/905 [==============================] - 1s 613us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1443 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "905/905 [==============================] - 1s 671us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0986 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "905/905 [==============================] - 0s 518us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "905/905 [==============================] - 0s 450us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "905/905 [==============================] - 0s 510us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "905/905 [==============================] - 0s 471us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1486 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "905/905 [==============================] - 0s 450us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1395 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "905/905 [==============================] - 0s 456us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1601 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "905/905 [==============================] - 0s 500us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1369 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1530 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "905/905 [==============================] - 0s 511us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1589 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "905/905 [==============================] - 0s 464us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "905/905 [==============================] - 0s 510us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1540 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1457 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1572 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1735 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "905/905 [==============================] - 0s 448us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "905/905 [==============================] - 0s 506us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1427 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "905/905 [==============================] - 0s 472us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "905/905 [==============================] - 0s 511us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1264 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "905/905 [==============================] - 0s 486us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1579 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "905/905 [==============================] - 0s 527us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1394 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "905/905 [==============================] - 1s 621us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "905/905 [==============================] - 1s 745us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "905/905 [==============================] - 1s 724us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "905/905 [==============================] - 1s 601us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1104 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "905/905 [==============================] - 1s 583us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1368 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "905/905 [==============================] - 0s 492us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1109 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "905/905 [==============================] - 0s 473us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1675 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "905/905 [==============================] - 0s 478us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1420 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "905/905 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1485 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "905/905 [==============================] - 0s 460us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "905/905 [==============================] - 0s 460us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1302 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1616 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "905/905 [==============================] - 0s 486us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "905/905 [==============================] - 0s 495us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "905/905 [==============================] - 1s 680us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "905/905 [==============================] - 1s 847us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1885 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "905/905 [==============================] - 1s 587us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1662 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "905/905 [==============================] - 0s 471us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1825 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1447 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1192 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "905/905 [==============================] - 0s 478us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "905/905 [==============================] - 0s 468us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1594 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "905/905 [==============================] - 0s 464us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1218 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "905/905 [==============================] - 0s 472us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1055 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "905/905 [==============================] - 0s 506us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "905/905 [==============================] - 0s 477us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1291 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "905/905 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1241 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "905/905 [==============================] - 0s 467us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "905/905 [==============================] - 0s 516us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "905/905 [==============================] - 0s 481us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "905/905 [==============================] - 0s 484us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "905/905 [==============================] - 0s 507us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "905/905 [==============================] - 0s 487us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "905/905 [==============================] - 0s 515us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "905/905 [==============================] - 0s 480us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "905/905 [==============================] - 0s 477us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "905/905 [==============================] - 0s 468us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1124 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "905/905 [==============================] - 0s 472us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "905/905 [==============================] - 0s 461us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "905/905 [==============================] - 0s 456us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1318 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "905/905 [==============================] - 0s 460us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "905/905 [==============================] - 0s 450us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1104 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.022006138167540792, RMSE: 0.1483446600573839\n",
      "Test Set- Score: 0.15339001949797285, RMSE: 0.39165037916229933\n"
     ]
    }
   ],
   "source": [
    "#predict one day ahead with last week's data\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'one_day_model.h5'\n",
    "y_train4, y_test4, y_train_preds4, y_test_preds4, train_score4, test_score4 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train4, y_test4, y_train_preds4, y_test_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like trends might be captured, but magnitude is off again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different numbers of features\n",
    "\n",
    "Now, we try to improve the results by training the model hyperparameters.  We begin by checking whether the addition of features improves performance.\n",
    "\n",
    "We will read in the dataframe again and consider another couple features (volume traded and vwap).\n",
    "\n",
    "We test compared to the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-27</th>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "      <td>9105139</td>\n",
       "      <td>64.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-28</th>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "      <td>6035231</td>\n",
       "      <td>65.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-29</th>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>8440854</td>\n",
       "      <td>61.0517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-30</th>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "      <td>6742046</td>\n",
       "      <td>65.2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "      <td>10665285</td>\n",
       "      <td>65.3223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close    volume     vwap\n",
       "date                                                             \n",
       "2014-01-27  64.7650  64.9747  64.5029  64.7825   9105139  64.7739\n",
       "2014-01-28  64.8786  65.8746  64.7388  65.2368   6035231  65.3045\n",
       "2014-01-29  65.7785  65.8484  64.7126  64.7388   8440854  61.0517\n",
       "2014-01-30  65.1232  65.6037  64.9660  65.3067   6742046  65.2975\n",
       "2014-01-31  64.5816  65.6911  64.3369  65.2455  10665285  65.3223"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Walmart Stock Data\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "new_df = pd.read_csv(filepath)\n",
    "\n",
    "#drop unnessecary columns\n",
    "new_df.drop(['unadjustedVolume', 'change', 'changePercent', 'label', 'changeOverTime'], 1, inplace = True)\n",
    "\n",
    "#set index\n",
    "new_df.set_index('date', inplace = True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first run the functions for 30 days sequence and 5 days of future point for the old number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 7s 8ms/step - loss: 0.0480 - acc: 0.0011 - val_loss: 0.0932 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1506 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1442 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1476 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1522 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1659 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1577 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1557 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1431 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1854 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1695 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1726 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1762 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1751 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1699 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1855 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2029 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1974 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1859 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2105 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1966 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1703 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1817 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1937 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2169 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2263 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2290 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2126 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1950 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2229 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2306 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2264 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1903 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1958 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2358 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2222 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1892 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2227 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2001 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1926 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1787 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1690 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1801 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1718 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1114 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1013 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1573 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1666 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1748 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1007 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1002 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1371 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0887 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1131 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0358 - val_acc: 0.0064\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0387 - val_acc: 0.0064\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1275 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0064\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.3289 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0064\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1360 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1143 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0309 - val_acc: 0.0064\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0586 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0247 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0373 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2714 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1890 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1646 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2346 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1945 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1665 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.3358 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.3163 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1645 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.3428 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.4557 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.5764 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.4594 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.3116 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1532 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2850 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.3089 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2244 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1190 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1576 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0584 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1008 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0969 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2044 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1772 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.3098 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1748 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1638 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0458 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0607 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1144 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0266 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0309 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0639 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0286 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0573 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0243 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0794 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0303 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0260 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0588 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0262 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0214 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0204 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0380 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0572 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0304 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0395 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0269 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0212 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0300 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0203 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0271 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0233 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0222 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0210 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0259 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Training Set- Score: 0.006159613274324399, RMSE: 0.07848320377204539\n",
      "Test Set- Score: 0.027706175232711044, RMSE: 0.16645172042580708\n"
     ]
    }
   ],
   "source": [
    "#model for old number of features\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 8s 9ms/step - loss: 0.0548 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1511 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1673 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1909 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1707 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1888 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1788 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1938 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1661 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1774 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1725 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1673 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1879 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1632 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1726 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1619 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1882 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1698 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1342 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1529 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1614 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1617 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1770 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1755 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1491 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1228 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1711 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1788 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1876 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1817 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1685 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1886 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2372 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2097 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2018 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1993 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1874 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1801 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1328 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1546 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1142 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0894 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0971 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0834 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1332 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1043 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1368 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1744 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1811 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.2060 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1384 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1494 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1431 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0607 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1088 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0503 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0434 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0647 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.2215 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1293 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0791 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1027 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1969 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0303 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0289 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0776 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1054 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0605 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0442 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0609 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0654 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0525 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0438 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0947 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0452 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0392 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0494 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0358 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0652 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2709 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0949 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0232 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2528 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0249 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2076 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3134 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0746 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1237 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0872 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2711 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0719 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0733 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0709 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0990 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0452 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0435 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0363 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0373 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0643 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0393 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Training Set- Score: 0.008340317677133358, RMSE: 0.09132533973182556\n",
      "Test Set- Score: 0.04561135691145192, RMSE: 0.2135681551904495\n"
     ]
    }
   ],
   "source": [
    "#model for new number of features\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features_real_long.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(new_df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 905 samples, validate on 160 samples\n",
      "Epoch 1/300\n",
      "905/905 [==============================] - 6s 7ms/step - loss: 0.0509 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "905/905 [==============================] - 1s 581us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "905/905 [==============================] - 1s 746us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1480 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "905/905 [==============================] - 1s 677us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "905/905 [==============================] - 1s 609us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "905/905 [==============================] - 1s 599us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "905/905 [==============================] - 1s 616us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1809 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1793 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1851 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "905/905 [==============================] - 1s 596us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1810 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "905/905 [==============================] - 1s 586us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1768 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "905/905 [==============================] - 1s 580us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1791 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "905/905 [==============================] - 1s 656us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "905/905 [==============================] - 1s 585us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1859 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "905/905 [==============================] - 1s 618us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1891 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "905/905 [==============================] - 1s 584us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2039 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2055 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2178 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "905/905 [==============================] - 1s 584us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2193 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "905/905 [==============================] - 1s 632us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2126 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "905/905 [==============================] - 1s 623us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2103 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "905/905 [==============================] - 1s 591us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2114 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "905/905 [==============================] - 1s 622us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2130 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2139 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "905/905 [==============================] - 1s 592us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2038 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "905/905 [==============================] - 1s 699us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2270 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "905/905 [==============================] - 1s 726us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2100 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "905/905 [==============================] - 1s 700us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2176 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "905/905 [==============================] - 1s 681us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2170 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "905/905 [==============================] - 1s 590us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2166 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "905/905 [==============================] - 1s 702us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1992 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1952 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "905/905 [==============================] - 1s 593us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1864 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1883 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1860 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1713 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1656 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "905/905 [==============================] - 1s 627us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "905/905 [==============================] - 1s 606us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "905/905 [==============================] - 1s 608us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1534 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "905/905 [==============================] - 1s 720us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1752 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "905/905 [==============================] - 1s 689us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1435 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "905/905 [==============================] - 1s 669us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "905/905 [==============================] - 1s 627us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "905/905 [==============================] - 1s 607us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1196 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "905/905 [==============================] - 1s 586us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "905/905 [==============================] - 0s 536us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "905/905 [==============================] - 0s 540us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1262 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "905/905 [==============================] - 1s 643us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "905/905 [==============================] - 1s 623us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "905/905 [==============================] - 0s 539us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "905/905 [==============================] - 1s 633us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1156 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1174 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "905/905 [==============================] - 1s 588us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "905/905 [==============================] - 1s 649us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "905/905 [==============================] - 1s 699us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1127 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "905/905 [==============================] - 1s 597us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "905/905 [==============================] - 1s 606us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "905/905 [==============================] - 1s 654us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "905/905 [==============================] - 1s 613us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "905/905 [==============================] - 1s 617us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1192 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "905/905 [==============================] - 1s 587us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "905/905 [==============================] - 1s 631us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1707 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "905/905 [==============================] - 1s 579us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1150 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1170 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "905/905 [==============================] - 1s 597us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1194 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "905/905 [==============================] - 1s 629us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "905/905 [==============================] - 1s 579us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "905/905 [==============================] - 1s 698us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "905/905 [==============================] - 1s 663us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "905/905 [==============================] - 1s 612us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "905/905 [==============================] - 1s 692us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "905/905 [==============================] - 1s 592us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "905/905 [==============================] - 1s 579us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "905/905 [==============================] - 1s 600us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "905/905 [==============================] - 1s 620us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "905/905 [==============================] - 1s 592us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "905/905 [==============================] - 1s 595us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "905/905 [==============================] - 1s 605us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1443 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "905/905 [==============================] - 1s 618us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 1s 629us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "905/905 [==============================] - 1s 583us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "905/905 [==============================] - 1s 584us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "905/905 [==============================] - 1s 595us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "905/905 [==============================] - 1s 602us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1184 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "905/905 [==============================] - 1s 585us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "905/905 [==============================] - 1s 641us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1021 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2146 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "905/905 [==============================] - 1s 611us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2061 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "905/905 [==============================] - 1s 614us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "905/905 [==============================] - 1s 633us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "905/905 [==============================] - 1s 623us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "905/905 [==============================] - 1s 569us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1271 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1866 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1477 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1866 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "905/905 [==============================] - 1s 606us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1378 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "905/905 [==============================] - 1s 589us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1478 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "905/905 [==============================] - 1s 618us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2210 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "905/905 [==============================] - 1s 591us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "905/905 [==============================] - 1s 619us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1537 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "905/905 [==============================] - 1s 660us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1354 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1723 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1571 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "905/905 [==============================] - 1s 575us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1318 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "905/905 [==============================] - 1s 571us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1503 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1644 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2020 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1297 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1601 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1617 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "905/905 [==============================] - 1s 575us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1309 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1437 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1449 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1060 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1226 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1393 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "905/905 [==============================] - 0s 539us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1820 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2437 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1913 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1667 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1193 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1222 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1703 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1910 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1428 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1791 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1315 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1852 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1734 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1765 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1730 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1397 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1756 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2189 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1585 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1417 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1676 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1675 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1700 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1357 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1523 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1691 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "905/905 [==============================] - 0s 537us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1491 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1414 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "905/905 [==============================] - 0s 540us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1378 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1314 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1329 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "905/905 [==============================] - 0s 540us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1479 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1367 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "905/905 [==============================] - 0s 537us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1589 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1113 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1720 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1593 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1571 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1658 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1774 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1581 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "905/905 [==============================] - 1s 567us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1723 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1427 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1471 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1357 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "905/905 [==============================] - 0s 535us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1807 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "905/905 [==============================] - 0s 532us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1096 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1209 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1244 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.021015886693948032, RMSE: 0.14496857140065922\n",
      "Test Set- Score: 0.14614055765436051, RMSE: 0.3822833473411581\n"
     ]
    }
   ],
   "source": [
    "#test with 5 days sequence 1 day future point\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features_real.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(new_df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any improved performance, so it seems justifiable to include the simpler set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Now, we attempt to tune hyperparameters of the model.\n",
    "\n",
    "First, we will look at number of neurons.  For all of these first trials, we will use a sequence length of thirty days\n",
    "and a future point of five points as that gave us our seeming best performance before.\n",
    "\n",
    "We begin by training the number of neurons.  As with any hyperparameter training, the process is to run the training and use the training set score to choose the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.1296 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1641 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1728 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1824 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1828 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1783 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1677 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1751 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1945 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1916 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1940 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1953 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2077 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2207 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2406 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2477 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2619 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2623 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2670 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2601 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2832 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3034 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2826 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2872 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3131 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3282 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3569 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3689 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3759 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3731 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3512 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3536 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3741 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3656 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.3874 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.3477 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3516 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.4027 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.4191 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3646 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3540 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3642 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3815 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3711 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3332 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3709 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3345 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3111 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3137 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2818 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3278 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3079 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3246 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2523 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2654 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2540 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2687 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2304 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2343 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1899 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1961 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1410 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1583 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1083 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0064\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0342 - val_acc: 0.0064\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0282 - val_acc: 0.0064\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0268 - val_acc: 0.0064\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0064\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0064\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0064\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0946 - val_acc: 0.0064\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0064\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0064\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0064\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0618 - val_acc: 0.0064\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0064\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1130 - val_acc: 0.0064\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0227 - val_acc: 0.0064\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0203 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0449 - val_acc: 0.0064\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0235 - val_acc: 0.0064\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0229 - val_acc: 0.0064\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0349 - val_acc: 0.0064\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0204 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0249 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0246 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0064\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0400 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0692 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0396 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0328 - val_acc: 0.0064\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0471 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0328 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0972 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1962 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1602 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0304 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0647 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0400 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0792 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0514 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0590 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0862 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0787 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0678 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0064\n",
      "Epoch 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0791 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0700 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0521 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0651 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0695 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0562 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0954 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0471 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1257 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1261 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1205 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2689 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1561 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0248 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0486 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0455 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1590 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2347 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0418 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0242 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0961 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1907 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1452 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1779 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1193 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2114 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2526 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2083 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1640 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1560 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1291 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1861 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0737 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0952 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1064 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.011277323450821523, RMSE: 0.10619474304701491\n",
      "Test Set- Score: 0.06465379343084666, RMSE: 0.25427110223312177\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0320 - acc: 0.0011 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1729 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1781 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1824 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1921 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2006 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2024 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2015 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2022 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1999 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1962 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2103 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1732 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2122 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2144 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2318 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2395 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2216 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2194 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2337 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2616 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2670 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2628 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2573 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2683 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2612 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2628 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2582 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2975 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3401 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3290 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3358 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3349 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3413 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2800 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3197 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3500 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3447 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3480 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3552 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3533 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3417 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3451 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3401 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3385 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3293 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3337 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3511 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3607 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3493 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3446 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3203 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2964 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3036 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3037 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2999 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3023 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2435 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2357 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2440 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2599 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2488 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2586 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3181 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2583 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2493 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2552 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2510 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2296 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1959 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1965 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1634 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1351 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1239 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0064\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0605 - val_acc: 0.0064\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0064\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0064\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0064\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1778 - val_acc: 0.0064\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0064\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0995 - val_acc: 0.0064\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2231 - val_acc: 0.0064\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1403 - val_acc: 0.0064\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1131 - val_acc: 0.0064\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0847 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0544 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.3627 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0702 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0841 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1927 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1825 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1684 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2174 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0677 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1077 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0833 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.3550 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2233 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1245 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1468 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1952 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2059 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0750 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1688 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.2757 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1771 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1203 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1867 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0263 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.4702 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0956 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0834 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0448 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1439 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0219 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1235 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0260 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0168 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0349 - val_acc: 0.0064\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0458 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1590 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0208 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0972 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0633 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0259 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0791 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0250 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0418 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0552 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0249 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0205 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0743 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0064\n",
      "Training Set- Score: 0.007928202011121007, RMSE: 0.08904045154378434\n",
      "Test Set- Score: 0.036964372772237526, RMSE: 0.19226120974402905\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0418 - acc: 0.0011 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.0011 - val_loss: 0.1362 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1315 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1301 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1280 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1280 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1314 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1365 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1416 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1332 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1586 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1513 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1395 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1278 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1362 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1400 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1374 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1447 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1301 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 998us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 991us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 995us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1461 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1523 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1538 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1594 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1722 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1234 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1510 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1439 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1424 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1525 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1551 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1649 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1479 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1782 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1761 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1294 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1658 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0617 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1421 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1365 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1234 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 982us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0565 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0455 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0365 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0254 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0282 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0233 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0234 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0236 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0064\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0647 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1078 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1658 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0777 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0770 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0759 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2133 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1956 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1328 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0524 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1121 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1951 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2122 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2166 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2138 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2077 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1361 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1649 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1844 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2200 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1205 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2309 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2328 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2145 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1889 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2256 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2665 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1589 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2757 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1777 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1428 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2448 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.4884 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0839 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1916 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1980 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1195 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1652 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2649 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1883 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2436 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2020 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2997 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0799 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1944 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1493 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2218 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2624 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1378 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1351 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0753 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1886 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1338 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2660 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2084 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1416 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1469 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1710 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1991 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1543 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1715 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1075 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1471 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1517 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1551 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1694 - val_acc: 0.0064\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1309 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0064\n",
      "Training Set- Score: 0.010154810512008575, RMSE: 0.10077107974021403\n",
      "Test Set- Score: 0.038823068141937256, RMSE: 0.1970357027087661\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0410 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.0011 - val_loss: 0.1669 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1727 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 998us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1766 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1847 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 992us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1926 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1952 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.2018 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2071 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.2099 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2048 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.2069 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2096 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2243 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2252 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2297 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2252 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2303 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2381 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2220 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2214 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2310 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2341 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2417 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2412 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2379 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2425 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2409 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2487 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2630 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2616 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2352 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2436 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2497 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2455 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2571 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2619 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2468 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2455 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2545 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2317 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2571 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2492 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2487 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2655 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2363 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2191 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2222 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 972us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2173 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 989us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2369 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2365 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2261 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2249 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2128 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2262 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2371 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2290 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2229 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2409 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2510 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2488 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2325 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2192 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2383 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2421 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2158 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2168 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2156 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2093 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2138 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1868 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2442 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2470 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2160 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2272 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2169 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2297 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2335 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2205 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2171 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2427 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2190 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2760 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2462 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2032 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1954 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2121 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2055 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2395 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2271 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1948 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1803 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2143 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2190 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2096 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2255 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1812 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.2097 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1677 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2010 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1754 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2007 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2233 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2063 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1877 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2001 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1757 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1915 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2204 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2251 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1851 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1460 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1603 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1016 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1014 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0666 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 991us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0289 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0284 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0262 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0482 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0263 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0267 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0394 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0345 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0245 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0269 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0282 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0315 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0328 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0403 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0342 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0305 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0300 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0307 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0223 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0342 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0246 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0268 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0231 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0343 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0380 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0227 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0220 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0378 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0284 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0259 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0351 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0305 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0227 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 995us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Training Set- Score: 0.0062098498303944675, RMSE: 0.07880260040375868\n",
      "Test Set- Score: 0.018896806499232418, RMSE: 0.13746565570800737\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0619 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 852us/step - loss: 0.0153 - acc: 0.0011 - val_loss: 0.1937 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 908us/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.1847 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1751 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1640 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 900us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 885us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 828us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1177 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1203 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 724us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 824us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1055 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 832us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1062 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 812us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 849us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1006 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1010 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 709us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0839 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0770 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0763 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0781 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0689 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0719 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0787 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0742 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0704 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0664 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0841 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0752 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 873us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 890us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 903us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 883us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 864us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 857us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 782us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0800 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0794 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0827 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0886 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1237 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0794 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0998 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0852 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 827us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0766 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 802us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0366 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0421 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0423 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 802us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0393 - val_acc: 0.0064\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 768us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0387 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 897us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0455 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 898us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0448 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0556 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0400 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0350 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0307 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0304 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0315 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 825us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 828us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 905us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 864us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 882us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 824us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 833us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0489 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 872us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 910us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 927us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 840us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 850us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0418 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 827us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0358 - val_acc: 0.0064\n",
      "Training Set- Score: 0.00840558975827522, RMSE: 0.09168200345910434\n",
      "Test Set- Score: 0.02098413115448278, RMSE: 0.1448590043955942\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 4s 4ms/step - loss: 0.0643 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0140 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.0648 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 850us/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 862us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 872us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0856 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 862us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 893us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 880us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 904us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0599 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 828us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 832us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0562 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0541 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 873us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 837us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 842us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 864us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0558 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0517 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 813us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0581 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 869us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 825us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0750 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0770 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 903us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 883us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 900us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1072 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 890us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 883us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1037 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 849us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1407 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1486 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1511 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1442 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1698 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1583 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1372 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 833us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1495 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1264 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1556 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 771us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1650 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1558 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1510 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1172 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1361 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1001 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1110 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0963 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1163 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 854us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 858us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1233 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1267 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1156 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1400 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1530 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1341 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1194 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1211 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1062 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0977 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 837us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 918us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 915us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 865us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1144 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1238 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1223 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 879us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1027 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1041 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 843us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 901us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 892us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 865us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1054 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0946 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1022 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 934us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 912us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 887us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0758 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 871us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0796 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 824us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 842us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 891us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0648 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 922us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 870us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0429 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0743 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0654 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0677 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0689 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 852us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0467 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0365 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0343 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Training Set- Score: 0.008468011232952658, RMSE: 0.09202179759683386\n",
      "Test Set- Score: 0.029004056330608284, RMSE: 0.17030577303957808\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Empty 'DataFrame': no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-438a79f7d9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Neuron Lengths'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train Scores'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Neuron Lengths'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Train Scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, y, **kwds)\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lifespan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m         \"\"\"\n\u001b[0;32m-> 3090\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2939\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2941\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   1975\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1802\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             raise TypeError('Empty {0!r}: no numeric data to '\n\u001b[0;32m--> 373\u001b[0;31m                             'plot'.format(numeric_data.__class__.__name__))\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Empty 'DataFrame': no numeric data to plot"
     ]
    }
   ],
   "source": [
    "#look at number of neurons\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "#neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "neuron_lengths = [[256, 256, 32], [256, 256, 16], [128, 128, 32], [128, 128, 16], [64, 64, 32], [64, 64, 16]]\n",
    "\n",
    "#create lists to store results\n",
    "neurons = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for neuron_length in neuron_lengths:\n",
    "    neurons.append(f\"{neuron_length}\")\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neuron_length, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Neuron Lengths': neurons, 'Train Scores': train_scores})\n",
    "\n",
    "results.plot.bar(x = 'Neuron Lengths', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neuron Lengths</th>\n",
       "      <th>Train Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256, 256, 32]</td>\n",
       "      <td>[0.011277323450821523, 0.0009615384615384616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[256, 256, 16]</td>\n",
       "      <td>[0.007928202011121007, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[128, 128, 32]</td>\n",
       "      <td>[0.010154810512008575, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[128, 128, 16]</td>\n",
       "      <td>[0.0062098498303944675, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[64, 64, 32]</td>\n",
       "      <td>[0.00840558975827522, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[64, 64, 16]</td>\n",
       "      <td>[0.008468011232952658, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neuron Lengths                                    Train Scores\n",
       "0  [256, 256, 32]   [0.011277323450821523, 0.0009615384615384616]\n",
       "1  [256, 256, 16]   [0.007928202011121007, 0.0019230769230769232]\n",
       "2  [128, 128, 32]   [0.010154810512008575, 0.0019230769230769232]\n",
       "3  [128, 128, 16]  [0.0062098498303944675, 0.0019230769230769232]\n",
       "4    [64, 64, 32]    [0.00840558975827522, 0.0019230769230769232]\n",
       "5    [64, 64, 16]   [0.008468011232952658, 0.0019230769230769232]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of interest is the first number in the train score column.  Now, we try to train 128 neurons in each of the first two LSTM layers and 16 in the final Dense layer.  Now we train it and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 4s 5ms/step - loss: 0.0746 - acc: 0.0000e+00 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1544 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1503 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1566 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1504 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1437 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1776 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1839 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2109 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1984 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1882 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1891 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1946 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2026 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2167 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2401 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 1000us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2388 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2353 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2300 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2421 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2198 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2081 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2064 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2023 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2228 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2311 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2636 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2629 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2326 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2977 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2507 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2297 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2235 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2046 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1873 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1984 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1871 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1862 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2326 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2401 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2260 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1810 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1752 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1879 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1803 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1574 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1542 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 952us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 980us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 958us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 973us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 971us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0746 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0477 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 929us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 935us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0395 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 932us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 921us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 948us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 954us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 970us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0064\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 930us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 954us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0296 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 953us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 953us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 952us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 930us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0242 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 969us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0258 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 966us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 954us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 974us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 971us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0575 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 953us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1588 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0864 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0446 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0961 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0847 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0593 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0878 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1064 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0064\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1670 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1127 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 990us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 994us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 968us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 993us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 980us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 970us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1070 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0352 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 956us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 951us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 961us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 973us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 995us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1585 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2362 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1196 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 977us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 973us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 961us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1746 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1810 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 970us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 992us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1117 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1780 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1748 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0815 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2400 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1188 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1977 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1362 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0919 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1188 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0541 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0617 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0349 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0404 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0296 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0491 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0313 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Training Set- Score: 0.009353225429255803, RMSE: 0.09671207488858774\n",
      "Test Set- Score: 0.027158301809559696, RMSE: 0.1647977603293191\n"
     ]
    }
   ],
   "source": [
    "#train model for 128, 128, 16 and visualize\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'low_neurons.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4VEXXwH+TQhJSCEkooYYuEFIgNCmKNFFQQLHRRIooFpRXjYpSbKjv64uAfBYQVJSiKC+KCAKCFKUHCCA9QBICSUghlZT5/rh3N7vJJtlANpuE+T3PPvfeuTNzz95s7rln5sw5QkqJQqFQKBSFcbC3AAqFQqGonCgFoVAoFAqLKAWhUCgUCosoBaFQKBQKiygFoVAoFAqLKAWhUCgUCosoBaGoMIQQM4UQy+wtR0UjhLhTCBFtbzkAhBBLhRBv6/u9hBAnbrCfT4UQb5SvdIrKhlIQimIRQrwqhPi1UNmpYsoeqVjpSkcIESWE6FdKndeEEOeEEGlCiGghxEqTc1uFEBNsL6mZPI8LIfJ0eVKFEBFCiMG2uJaUcruUso2VMu0o1HaylPItW8ilqDwoBaEoiT+BHkIIRwAhRH3AGehYqKylXrdSIIRwsrLeWGA00E9K6QGEAZttKZuV/KXL4w0sBlYJIXwKV7L2eyoUN4pSEIqS2IumEEL0497AH8CJQmVnpJSxAEKIj4UQF/W33/1CiF6WOhZCBAghpBBinF4/SQgxWQjRWQhxWAiRLIRYYFK/hRBiixAiUQiRIIT4VgjhbXI+SgjxihDiMJAuhFgONAF+1t/GX7YgRmdgg5TyDICUMk5K+bne3ztAL2CB3n6BXn67EGKvECJF395uIoOPEGKJECJW/z5rivnuzwkhjgkhGpV086WU+cCXgBvQ3DBUpX/POGCJ3t9g3dJIFkLsEkIEmVwrVAhxQAhxTbeOXE3OmQ19CSEaCyF+FELE6/d5gRCiLfAp0F2/D8l6XeNQlX48UQhxWghxVQixVgjRwOSc1P+2p/T78okQQujnWgohtun3M8HUglPYH6UgFMUipbwO7EZTAujb7cCOQmWm1sNeNOXhA3wHfC+EcKV4ugKtgIeBucDrQD+gPfCQEOIOvZ4A3gMaAG2BxsDMQn09CtwLeEspHwUuAEOklB5Syg8sXPtvYIwQ4iUhRJjBKtK/++v6d31Gb/+M/ha/DpgH+AIfAeuEEL56s2+AmrrsdYH/Fr6gPm7/OHCHlLLEeQndQpgApAGn9OL6aPe2KTBJCNERTYk8qcv0GbBWCOEihKgBrNHl8gG+Bx4o5lqOwC/AeSAAaAiskFIeByajWzVSSm8Lbe9C+9s8BPjrfawoVG0wmkIO1usN1MvfAjYCtYFGwPyS7omiYlEKQlEa2yhQBr3QHprbC5VtM1SWUi6TUiZKKXOllP8BXICSxrnfklJmSSk3AunAcinlFSlljH6dUL3f01LK36WU2VLKeLSH8x2F+ponpbwopcy05otJKZcBz6I9rLYBV4QQ4SU0uRc4JaX8Rv9+y4F/gCFCCH9gEDBZSpkkpcyRUm4zaSuEEB/p1+qjf4fi6Ka/qcehKb1hUsoU/Vw+MEO/D5nAROAzKeVuKWWelPIrIBvopn+cgbm6PD+gKXBLdEFTvi9JKdP1v8mOYuoWZiTwpZTygJQyG3gVzeIIMKkzR0qZLKW8gGaFGizQHDRl16CM11RUAEpBKErjT6CnEKI2UEdKeQrYBdyulwViYkEIIaYJIY7rQwbJQC3Ar4T+L5vsZ1o49tD7rSuEWCGEiBFCpALLLPR7saxfTkr5rZSyH9p4/2RgthBiYDHVG6C9HZtyHu1tuzFwVUqZVExbb2AS8J7Jw744/pZSeksp/aSU3aSUm0zOxUsps0yOmwLT9OGlZP2eN9ZlbQDESPOInIXlN9AYOC+lzC1FNkuY3RcpZRqQiHZfDMSZ7Geg/12Bl9Gswz1CiKNCiCdu4PoKG6EUhKI0/kJ7yE8CdgJIKVOBWL0sVkp5DjS3SeAVtCGE2vpwRAraA+BmeQ+QQJCU0gsYZaHfwqGJrQ5VrL9hfw8cRlN6ltrHoj2QTWkCxKApJx/TeZFCJKENsywRQvSwVi5LohY6vgi8oysUw6embt1cAhoaxvtN5LXERaCJsDzxXdp9NLsvQgh3tOGumFLaGeZ9JkopG6ANky0UQrQsrZ2iYlAKQlEi+jDGPuBFtCEfAzv0MtP5B08gF4gHnIQQbwJe5SSKJ9pYfLIQoiHwkhVtLgPNizspNPfNe4UQnkIIByHEILT5g93FtP8VaC2EeEwI4SSEeBhoB/wipbwErEd7wNUWQjgLIXqbXk9KuRVtOOYnIURXa760FXwBTBZCdBUa7obvhKbcc4HndHmHow0lWWIPmkKZo/fhaqLILgON9DkNS3wHjBNChAghXIB3gd1SyqjShBdCjDCZrE9CU0Z5pX9tRUWgFITCGrahTbqajg9v18tMFcQGtIfkSbQhhyxuYNinGGYBHdEsknXAj1a0eQ+Yrg+9/MvC+VTgNbTJ7GTgA+Apk3Hwj4EHdc+beVLKRDQrYBraEMrLwGApZYJefzTamPo/wBVgauELSil/B8ahTSR3suI7lIiUch/aPMQCtAfsabRJcIOTwXD9OAnNEcDifZNS5gFD0FyWLwDRen2ALcBRIE4IkWCh7WbgDWA1mpJpAVi7LqYzsFsIkQasBZ43WKQK+yNUwiCFQqFQWEJZEAqFQqGwiFIQCoVCobCIUhAKhUKhsIhSEAqFQqGwSJUO9uXn5ycDAgLsLYZCoVBUKfbv358gpaxTWr0qrSACAgLYt2+fvcVQKBSKKoUQorgV9WaoISaFQqFQWEQpCIVCoVBYRCkIhUKhUFikSs9BWCInJ4fo6GiysrJKr6xQ3CCurq40atQIZ2dne4uiUNiMaqcgoqOj8fT0JCAgAPMglgpF+SClJDExkejoaJo1a2ZvcRQKm1HthpiysrLw9fVVykFhM4QQ+Pr6KitVUe2pdgoCUMpBYXPUb0xxK1AtFYRCobg1+P57SDAEID9+HHJy7CpPdUMpiHImMTGRkJAQQkJCqF+/Pg0bNjQeX79+3ao+xo0bx4kTJ0qs88knn/Dtt9+Wh8j873//IyQkhODgYNq1a8eiRYtKrL9lyxb+/vvvEuvce++99OrVq9RrX716lU8//bRM8hZm1KhRrFmz5qb6UFQ9Ll2Chx7SPly8CO3awbRp9harWlHtJqntja+vLxEREQDMnDkTDw8P/vUv81w1UkqklDg4WNbPS5YsKfU6U6ZMuXlhgezsbJ566in27dtHgwYNyM7O5vz5khdZbtmyBT8/P7p162bxfGJiIkeOHMHV1ZULFy7QpElxWS4LFMTkyZNv6nsobj0yM7Xt2bPAX39pB6tWwbx5dpOpuqEsiAri9OnTBAYGMnnyZDp27MilS5eYNGkSYWFhtG/fntmzZxvr9uzZk4iICHJzc/H29iY8PJzg4GC6d+/OlStXAJg+fTpz58411g8PD6dLly60adOGXbt2AZCens4DDzxAcHAwjz76KGFhYUblZSAlJQUpJT4+PgC4uLjQunVrAC5fvszw4cMJCwujS5cu/P3335w5c4ZFixbx4YcfEhISYryWKT/88ANDhw7l4YcfZuXKlcbyuLg47r//foKCgggODmb37t2Eh4dz4sQJQkJCCA8PZ9OmTQwdOtTYZvLkySxbtgyAGTNm0LlzZ+N9VMmubm0yMkwOzulJ6PLz7SJLdaVaWxBTp0Kh5+FNExIC+nO5zBw7dowlS5YYh1TmzJmDj48Pubm59OnThwcffJB27dqZtUlJSeGOO+5gzpw5vPjii3z55ZeEh4cX6VtKyZ49e1i7di2zZ8/mt99+Y/78+dSvX5/Vq1dz6NAhOnbsWKRd3bp1GThwIE2bNqVv374MGTKEhx9+GAcHB5577jlefvllunXrRlRUFIMHDyYyMpIJEybg5+fH1KlFMmoCsHz5ct577z1q1arFqFGjeOklLX30lClT6N+/P8888wy5ublkZGQwZ84cTp8+bVRcmzZtKvb+Pf/888yaNQspJY899hi//fYbgwYNsu7mK6od165pWymBqCjtICEBsrLA1dVeYlUrlAVRgbRo0YLOnTsbj5cvX07Hjh3p2LEjx48f59ixY0XauLm5GR+CnTp1Isrwj1CI4cOHF6mzY8cOHnlESw0cHBxM+/btLbZdunQpv//+O2FhYcyZM4dJkyYB2sN68uTJhISEMHToUJKSksg02PXFEBMTw4ULF+jWrRvt2rUjLy+Pf/75B4CtW7fy5JNPAuDk5ISXl1eJfRVm8+bNdOnSheDgYLZt28bRo0fL1F5RvUhLMzkw/F9IqY85VU3e3f4u9y2/r9JYx9XagrjRN31b4e7ubtw/deoUH3/8MXv27MHb25tRo0ZZ9KuvUaOGcd/R0ZHc3FyLfbu4uBSpU5YfWVBQEEFBQTz22GO0bduWRYsWGa0SUxlKY+XKlSQmJhoXkKWkpLBixQpmzpwJlO4e6uTkRL7JMIHhnmRkZPDMM89w4MABGjZsyPTp09U6hFscgwUBwPnz4OsLiYna7HUhS7yq8PqW1wE4nnCcdnXs/x2UBWEnUlNT8fT0xMvLi0uXLrFhw4Zyv0bPnj1ZtWoVAEeOHLFooaSmpvLnn38ajyMiImjatCkA/fr145NPPjE7B+Dp6ck1s//OApYvX86mTZuIiooiKiqKPXv2sHz5cgD69OljHF7Ly8sz3gPTvpo2bcrRo0e5fv06SUlJbNmyBYDMzEwcHBzw8/Pj2rVrrF69+obvi6J6YLQgpNQsiC5dtOPLl+0l0g2RlpbGmTNnSMpMMpZdSLlgR4kKUArCTnTs2JF27doRGBjIxIkT6dGjR7lf49lnnyUmJoagoCD+85//EBgYSK1atczqSCl57733aNOmDSEhIbz99tt8+eWXgOZKu3PnToKCgmjXrh1ffPEFAPfffz+rVq0iNDTUbJL6zJkzxMXFERYWZixr1aoVLi4u7N+/nwULFrBhwwY6dOhAWFgY//zzD/Xq1SMsLIwOHToQHh5Os2bNGDp0KB06dGDMmDHGeRNfX1/Gjh1LYGAgw4YNo2vXruV+vxRVC8N7hW9+vObSZPhNVDEF0b9/f1q2bMnR+IIh07i0ODtKZILB5bIqfjp16iQLc+zYsSJltyo5OTkyMzNTSinlyZMnZUBAgMzJybGzVNUH9VuzL3PmSAlSDqm3W9tZs0ZKZ2cpX3nF3qKVCUACcuGehZKZSGYi52yfY+tr7pNWPGOr9RzErU5aWhp9+/YlNzcXKSWfffYZTk7qT66oHhgsCP/r+rqdZs2gbt0qZ0EYOBR7CI8aHmTmZJKclWxvcYBqPkl9q+Pt7c3+/fvtLYZCYRNSU7VtnYwobadpU6hXr8oqiIi4CILrBXMy8SRJWUmlN6gA1ByEQqGoksTHa1v/7CiktzfUqlV1FYSAyIRIQuuHUtuttlIQCoVCcaPk5sKKFdp+U86T1zhAO6hfv0opCKOrdm1Iz00npH4ItV1rm3k02ROlIBQKRZXj1KmC/QCiyKqnuWbToAHExVUZJXHZIKe/tgn1VxaEQqFQ3BQGBTH9dUkAUaT5BWgFjRpBXp5mSegr+CszRgVRHxyFI+3rtFcWRHXmVg/3vWjRIurUqUNISAht27Y1rqm4UUxDeZd2XwrLVZ73SFG5MDxXQ5sk4kE6ybUCtIKGDQsqbd9e4XKVlYsXL2o79aGBUwNcnFyo7VpbeTFVV1S4bxg5ciRz584lLi6OwMBA7rvvPvz8/Iznc3Nzb8jdtrT7Uliu8rpHisqHYYK6rbv2W413b8qvH0HkN40wvpLExtpFtrJgjG7gD/VlfQC8Xb1JzkpGSmn3zIXKgqggbqVw3wbq169PQEAAFy5cYPr06Tz55JP079+fcePGkZuby4svvkiXLl0ICgoyWi35+fk8/fTTtGvXjiFDhpBgTBdWcF8A1q1bR8eOHQkODmbAgAEW5TK9RwcOHKBr164EBQXxwAMPkJKSUuK9O3LkCJ07dyYkJISgoCDOVuEAcNWRCxc0p6X66drfJc4lgGnT4MeIZgWVKvk8RG5uLmfPnsW9jjt4gE+u9j9Y2602eTKPa9cth7OpSKq3BVHJ4n3fKuG+DZw+fZrz58/TvHlzAA4ePMiff/6Jq6srCxcupG7duuzZs4fs7Gy6devGgAED+Pvvvzl37hyRkZHExsbSrl27IsmE4uLieOqpp9i+fTtNmzbl6tWr+Pj4FJHr119/NbYZNWoUn3/+OT179uS1117jrbfe4t///nex927hwoX861//4uGHHyY7O7vSRNdUaBw4AJ06gdt5bZ4hzkt7qUnBG65cgTvvrPQKYtSoUaxcuRLfUF/SScczyxOA2q61AUjKTMLLpWwRj8ub6q0gKhmWwn0vXryY3NxcYmNjOXbsWBEFUTjc9/ZixlWLC/f9yiuvAKWH+z58+DCbNm1izpw5bN68mUWLFrFp0yazMX9rwn0DfPvtt2zbto0aNWqwaNEivL29AS2Gk6sep3/jxo0cP36cFbqvYkpKCqdOneLPP//k0UcfxcHBgUaNGnHnnXcW6f+vv/6iT58+xqCCBuunOBITE8nKyqJnz54AjB07ltGjRxvPW7p3t99+O2+//Tbnz59n+PDhtGzZstTvrag4UlO1hdNOJ49xjgAyHQoiJVOnTpVYD2FIpuVY1xEAtww3QLMgAJKykmhKU/sIp1O9FUQli/d9K4T7hoI5iMKYfn8pJQsXLqRv375mdX766adSx13LOjZb2n2wdO9Gjx5N9+7dWbduHf379+err76id+/eVl9TYVsyMsDdHRz+Pswx2lHk36JuXagiUQRyvXMhFxyuaSP+BguiMkxUqzkIO1Fdw31by8CBA1m4cKHxgXzixAkyMzPp3bs3K1asID8/n5iYGLZt21akbY8ePdiyZYtxMv3q1aslyuXn54ebm5txfuGbb77hjjvuKFG+s2fP0rJlS55//nnuvfdeDh8+fFPfV1G+ZGRA88yjOBw/xlbutKwgDDPZlZwcrxxqpNUgM12zzo0WRGYSV9KvkJCRUFJzm2IzBSGE+FIIcUUIEWlS5iOE+F0IcUrf1tbLhRBinhDitBDisBCi6GB5NaM6hvsuC08++SStWrUiJCSEwMBAnnrqKXJzc3nwwQdp0qQJgYGBPPPMMxbf2uvVq8f//d//cf/99xMcHMzIkSNLleubb77hhRdeICgoiGPHjjF9+vQS5fvuu+9o3749ISEhnD17llGjRt3Q91TYhvR0GBzxNnh6soQnijos+fhASoq2JqKSk10rm5rpNcnQk2x7u2pDslczr9Ljyx60WdCGvHw7fQ9rQr7eyAfoDXQEIk3KPgDC9f1w4H19/x5gPSCAbsBua66hwn2XjAr3bVvUb80+5OVJ6UmKzHF0kfK556SWMajgI6WU8uOPtYOEBLvKWhKApAaSGcgmo5vIPn36SCmlTM5MlsxEPvfrc8bw3wcvHSzva1sV7ttmFoSU8k/gaqHi+4Gv9P2vgKEm5V/rsv8NeAsh/G0l261CWloaPXr0IDg4mAceeECF+1ZUCzIz4V7W4ZSXDQ89ZLmSwXHhauFHUCWjLiDA57qP0YLwdPHEQTiw79I+Y7XDl+0zxFnRT4t6UspLAFLKS0KIunp5Q+CiSb1ovexS4Q6EEJOASQBNmjSxrbRVHBXuW1EdyUjN5XGWku7lj3v37pYr1dbG8Su9gtDWxlFP1iMmPQYAB+GAt6s3+2ML/nfPJZ2zh3SVZpLakkuKRdcTKeXnUsowKWVYnTp1bCyWQqGobLhOm8JANnKyz5NQTDQCowWRVDliGlmiefPm0BC8Xbzxq+FntCBA82TKzsvGycEJXzdfYq7F2EXGilYQlw1DR/r2il4eDTQ2qdcIqPzr5BUKRYXy/cJ4XJYvYTFPcPLhN4qvWAWGmOrWq4tLWxf6Nu+Le0130tPTjecMnkyNvBrRpFaTW0ZBrAXG6vtjgf+ZlI/RvZm6ASmGoSiFQqEw8NeUb6hBDh/xIjU9Snh8VQEFcSX3Ctmu2fRr3g93d3MFYfBkauzVmIZeDYlJrWYKQgixHPgLaCOEiBZCjAfmAP2FEKeA/voxwK/AWeA08AXwtK3kUigUVZfH+I6/6cox2lOzpuU6UlKp5iD2x+7n478/Jje/YLFGUlISZ73OgoRBLQdRs2ZNMjMzjYs6DYvlGnk1oqFnQzMLYu7cuWYRGWyJLb2YHpVS+kspnaWUjaSUi6WUiVLKvlLKVvr2ql5XSimnSClbSCk7SCn3ldZ/ZaU8wn0DfPnll8TFxVk8t3PnTrp27WoMqf3WW2+V2NeBAwf47bffSqwzZcoUmjRpUuqq4/z8fObMmVNindIwDaKnUFhNaiqhHOQ37gbA0dFytfx8wMkJvLzsriCklDz0w0NM3TCVKeumEJUcBcC737wLt4PTCSeaejelZs2a5OXlkZOTQ3p6Op7OWlymxl6Nqetel6uZV41rIV544QX27dtnXCBqSyrLJHW1wRDuOyIigsmTJ/PCCy8Yj8sSsqIkBTF27FgWL15MREQEkZGRPPDAAyX2VZqCyMvLY+3atfj7+7Nz584S+yoPBaFQ3BB//YUj+exAi6kVGmq5Wn6+vuPjU2EKYs+ePYwbN458/eIv/PYCHT/ryO9nf+ds0lkEgs8PfE7bT9qyP3Y/P2X+BKmw9MGlgBZzDSAjIwMPDw++/+Z7AOp71Mevph/5Mr9I6I3o6Gibfy+lICqQr776ii5duhASEsLTTz9Nfn4+ubm5jB49mg4dOhAYGMi8efNYuXIlERERPPzwwxYtj/j4eOrX1/zjHB0djQH+0tLSePzxx+nSpQuhoaH8/PPPZGZmMnv2bL799ltCQkL44Ycfisi1adMmQkNDmTRpEsuXLzeWX7t2jbFjx9KhQweCgoJYs2YN4eHhXLt2jZCQEMaMGcPp06cJCQkxtpkzZw5vv/02AJ9++imdO3cmODiYESNGWBXoT6Eolh07yMWR3XQFtHDflrCHghg2bBhLly7l0qVL5OXn8fHujzkYd5CBywYiEMS8GMOOcTvwcfMh7IswzmSdgf3QM0xTdjX18TLD/8i1jdd4stOTjO84Hr+aWi4VY8gNX2AwRMZFFpGjvKnWq6amTp1aJP/BzRISEnJDwyORkZH89NNP7Nq1CycnJyZNmsSKFSto0aIFCQkJHDlyBIDk5GS8vb2ZP38+CxYsMHv4Gpg6dSqtWrWiT58+DBo0iDFjxuDi4sLs2bO5++67Wbp0KUlJSXTt2pXDhw/z5ptvEhkZWazcy5cv59FHH2XQoEHMmDGDjz/+GCcnJ2bOnEmdOnU4cuQIUkqSk5MZPHgwixYtMt7X06dPF/udR4wYYQzVHR4eztKlS3nqqafKfO8UCgD+/JMIQkjD06x4+HD48ceCY+MoqY9Phbm5+vr6EhsbS0JCAsJLIJE08mpEdGo0tze+HX9Pf/w9/dk8ZjNtP2mrNTpaEMDS1IIAIA0+HaylBTBVEJ6xnnAHEAR/x/3NYzxm0++lLIgKYtOmTezdu5ewsDBCQkLYtm0bZ86coWXLlpw4cYLnn3+eDRs2FImVZIlZs2axd+9e+vXrx9dff829994LaCG033nnHUJCQujTpw9ZWVlcuHChxL6ys7PZuHEj9913H97e3nTs2JHNmzcbZTZkZRNCUNsw8Wclhw8fplevXnTo0IEVK1Zw9OjRMrVXKIwkJCB37jTOP9xzT8Gpwkax0YKoXbvCLAhDxsT4+Hhir2ke+h/f/THLhi1j1YhVxnq3+d3Gngl7cN/oDkkFCsJgQaSlpRXt20RBJCYmQm0gCnrXtH104WptQVSmiVApJU888YTFCeXDhw+zfv165s2bx+rVq/n8889L7a9ly5a0bNmSiRMn4uvra8wMt2bNGlq0aGFW1zRaa2HWrVtHSkqKMVdEeno6Pj4+DBw40Kqw2k5OTsZxV4CsrCxjOI8xY8awfv16AgMDWbRoUbF5rBWK0oj9dC0N8vL4keG8+iqYxlos/BO1xxCTh4cHoP3/5GZo3kr1Pepze+Pbi9Tt3LAz6bs0l1ZDfhRD+7Vr1xapb6ogvK95a0NMxywrk/JGWRAVRL9+/Vi1apUxhWZiYiIXLlwgPj4eKSUjRoxg1qxZHDhwACg5pPa6deuM3kYnT57ExcUFT09PBg4cyLx584z1Dh48WGpfy5cvZ+nSpURFRREVFcXZs2dZv349WVlZDBgwgAULFgCagktKSjI+/A1huuvXr09sbCxJSUlkZWWxbt06Y9/p6enUr1+fnJwcvvvuuxu+d4pbmKgo8tf+Qt6ChZykFQcJZfJkiri4HjoEhhTkRgXh7Q3JySZjTrbD8KDPzMw0TiYbXFVNOXXqlDHvi7+/v/EFzNfXF4A333yzSBtTBRF1OQpqAlcL8pjYEqUgKogOHTowY8YM+vXrR1BQEAMGDODy5ctcvHiR3r17ExISwsSJE3n33XcBGDduHBMmTLA4Sb106VJjeO7HH3+c7777DgcHB2bMmEFGRgYdOnSgffv2zJw5E4C77rqLQ4cOERoaajZJnZaWxubNm40Z60BTJl27dmXdunXMmDGDy5cvExgYSEhIiDGb3fjx4wkKCmLMmDG4urry2muv0blzZ+677z6zjHizZ8+mS5cu9O/fv0imPIXCEocPg/FdJi8PevfG4f4hNL68nzmEAwJLEXaCgsBgOBv1Qe3acP26Ft3PxhgUREZGBkmZ2rzHiqUrzNzGf/jhB1q3bs2LL74IaOH4DRiGqAy0adPGuF/TuSZuTm7EZ8Sz++RuAJbNW8ajjz5qmy9jijUhXyvrR4X7VtgT9VsrX3JztQjdd96pFxw5IiXIPe53yv5skCClEMW3nztXa3/1ql7w6adaQUyMrUWXEyZMkICcP3++nLVllham2wl58uRJY53p06drIb71z6lTp4znkpOTzc61aNHCrP8m/20ix/40Vja/r7lkJvLI5SM3JS/2DvetUCgUZcEwNLR1q15w6hQA/2n4Eb8zACjZGDDMRZgNMUGFeDIZhnsyMzM5dOIQ5AKuRhR2AAAgAElEQVS5mDlmFA61b5pL3eDFZCA7O9vs2K+mHwkZCcTna1nyWtQ2n2e0FdV6klqhUFQdTHwdNC5p4di2ntRSwyxaBCUNuxsCu5oNMYE2D2FjDAri5ZdfhiFAa608NjaW3NxcnJyciigIb4MCA5ydnc3OFR5WNiiITLdMPPI9cHM2Vyi2QlkQCoWiUlBkLjkujjwciKcODz0E48eX3N6gIIpYEBWgIMxwBbR5aL744gucnZ2JjIw0UxBhYWE4mIQqF0KYTTpbsiDOx58n1zMXX+FrU/FNUQpCoVBUCopYEHFxxFOHfBzJySm9fbEKogKGmExdvU0VhGFB6ZEjR8wUhKXwOKYKIjU11ejtBOAm3YhLjQMfqOdcr3yFLwGlIBQKRaWgsIK4fjGOOD3lWlhY6e2LzEFU4BCTJQVh6rkXERFh9AKEonMOgFmsNiklUVFRxmOXPBetXw9oW7dteYpeImoOQqFQVApMn7GnTkHib1dIRctKPG1a6e2LzEEYohJUgILIy8srOHCFQd0GEX24IJjeBx98YFa/poVY5YY1UgZMo7U6XS94VA/pMeRmxbUaZUGUM1Ut3PemTZuoVauWsa933nnHahktYRrK+/XXX+ePP/6wWq6ffvqJDz/88Kaur6i6mCqI1q2hFikk480LL5Q8OW2gyBBTjRrairoKGmIyrmVwhSZ1m5CamlpsfcO6CUuEh4cDmCUQqpFVYF209m19k9Jaj1IQ5UxVDPfdp08fIiIi2Lt3L4sXL+bQoUNm5w2rpsvKO++8Q58+fayWa9iwYbz00ks3dC1F1afwEJMXqbTu5MVHH1nXvsgQE2jDTBU0xOTo6AgCcNUywr388ssAzJgxo0j9kv6nDAtXR4wYYSxrmNUQAHdnd9rWqbghJqUgKpDKGu7bgIeHBx07duTMmTMsWrSIRx55hMGDBxt/sHPmzKFLly4EBQUxe/ZsY7vZs2fTpk0b+vfvzynddx1g1KhRrFmzBoDdu3fTvXt3goOD6dq1K+np6UXkWrRoEVOnTgXg3Llz9OnTh6CgIPr372+MfT9q1Cief/55br/9dpo3b85PP/0EQExMDD179iQkJITAwEB27dp1U38rRcVjSUH43+ZldfsiFgSAnx9cuXLzwpVCfn4+Dg4OxCXEgSPUcqll/B/v0KFDkfolhb43/G+npKQY5zZSElPgI9g1bhdODhU3M1Ct5yCm/jaViLhyDvddP4S5d1evcN8G4uPj2bNnD++88w7bt2/nr7/+IiIigtq1a/Prr79y4cIFdu/ejZSSe+65x/hdVq9eTUREBNevXyckJITu3bub9ZuVlcUjjzzC6tWr6dixIykpKbi6uhaRa9GiRcY2Tz/9NBMmTGDkyJF8/vnnTJ061ajcrly5ws6dOzly5AgPPfQQw4YNY9myZQwZMoRXXnmFvLw8lXuiCmLq5upAHp6k4dmy7ArCzF22QQPjegpbYlAQ+c7aA92QU1oIQdeuXYvUt/T7XLduHVeuXDFGeAUtNam7u7sxbE6Qf5ANpC+eaq0gKhOm4b5B+4E0btyYgQMHGsN933PPPQwYMKDUvmbNmsXo0aPZuHEjX3/9NStXrmTTpk1s3LiR9evXGzO+WRPuG+CPP/4gNDQUBwcH3njjDdq0acP27dsZMGCAMcS3oe9QPY1XWloaJ0+eJCEhgQceeAA3Nzfc3NwYMqToBNrx48dp0qQJHTt2BLAqpPnu3bv55ZdfAC0q7BtvvGE8N3ToUIQQBAUFEROj5ert3LkzTz75JFlZWQwdOpTg4OBSr6GoXJi++Y8YeA02UHxWIAtYtCAaNIByzgljCYOCSMlOAaCWa4HcjRo1Yv369UZLPDQ0lAkTJhTp4x49hrlpYM0zZ84UO9RcEVRrBXEjb/q2QlbScN+gzUEYhoJMMX2TkVIyffp0xhdarfTvf/+71JDg0oqw4WXB1F9c6q+Ld911F1u3bmXdunWMHDmSV199lZEjR5bbNRW2x/BgnzULXh2ZCi3R8kpbicU5CH9/uHwZcnO1PNU2wqAgDJFcDRaEgbvvvtu4b4jYXByenp4cPnyYoKAgtm/fbrbiuqJRcxAVRGUN920tAwcOZPHixUbPiujoaBISEujduzc//vgjWVlZpKamGt/6TWnfvj3nz583frfU1FTy8vJKlKtbt26sWqUlWlm2bBm9e5ecHOX8+fPUr1+fSZMm8fjjjxu/u6LqYHiw+/uDc4b2Jl4WBVHsEFN+vqYkbEheXp5mQWTpFoRLUctn06ZNJXr1mRIYGIijoyNJSUlGd9djx46Vn8BWUq0tiMqEabjv/Px8nJ2d+fTTT3F0dGT8+PHGt+z3338fKAj37ebmxp49e8w8oJYuXcoLL7xAzZo1cXZ2Ngv3PXXqVDp06EB+fj4tW7bkf//7H3fddRcffvghoaGhvP766zz44INllv+ee+7hn3/+oVu3boCmdL777ju6dOnCsGHDCA4OJiAgwOKD3MXFheXLl/PUU0+RlZWFm5sbW7ZsKSKXKQsWLGD8+PG899571KtXjyVLlpQo3+bNm/noo49wdnbGw8ODZcuWlfk7KuyLQUE4OAAGF9GbHWJq3FjbXrwIDRvetIzFYfBiKs6CAOjbt6/V/Qkh8Pb2Jikpiby8PJycnLjtttvKTV6rsSbka2X9qHDfCnuifmvlS1SUFp37yy+llL/+qh3s2mV1+1WrtCZHTCNhR0Zqhd9+W+7ymvLII4/I1q1by8/2fSaZiYxOib7pPlu0aCEfe+wxOW7cOOnv718OUhaAleG+lQWhUCgqBWYWhGHo0dPT6vaGKQazJQYBAdr23LmbFa9ECs9BmE5S3yje3t4kJyeTkZFBs2bNbrq/G0HNQSgUikqBQUEIwQ0pCIPvglkgVHd3qFu3whTE/kv7cXd2x93ZvfRGpVC7dm2Sk5OJjY2loQ2Hx0qiWioIWSRusEJRvqjfWPljuKUODkBamnZwAwpiy5ZCJ5o3rxAFkeWbxaqjq8iX+eXitZeamsquXbuIiYmxmydTtVMQrq6uJCYmqn9ghc2QUpKYmFhiPB1F2bnZISaDgnjtNYiMNDnRrFmFKIh0f83D78073iyXPvfs2QNoMZmsWTtkC+wyByGEeB6YiBa55Asp5VwhhA+wEggAooCHpJRljrLVqFEjoqOjiY+PL0eJFQpzXF1dadSokb3FqFYUURAuLlAo01pJmAb0M/OebtYMVq2y6VqI+Ph40gPTCawbSHjP8HLpc/78+Tz77LMAdrMgKlxBCCEC0ZRDF+A68JsQYp1etllKOUcIEQ6EA6+UtX9nZ2e7TegoFIobp4iCKIP1AOYKwiQQqqYg8vI0V1cbPRt27twJYdChbtG4SzfK6NGjjQrCw8Oj3PotC/YYYmoL/C2lzJBS5gLbgGHA/cBXep2vgKF2kE2hUNiJIgqijA9FUwVhmMIAoEkTbXvx4k3JVxzZ2dnaq7Z3+YbiNl37VJZI0OWJPRREJNBbCOErhKgJ3AM0BupJKS8B6Nu6lhoLISYJIfYJIfapYSSFovpgpiDS0spsQZg+Q80sCMNiuehobMH69euhNiBspyCcbBgmpCQqXEFIKY8D7wO/A78BhwCrEw5IKT+XUoZJKcPq1KljIykVCkVFU8TNtYwKwjSpm5kFYZgrspEFMWzYMPDV9tv4tim3fh0dHY37t4yCAJBSLpZSdpRS9gauAqeAy0IIfwB9a/sg7gqFotJg5uZ6AwqieXN48klt30xBeHpqITtsZEEARgXRyreVTbq/pRSEEKKuvm0CDAeWA2uBsXqVscD/7CGbQqGwDzc7Se3gAJ98ou2bKQjQrAgbWBDGvNG+UM+9Hl4u1gcXLAv2UhD2CrWxWgjhC+QAU6SUSUKIOcAqIcR44AIwosQeFApFteJm5yAAHB3Bza3QHARo8xA2sCCM6UTrwG1+tgumZzrcVJHYRUFIKXtZKEsErA93qFAoqhU3a0EY8PAoxoIoJQ9DWTl9+jQLFiwAAS6NXQiqZ7tsb7fUEJNCoVAY0aPrTZumHQrkTSkId3dYvbqQkmjcWMtNbRao6ebo1Ut7z+0xuAfZZCsFoVAoFOVKVha0bEnu89PYuVMryku+prkk3eDq4cRETRdMnAi7d8Pp0xS4uuopassDQyrQJB8t4EP3Rt1Lqn5TVFoFIYSoJ4RYLIRYrx+30+cJFAqF4ubYswfOn8dp3kfGInHmtLZzg6FMDAvmjhyBbt2gVSvYE6v3ZYN5iPg68dzmdxvt6rQr974NVFoFASxFSx/eQD8+CUy1lUAKheIW4sIF464LWQCELn1OK2je/Ia6dHPTtkePFpSNmW6SWe4m6dmzZ0G0VndI8EjgwbYPlmve9cJUZgXhJ6VcBeQD6OEx8kpuolAoFFYQG2vcbc1JAPzP7NTckTp3vqEuLQXZjaaoBbFunbYoL6kMIUGTkpK0uEs6vSb2QiIZ0d42TpcdOmixnSqzgkjXXVIlgBCiG5BiU6kUCsWtgWEdAdCMc9wZrD+t33tPX1JddkaPLlqWjgdJeJtZEG+8oW2PHLG+7wULFpgd17+9Po28GpVrkD5TvLy0dRW2tE5KwhoF8SLaIrYWQoidwNfAszaVSqFQ3BqkFLxrNiSGPz49oR3cduNrCqZPt1x+nqac23qe0aM13XPwoFZucK8tjfz8fObOnQvAkiVLOHfuHFujtnJXs7ts9gCvWbMmAJmZmTbpvzRKtVuklAeEEHcAbdDyN5yQUubYXDKFQlH9SU3lqnczaiWfx59LcEJXEG1uPKZRcc/qszTntqP/sOyoaWkU//73R/Tq9d8SF6Nt3LiR9PR048rpxx9/nNhrscRnxBPmH3bDspaGmz6hkpGRYbNrlIQ1XkxTAA8p5VEpZSTgIYR42vaiKRSK6sy5c3BoeyoJebVJoRbeJGsKwsnJJnkbztKcdhznsEtnPEnVS0eybt189u/fX2y7TZs2MXDgQN566y2z8qNXNE3Tvm77cpfVQNu2bYHKnQ9iopQy2XCgZ3mbaDuRFArFrcDAgZB8MZXYa54k480jd+sKomXLMmWSs8TXX2tzEaaZh8+ieUV1yN7HGVoQxCFAi8lR0iTw+PGaV/+pU6fMyo/FHwOwqXvrW2+9xerVq+nb1z5BJqxREA7CZIBNCOEI2Cd7hUKhqDacOgUepHENT7Jda1HHKRnOnoUWLW6679GjNSVhygE6GvfrkMC/+DdaODjYe2IvI6aNIDe3aOaBC7orrmGYZ/Xq1QCcTzmPm5Mb9dzr3bS8xeHs7Mzw4cMr9ST1BrQgen2FEHehRV79zbZiKRSK6k79+pqCSMedjBrekJysrYto2tQm19tDF8J5j4ZEs5xH6MtmIAdcYXLEZH7w+oFX17xabPt8fTa7R48eAFxMvUjjWo3t9vCuCKxREK8AW4CngCnAZuBlWwqlUCiqPx07gjvppOFBZg1vLQzG1asFKULLGYkD7xNOLA3Zwl004BJuThnQEtCchdgQs4G8vDwuXbpkbBcUZB5jyeB6ejHlIo29GttE1spCqQpCSpkvpfw/KeWDUsoHpJSfSSnVQjmFQnFTJCdrFkQaHmS6emuz1lAQN8mGeN53FwDvDgmGtkAGsBfOpZ1j9uzZNGjQgBg9blNOToHTpqOjI676SjyDBVGdKVZBCCFW6dsjQojDhT8VJ6JCoaiOJCdJo4JwqG0SmM9GFoQp901tDv7+/JH/K7RHS3ycBGm5afy2VRtBnz9/PgDpJsklvLy8EEJwPe86l65duqUtiOf17WBgiIWPQqFQ3BBffAFnjmfjRB4tgz3oNsh2CuIuzVhg6lT47DNtv2UrAcOGMfIY8AewHdB9NZ3raB5U77//PgDXrl0z9uWse1ddTLmIRNLMu/zdcSsTxfp2SSkv6R5Li6WU/SpQJoVCUY25dg0mTQJftIQNj0zwgDy3ggoNGhTT8sbYsAFycgqC+I0dq0d8nTePhxLeZGafPhzPOG5UEB4NC9YcJCcnk2QSrCkhIQGAqOQoAJrVvkUVBICUMk8IkSGEqCWlVPGXFArFTXP8uLb10BUEHh7my5/LOTCdk5N5l4Zw4Dg6Qr16uBgK9Cfcht0bjHXHjh1r1ld4eDgA55K1+ZIA74BylbWyYc1fIgs4IoT4HcOqEkBK+ZzNpFIoFNWWY9r6sgIF4e5esDDO3b3C5alRQ1/WlY62LEIf7fL392ft2rUAdO7cmb179zJlyhRAsyAchSONvG4sZ0VVwRoFsU7/KBQKxU1jSAExYlA6rEezIHTXUWpU/BrcrKysgoNYQB81+vDDDxk1ahQAy5Ytw9HRkQb68Ne55HM0rtUYJwf7hOGuKEr8dkKIUDS9elRKebxiRFIoFNWZtDQtZ8OMaWkFCiI4WDtpmFGuUHlMklefAAYA3tC/f39jcatWrRBCsDdmL8NWDiPmWgwPtnuwwmWtaEpyc30TWAk8AKwTQqj4SwqF4qZJS9N0AmkmcxAeHhAZCUuXVrg8hgit06ZNA8NrcFvw8/Mz1jGslv7x+I/EXNPWRzwR8kSFymkPSnJzfRgIkVI+CnQGJlWMSAqFojqTnq5PNZgqCID27Qv2K5DkZM19afjw4ZAEXALagoODAy+99BI///yzse7Z5LMAPNP5GQa0GFDhslY0JQ0xZUkpMwCklIlCCGvCcigUCkWJWLQg7Ej79u05evRoQUiNKCAM8mU+H3zwgVnd01dPc3fLu5l/z/wKl9MelPTQbyGEWKt/fi50vLaiBFQoFNWLIhaEHTyXTPnll1/Yu3cvHh4efPPNN3AFcIZzSefM6kkpOX31NK18WtlHUDtQkgVxf6Hjf9tSEMWN8f33MG4cJCRYTtauUFQ2srP1tQiVREEEBAQQEBAAwKhRo2h1Zyu6Le5G5JVIWvgUhB5PyEggNTuVlj4t7SRpxVPSSupttrqoEOIFYAIggSPAOMAfWAH4AAeA0VLK67aSoboQHq69kW3bpiVgUSgqOzk5JgrCzU1bsFaJMCQAOhZ/jPtvK3hPPn31NMAtpSAqfF5BCNEQeA4Ik1IGAo7AI8D7wH+llK3QporGV7RsVRHDItC777avHAqFteTk6Ovi0tPtPv9gCU8XTxp7NeZYwjGz8lNXtYxySkHYHifATQjhhBaJ/RJwF/CDfv4rYKidZKtSpKgAKIoqhlFBGGerKx/t6rQzphQ1cPrqaRyEQ7UPr2FKhSsIKWUM2nzGBTTFkALsB5KllIZ8f9FAQ0vthRCThBD7hBD74uPjK0LkSk2bNvaWQKEoGzk5+oLpSq4gjscfJ1/mG8tOXT1Fk1pNqOF462RcLnWduO7BJAsVpwD7gM+klFlFW5XYX220CfBmaPETvwcGWaha+JpaoZSfA58DhIWFWaxzK6HPrdG2LeTlaTHPHJRDsqISY7QgrlZuBZGZm8n55PPUdqvNzK0zWRG5gqG33VoDG9YEEjkL1EHLRQ3aArrLQGvgC2B0Ga/ZDzgnpYwHEEL8CNwOeAshnHQrohFaVBRFKeh51MnOhk6dtJA2f/5pX5kUipK4ft1kiMnOHkzF0b5OewCOxh9l89nNfLz7YwD6N+9fUrNqhzUKIlRK2dvk+GchxJ9Syt5CiKM3cM0LQDchRE0gE+iLZo38ATyI5sk0FvjfDfR9y5GZCU2J4uzZpkD1TZ6uqNxkZcGRI9C5c+l1zeYg6tWzuWw3Qts6bQH4+cTPLD64mPva3MeIdiNuifhLplgzGFFHCGFM8aTvG4KUlNkNVUq5G20y+gCai6sD2pDRK8CLQojTgC+wuKx934p0OvcDUTRjML8Yy0xS6CoUFcITT0CXLnDlSul1q8IktberN01qNeHzA5+TJ/OYd/c8RgWNwtXp1lpsZI2CmAbsEEL8IYTYipac7yUhhDuat1GZkVLOkFLeJqUMlFKOllJmSynPSim7SClbSilHSCmzb6TvW40WV/cA0J/fcSAPB/IYNszOQiluOX79VdueOAGylJnByu7mamBgC21hUSf/TjT1bmpnaexDqUNMUspfhRCtgNvQxjD+MZmYnmtL4RSl45mpvbI14QLrGUQtUui2bjdCwC+/wL332llAxS2Bwd26d29YuxaGlJC1vip4MQE82+VZDl0+xLy759lbFLthrb9LJ6A9EAQ8JIQYYzuRFIW5cEHzTlqzxrzspwELuSNZm6oJ4jAD+J2u7MGHRAAGD7aHtIpbnbNnzY8zM2H+fG2eAnQF4ZineVhUYgXRoV4Hdk/YTddGXe0tit2wxs31G6AFEAHk6cUS+NqGcilMOHRI2y5aBEN1L7vbm0YTzRRjneYUBBYL5hB/UPGJVxS3JnMLjSMY3KyzsyEpCfz9ASTuB3cy7sN2ZGf74OGgu99VUi8mhYY1FkQY0ENK+bSU8ln9o/JRVyCGcBqGN7CYGGhPgQNZimNts/qhHDTur1VxdxU25oUXtG2fPtr2uee02GD9+hmUA/RkB08s6UV+335ICT41Kkeob0XJWKMgIoH6thZEUTyGfO6G9Q3r1kEn9hvP7+jzpln9//AvVjMcgPsLx+RVKKwkMBBefrnkOtdN/Bi//qpgdnr6dDi2IxFvkgDojfbjdTx0EC9S8HZSCqIqYI2C8AOOCSE2qHwQ9sHwT2hwX33uySxe5T0AVjGCA+1GaUuqJ0zga33d4nB+ohlnLfSmUJROWhocPQoffgjjx8O5c5br/fWXtl379mEaBfnwCnMAaNRQcpggIgnEiRzCPE8Y27TgDJ5CKYiqgDUL5WbaWghFyWQVCmbSi+14ksa+GT/zyleDWf8U8LH2Hzxh0XX+wzQOEcJah2G8XW8+0LtInwpFScyaVbD/5ZdaGBdL6aIXLgQvUhgyPRiAKZ5f8/61cMTlOBrqwRDua3iA1qknicePOiTQgjOkX9YHJZSCqNSUakFIKbdZ+lSEcAqNU6egMRcQ5JOTA/3YxHWcaTCyD+fOwW23FdTNoQaHCYKwMALzD/PdpTtV7A1FmfH2Nj+uW9dyvdhYeKbdH8bjxteOc29wNHFbjxvL7m0YwW3iBOv1kGutOEW7punaSaUgKjXFKgghxA59e00IkWryuSaESK04ERUrX9rLBZryIS8RGQn9nLaxX3SmQauiHiB33w3NmwvYtYvXHjlLAn7kzP/UDlIrqjLZhZap5uZarnflCnQQkdrB7t0A1Du0wcxR4vGED3FMTSahcUcuU5exvc4R1FwNMVUFilUQUsqe+tZTSull8vGUUnpVnIi3NtOmwSDWAzCOJezeDW3yjpLRLsxi/fXr4cwZwNmZBM9mrGcQ6Ws2amMECkUpHDoEt9+u/4ZMSE4uWjc/X7MgAvLPQIMGWiCmhg25j7W8wvvsoxOZvg1xOKt19k9+a6IIoG5mVKVJN6oomVKHmIQQLYQQLvr+nUKI54QQ3qW1U5QPH30E7dASl/iQxJynovCQaWR7F2Pzm3DsGGxkAN65iWT8dcjWoiqqAYsXaxPPEd8dZYvbveTtj6BZM3NvJQPnz2vP+aa5Z6BFC2015913cz9rqUs87/IamW+8a6zfbUxrztGMWlfPFSgIZUFUaqzxYloN5AkhWqIF0GsGfGdTqRRGPD2hLleQTpo/wb2sAyDTzbfUtvHxsIcuAPzfU4fJyIAXX4SJE2HfPtvJrKi6NNTTdI1nMX0yf8VhwhPceX2jxQCQiYnQkGj8Yg9rCgLMct++/tcQfJ4foy3G6duXJ2YH8PDLAThcvFBgkigFUamxRkHk6zkahgFzpZQvAP62FUthoHFjaOGVgOjfn1wnFybyBQAJxoC6xZOTA+doxnWcyYn8h65d4b//1VZkT5xoa8kVVRHDc7u5wUX64EG+jBlI3cTjReqmp+YRTWOc01MKFMTgwfDaaxAbS6du+gKeIUNg0yZwckI0b6b9MNes0X7cbm4V8K0UN4o1CiJHCPEoWo4GQ0xpZ9uJpDCQm6uN8XrnxkPDhlwIvZ8QtKGiuBpNSmmtvbiNHOPEWYeWhLGPyMiCc1kRx8n38S062Ky4pUlJAV9fGNrtsjavoNM6fmeRuvLkqYKD1q21rasrvPNOwRLqwhhSIO7fXxA3RlFpsUZBjAO6A+9IKc8JIZoBy2wrlgK0hUrJyRLP7ASoU4fc0C4FJw1vbCUQGAhffQUJnQbSj80EE2E89wwLcEi6Cj/+aAvRFVUUYwTuK1fgzjvh1ClSHGvTKvFv84o5ORAdDcC1OwZb/7Bv1qxgv0ePcpFZYTusWQdxDPgXcEQIEQhESynn2FwyBVu2gBepOOTlgp8frSb3BeBC0L288kHpcxAG9g6aQR4ORBDK+7yMLwn46hFf8x0cbSK7omqSlaUZAVy+rGV7a9mSo17duS35L/OK3btz5zta+s20f83U43dbQRMTy7dXr3KRWWE7rPFiuhM4BXwCLAROCiHU0twKYO9e8CNBO/DzQ4SGwIEDNNmxXPsntpKJL3nzOu8A8DIfcoI2PMJKAHLPRZe32IoqSHY2PPwwZO3azz8nhGZK6KvjjtfqTkD6MXIuXyUzU2+wvyAWWM2GtS30WAyurnDPPdpchckQlqJyYs0Q03+AAVLKO/Tc1AOB/9pWLAVo/7TBLfQVpwZ/8dBQzbWpDHh4QP9N4TTjLHvojC9Xjefyoi6Wl7iKKsyBA/D9qny+jB5QUKjniz5QV/NMcq7vy4qa44qsmvNqWgYFAVomKxVmuEpgjYJwllIaI21JKU+iJqkrhOvXoaajvqTVEPP7BqlXD6JoxiImGMvOEUD8wYvk599U14pqwIYNMJEvzF4eDAoiyreTsWgcS8k/aL6mRnjXKtvFhNA+ikqPNQpinxBisb5I7k4hxBdgEmtaYTNycspPQdTXY6MtYxT5Dz3M5ld/Zxt30CR2N0umRZbcWFGtyczUgvP1QYuplI/+8NYtVQdHgS8JXNKj/l/dWGgRjYO1iSkVVQ1r/rJPAUeB54DngYXg3bUAACAASURBVGPAZFsKpdAwUxBlmXSwgI+Ptn348Zo4rFxBvcf6cYx2AHh/UzTnbm4urFpVegJ6RdXn5EktIutANrCWIQxz1hZj0k77fRw9ClfxpQWaS/Tv7+y2l6iKCqbUcN9SymzgI/2jqECuXwc3ocf6vkkLwsFBS/9oWLgaGAh91r4I971CarIkNRW8TCJszZoFb78NNWuq3NbVnbNnYRKfU5tk3ucVduX0MHszMOSCyKQmKXjxaOYSO0mqqGhKiuZ6RAhxuLhPRQp5q5KTA+8d0Z/ON6kgQAvh7GTySjBoiBNpzQJplBfF+vUwZ05BFE89MKcaKq7mrF0Lw4dr8w/ZPe5iFz0YP968zu+/F+wnNexQsQIq7EpJFoR6b7QzOddNxnfKQUFYwj3hPP2J5PFJP/FV6jCcnbV4TYaHQrMd30C+txYuQVHtePZZcCSXZpzD+Y4RJK8r6iTXrx98+y2MHAnXFy7i2P3DOUgoffo702D8IPsIrqgQSlIQzkA9KaXZGnshRC/QU0UpbIpz1rWCA2sXIpUR8eyz8O67fJI6ikPs4LvvQs3SS7abM0bbUZMR1Y7vv4cLF6AxsTiTCwEB1CrGIemxx7RPSspteOvRhXe/DQ26WK6vqB6UNEk9F7hmoTxTP6ewMZ5Z8QUHNrIgePttng3dgTsZHKQjNQ9sZ8cnEaW3U1R5luhTCas/1N8ITMNgFINpbL3CWecU1Y+SFESAlLLIXIOUch8QYDOJFIAW8iDt3BXtYMaMgjjM5Y0QXGzSg/k8A8B2ehNBKA2I4U9UKITqTE4OdOsGnb31oHvNm5faxtlkBZTBM05RfSlJQZTkV3nDMXqFEG2EEBEmn1QhxFQhhI8Q4nchxCl9W8blmdWLV1+FOugWhI3H/7284NNCnssxNKIXO2x6XYV9uXBBj3axdav2IzBEWi0BU6cFX+vDgSmqKCUpiL1CiCJZA4QQ47mJhXJSyhNSyhApZQjQCcgAfgLCgc1SylbAZv24wsnL0xLt2HvI/fhxLVEQAHXq2PRakZFwSaX4uKVISNDWP4R1kvDbb1o01jIueFMebtWfkn4RU4FxQoitQoj/6J9twAS0BXPlQV/gjJTyPHA/8JVe/hVgl2DxCxZoMcruukt7oZprp9mWxo3NA/XZkm7dIInaJDmZX+dHhmk7TZva9PrVjdxc7eFbWUlPL3jnuCvwipYarlOnkhuZ8MMPEKGmqW4JilUQUsrLUsrbgVlAlP6ZJaXsLqWMK6frPwIs1/frSSkv6de+BFhMuiyEmCSE2CeE2BcfH2+pyk1x8KC23bM1Hd/z+3nhhXK/hBlSwqBB8Prr5uVxcf/f3pmHV1FkC/x3EhJIAgkEREGWsAQEF0AiqDiOCigiAq7jNsC4oCg4Cir4nHnoU8cVBndEZERER8UdNxYd1wFBdtlXUSBAAmELkOW8P6pv7g0kkEBu+oac3/f1191V1d2nuu/t03Wq6hxodVyGm6kWHx9WGZ55BrZuFarP/5G9V15fkH4F77PkrBsPcs5mFE9ODgwdCi1bOhNOJBLiiJV2MZ6bFW/WdEm44gpo06aMhTIikpLMpP4aPCctZYiIxAI9gftLc5yqjgHGAKSlpZW5IShgWhpDf67nTS5hMnl5lxAdprAJixe7Fv4XX8BNNwX7CTduhPqxW6Fa+A29MTGePbl2KjHvvgHv9GRnfgJcC/ujq7kec6NEhI5G3rq1cPiDSGGyFxfy08cWENu9i9s5/XT/BDIiFj+9bF0MzFHVdG8/XUTqAXjrzX4IlZkJoPTiIwC68xl79pTNubdsgZ0HDBwOxAAGGDLErbOynOI4Pnpr2M1LRXL11UT3vASAHfuqEQwCYARYutSLnxCiOw/st8rLK1+ZSkp6urMadp/rYoRw9dU2JMkoEj8VxLUEzUsAH+PiXuOtPyovQbKyAorB/fFPrp1OdVwchjt4kWodTqXQ7LEjpG7dg1vyf/ubW9cikwlT6sILLzB7tnsnN4rf6ttQkYBVa+qsJNizx9lODMD9Xlq1cs4M4+JcZ23TpsGpKnHsYQy3cEYHcfamCGL5cmdGrVED+Okn6NYNJkzwWywjQvFFQYhIPNAVCA2I/DjQVURWeHnlFtb0jDPcezg9HVauhDu6Oa+VO3Ge7WKWLoJJk8pkZJMXxpcRI5wPnPmea/3efEj1PVtg4MCCDs7q+zL8aUGEkIn3Zbltm69yRBJLlwa3b+MlxnALI9f0ZnjOA9RmK1fwHrcw1hV48klq1IANG5xCKS9GjoS1aw9Ob9kSFi6EzRvzYP16Z1oK0yx94xhAVSvs0r59ey0LnHFA9dxz3frX64dprkTruAvf0tWkuMTBg/XKK1V791bNzw8em5+vOmSI6pw5qrNmFX+N/fuD13n++eB21aqq9w3YEUwAHThQ9QKmuf2bby6TOh4JM2eqXstEJ8eSJb7JEWk89ZS7JQ34tdBzK24B1YYNvd/Wr+GXLz3dXatFi8Lp+flBsQpkf/nl8AtkRBzAbC3BO7bSR/p4++3AltL926F051NO/Op1oi/sQsJN19CUNWTENyBzZSaTJsGHH8Ly9xe5oYG4j7ARI9yH2BlnFD82fLPXo5JMBpsGPkwS27mBCQzd9xB/3PxuQblconn+eeU1+rmEc/0L/12nDiynBQB7nnnFNzkijXvvdeuZ3R4sSPvHIcZaxLKP+9cP4CreoVEj50q9NGzf7iZO3nVX4RFIxbHeiyJ7oFV0c0iv3pk1vSCRkdiLbkQOJdEikbocbQti507Vk05ShXxdSovCX37TpunKlW4zQ5JVQaPI1RYsdYm1a6vm5Oj06Qd/NGZkHHytzz5zef/DI8V+aQby2jPLpQ0YULi5Us7s2uXEmEsb/Yk03+SIJPLzVWPZq0lsU01NVe3WTVVVly9XfWNkuub06KV6ww3akHUFz7UzU0NaE/kKqvfcU/Jr3nVX8GfSqtXhy4f+rArIydG5H6xRIU9HjlTNPr+bakyM6tq1pbsBxjEB1oI4NB984Drqli6FHo0X0ZKQmU1160LnzjRr5vrwFiadA8B1yV/yrfzRlcnIgHnzWOW6K2jAesZwC4qQXFtgtgvLmJcHl1wC3bu7cknsKFKeCTE3sg3nXeS7W99wicOH+zpdNSHByT2TjjRjFTu2W/DqH36Ar7iA7dSCFSsK3KCkpsL1d9elyicfwoQJaINGtMVNqhkW0p32KjdxI6/y36e/Z9farSWash+Y4HwCG2m5bQa89BIlCSRejWzyZ8/httvg90GP0/ayJrxOH7o3WEC1r7+AYcNsEqRxaEqiRSJ1OZoWxHXXBb+yvu7ivty/4EKX8OOPBeX69lU9pX6GKmhGUooq6PdJ3VVBx/zxDR0yRDU2VjX/8isKf7pdcYWqqk6ZUjg5vd1FurlGE13AKfpu3J9Vhw1T/e03rVNH9QZed4Vq1lRNSTniupUl48apXscbqqDZzU92nS2HYONG1fnzy0m4cmbtWtVocgo/0F27iiz71VeqQp6uo2GxLcZA31YoP/yg2rOn6uTJ7lbPnq16++2u6DaSgsd9/32xcjZp4oq8Rh9V0JNZqB/To+DY3GapWm4dIkZEQglbEL6/5I9mORoFcdVVrvYBk1FG8zN07bK9qqtXFyp3772u3Pv0LviD1SJD8xD9Xx7UGtXz9crTVxXkdU/8Tuec2EO1cWPV/HwdMcJl9eywUWeP+s7t9O+v69YVNkUlJKj25MPgCyBCOg/z81VffHJnUK4QxfX666qJiS55zn/3qmZm6gknaGHTxjHEG2+oduEAjV8MCxa47ElcfmgF0bp1oeMCyW2Yqwp6Fj/oUB7TZLYWPu7dd4u9duPGTjkFyl7Ge7qCZjqFLrpB6rn0WrV8NV8a/lJSBVFpTUwbN7r1+JibAUi+ux+NW1Q9yCd+r15ufSPj2Hb1rfx42VNsI5n1NORkfmHLrmq8O6eZK/TVVyT3PIe3srrDunVsmTKXKVPcENoPa/al/V2e++zzz6dRo8Jzk7KzYSchobwujoxIXSLQsXN15tDOJYS43ejTB3Z4FrO47udDcjKZm1zM0v2LlsOuXeUtbliYPBk++QRuuAH68How4xDBuk8+GW69FVIuOgmAD3E/pG/7vcr/8fdgwd27CzY1xNrU13NL9iOdeJz7yeCA4c5btxZ77exsSGFtwf77XEFzVvExPflUPM/AhxpRYRgBSqJFInU5mhbEOU1+036XZ2l+dLTq0KGHLDt+fLBhsXat+wCbSmfdS2zwi+6zz1RV9fHHVWuSqdlRcTqKOxVUb++3W1XElRs0SDUn56BrgAY7pyPsE3zNGtUY9unPvR9ysi1erKpBUVvxS8HOeXylx+GNs+zVy1/Bj5J9+1RHjw7Wsxp7dDdxmt2mg2pmpuqePYc/yYYNeiejnGlKVefODbZcN6ac6QY7eAQGBYDqYk4qssVxV+JYtz18eLGXrFFD9fmeXx50bDJbdfDxzlyof/vb0d4eowKDmZgOQU6O5hCt+6OrulswblypDn/6adWFnW4N/vnWrSvIe+stl/QjZ+r3nK2fcEmw3LRpxZ4TVFNZ5jbq1TuyeoWJnZ6F6Ty+KqhLXm5+QbUG8EKhF9HpzI5IRVdaOnQIVuMq3tbbeFEPZ94pigNvReAjY+Z597mJMB6//66FzEuBZQu1VUF/at1XhTzd16SFalpasSaiKlVU3+r5pipoW+bozpPaa/7dg3X8eNWVy3JVJ05Uzco6ontiHBuUVEFUShPTt2OXU4U8YvKcOaQkkbRCGTIETunpHdO4caGx5IGJz5s4gU78SA8+dQmJidC58yHPu5Lm7HrgMTdUJoKo7iaU8x1/INuLI/Xh2KCJ49q2S9lN0ONsE9YED77ttgrppmPXLueJAuD+uFG8w594idtdQosWpTrX99/D+yE+A+p5oTeyo6vDvn3o/hwuvRT69oUEdtE+YVmh44cwAlT59KrXUKJ4tcptbpTcN98cdK3cXLdUx5n3nhx3HAmLZyMjR9CnDzRrEe2CSycmlqoORuWkUiqIjPf+UzihlAoCgAYN3Pq++wol1/Li4G3iBAC2VTuBnNGvFvbPUAQjRkCnc6Ko/siwEsUGLm/69IE8qnAlkwDYcecDxLObt4cv5g/znmN2bCcu8zyn/J2Hgwe+/HLEKbySEHj3Duq+in9kh/h8r1PHdTCUgk6d4LLLgvsxMc78vyvKvaR/mprF5MkQPe0LdlGD66q8Xej4Cwe2BGDwYLc/eMVtZFVJhttvLzTcdeNGN3wbICnKeYXsenkN62owjpySNDMidTlSE9OC0T/oS4SYiPLySn+S3Fw3hvWAZv4qb0DTNbx5TJhZAgTcNBRMFARdQTNdfuNjqqD902brySwsyJtCF/2/hMfd/ujRfotfamo7q47ueGik21i50vlLKSPTTHy86ms93lUFfejyeSrk6SqaFNy/HVQP/n5ChrtN9ebcbScxmL9okaq60UuBpGXXP+g2cnPLRF7j2AIzMRXPqbeezbXbRztPeTNnljrUIgDR0dC160EjQQKRut7mT2S27wIPP1zEwRUPEfd1ev7NzZlVx42was4qUsfdDzExrE5sxyqaFZTvwWRekIFuZ0fRkwMjgf37i46H5HlSofrqBXD88dCsmfv0LyPTTK1asC6/IQBzP17PnXFjaRpimltPQz4/9zG4++5Cw906dHDrm3g1eLJTToENG1i3LpjUoFqGsw2GK5CJUSmolAoCICkJOO204D+ujKhRw4UprRYXRe5nU4P+vI8BeveG0a9E02zZZwghM3k7daLeiVHsJa4g6dZBVcnIjnfKNyvLB2lLxiWXeF0Kc+fCPm+I7v5gviyYH5bwaQ0bwqIspyB65U5iVPatAOxr4Myda0nh647DnFvWEBIT4Q9/gPe4kh58EswYO7Zgs02LbOJ/mQVt25a53EblotIqiHDy17+6EAp1iwyaWvFx/SzCHTzvEnr3ZtQoeOQRyJszH379lTp1IDdP0MTEiG5BTJsG+9b87rwtVqsGHTqwfZubkPDCqBz45Rf3IVHGNGwI7/1wPDlUoV9BKHao+t10Mhucyj08XdAaPZBJrhuITwmZh+GF363KXuYtj4cZM+Dss8tcbqNyYQrCKDUiUL8+pF/8F5g4Ee64g+RkF1c7ut1p0LAh1dxgJzQxKeJaEOvXuyBqmxp3QBFe5aZg5qxZBAJy1P91hmtOdOxY5jI0aAD5RLOPqsHE5cshJYWktQsY/Epr7rqr6GPr1g32+3dkhtv4+WeqVoX6bAgWvOWWMpfbqFwcNia1YRTF778DxAPXFZkfUBD51ROJirAWRKNGkMYsTmAWAN34slD+q49spBurqbd+sUs4//wyl6Ghsy6xnBaczlzXF5aaCrhug5tvPvTxgdbpT3RkYuIArl/wOrWTldbZG2E7zgVA8+ZlLrdRubAWhBEWAgoir3pktSA8SwyDKWzbn0cbBtV1w0svnTKQz+lO85lvuA7iMIR9DSiI/0mdBG+95VxflIJQ8+WSHfVh926GbR7MNWd5PdWPPlpGkhqVGVMQRlgIxLTOiYuMPojdu2HVKliyBDozjWv5d6H8Lkzj662nAnAKvwAQu2d7UNOVMYGpN/XPaQrXXFNqv0iJifDss277Uy4BYFDeKK74jzdyzFoPRhlgCsIIC4EZ5dmxSRERz3r4cPfOfP2PY5lGVwDe5FqeTn0Zzj2XM7rVYVt+4SGsNbaudUNbw0C7dq6D/KWXjvwcgwa59TzaMYSnAYjL3gbt20PVqoc40jBKhikIIywETCBbTjgNVq+G9PRyl2H+fFi40A3oGTECarCDsQQ7bm/gDcZV6Q/ffENODmymLr9Tv/BJwqQgRJznlaN9j2dmunV2yBBjpkw5upMahocpCCMsBDyRzNvj+S3atKncZWjbFnqetobEs0+hCav5mmBn85bPZqFEUd/TB9OnQy4xjGRw4ZOESUGUFQHXLu9zOdu7/ckFng71I28YR4EpCCMs1K3rBuWs3FrTJWzfHvZrPvqom+8WygBeorX+wkf0oj1zAMhes4njLk7j3Xdd/3AoIxlCS5byLV7sjgoyEzmdE6j5+b8pdvKEYRwBpiCMsJGYCFvzvE/cMCuI/fvdpPX27d1+wIddrjeS+1QWAXDn5b8Rl3I8AFdeGXyfnntu8FzLacm5fOd2Fi0Kq9xlwdSpRTp2NYyjxhSEETYSEmBrTpLbCbOCCPSDqzp37AHbfDx7goVateLZ904s8vjPP4cNG+A7Ty/cyugwSlu2dOlSWMEZRllhCsIIGwkJsG2v13m6d29YrxVQEFXZS97IUciggaQxq3CI0ECc2SKIj3dxGgKxLybw5zBKaxgVA1MQRthISIDt2d4wHc8RXig//+xG8zwwLO+oTTkBBTGchxjF3dT+9wvMogPJbGOyN0+ALl0Oe57A/I1Co4IMo5Lii4IQkZoiMklElorIEhE5S0SSRWSqiKzw1rX8kM0oOxISYNsepyCyt+0lO7tw/pNPunWtJ4bCqae60GtHyC4XQI2TODgw03zakPfzPHjttcOep0qB8xmLsmMYfrUgngG+UNWTgDbAEmAYMF1VU4Hp3r5RgUlIgN+3OgUR9+BQJjT+m/Oz7n3uO3OOcg8j3AG//nrE1woon8Z19hyUd8sjKUSf3sYJdBiOVQ+8hnEklLuCEJFE4FxwEU9Udb+qbgd6QYHf4/FA7/KWzShbEhJg196gP8j+Wx51bjdmzCA/H8aNgwb8FjwgNBBDKSlQEImZfMbFhfLqdkgp8XmqVy/zECGGUWHxowXRFNgC/EtE5orIWBFJAI5X1Y0A3tq+5So4xX6wZ2Qwb57bfJp7guk5OaU6//jxBZ65CxREjbztZJFELTKDBVNSSnXewOzmTd36weOPl+pYwziW8ENBVAFOB15S1XbAbkphThKR/iIyW0Rmbwm45jQikmIVRGYmmze7zc5MD6aXQkGoQr9+kJbm9gMKInpXFpfekMR2arGQU1xiwHVqCQkoiAV3/wuGDi3VsYZxLOGHgvgN+E1VZ3r7k3AKI11E6gF4681FHayqY1Q1TVXTjrNZoxFNsQrir39l03+WcgIbqUMGs2LOcumlUBC7d7v1zp1unZ0NKawhOmMLVaJdRLhufAGTJ5faI2tsrFsfhcXLMI4Jyl1BqOomYL2ItPSSOgOLgY+Bvl5aX+Cj8pbNKFsCCmIGHVlDSqG8Tk9cWmBeSsj33vKleCMHFANAbi6sXQtdmQpA1Dku1OYGTnRBp0uJKQjDcPg1imkQMFFEFgBtgX8AjwNdRWQF0NXbNyowAQXRiR9oymri2c0wHgMglZVcz5sADEiY4AqWogURUBADeJEqMUL2c6/QlnmQmEjMjX047zx4550jkzvgRts6q43Kji8hR1V1HpBWRFbn8pbFCB8BBZGPc3iXTTxPMIy+bebTar4L2LOk0YUszDrNFTwCBfEY9wPwCv1ZffyZ0LItEiV8/fWRy33BBa6PwzAqOzaT2ggbxfVBXDZ/OADfXPU8r1zxJbn5Uc5railsOoHwElO94D8ATdNnOB/fhmGUCaYgjLAR6in7ySeD3jaWcRKCctyDdxAdDXl5uLgLpWhBrPNCL6eyonCGhdo0jDLDFxOTUTkIuNw++2y4995gemysc+4aF0dQQcSWTkFs3gxR5HEKB/hwatTo6AU3DAOwFoQRRk491c0pGD48mLZzp1viPF94QQURWyoT044dkEQW0eRzL08GM0o558EwjOKxFoQRNpKSDvbyHXCnHSAqylMQcXEc5M3vEOzcCe/GXAc5kM7x7KUq1dhnCsIwyhBrQRi+Eh3tRgxpQkJw9tthyMiA8a/so3POlwDsoyqX8glceinUqRNOcQ2jUmEtCMNXCjqy40uuIB59FK7GTXLIbdKcyWt6sIcE+LjrYY40DKM0mIIwfCWgIDQ+ATmcgli+nOxte/nnP0/jO14GYN/7n7Gn3eHdeBuGUXpMQRi+Eqog2Lb10IVbtiQOCMxh0xtvIu60VMCNkjUMo2yxPgjDVwIKIj8xyXUubNoEuH6J116DvT8tIKf/Hdx/+bKDjpXU5kRFwXPPwdy55Si0YVQSrAVh+EpAQeQ1P4mY996GevVgyxZmrKjDX/4C5yX3IyVzLo/x4sEHN2sGwMCB5SiwYVQirAVh+EpAQezrflkwccGCguGxcZm/Fyr/QWigwbPPDrN0hlG5MQVh+EpAQexv1QZ++MHtLFjgOeNTapPBE9xXUP56JlIjajfMmQMnnlju8hpGZcIUhOErgYlzWVm4FkHdurBwITt3Qiz7qUIeWSRxGy/RkRlkE09U9Xho185XuQ2jMmAKwvCVJk3cevVqL+G00+Cnn9i5Q6nOLgB2UZ2XuY2f6AgEA/oYhhFeTEEYvuL1MwcVxEUXwaJFdHmuFxm4WdG7qE7HjrB8uSsyYED5y2kYlREbxWT4Sr16LmT0gAEufsS1N/Sjyr330nzJJwVldlGd9HRITXWmqGJjXRuGUaZYC8LwlaioYIugTx8YP7n2QWW2U5MRI9x2YmLhOBOGYYQPUxCG7zz1lFu3bAkzZgoP8AgvErQjTVlYn8sv90k4w6jEmInJ8J3oaPj73+Hhh2HZMoAHAGhQI4ueO9+EBg18lc8wKivWgjAigtBRq3XruvU9yf+CX36BmjX9EcowKjmmIIyI4OSTg9s9erh1VnYstG7tj0CGYZiCMCKDFi3gmWecV9ZevVxaKQLMGYYRBkxBGBHDnXe6sNStWrl9527DMAy/MAVhRBwpKX5LYBgGmIIwIpCYGHj2WZg5029JDKNyY8NcjYhk0CC/JTAMwxcFISJrgZ1AHpCrqmkikgy8DaQAa4GrVXWbH/IZhmEY/pqYzlfVtqqa5u0PA6araiow3ds3DMMwfCKS+iB6AeO97fEQGjrMMAzDKG/8UhAKTBGRn0Wkv5d2vKpuBPDWdYs6UET6i8hsEZm9ZcuWchLXMAyj8uFXJ3UnVd0gInWBqSKytKQHquoYYAxAWlqahktAwzCMyo4vLQhV3eCtNwMfAB2AdBGpB+CtN/shm2EYhuEodwUhIgkiUiOwDVwILAI+Bvp6xfoCH5W3bIZhGEYQP0xMxwMfiEjg+m+q6hciMgt4R0RuAn4FrvJBNsMwDMNDVCuuGV9EtgDrjvDwOsDWMhTHL6wekcWxUI9joQ5g9TgUjVX1uMMVqtAK4mgQkdkhczAqLFaPyOJYqMexUAewepQFkTQPwjAMw4ggTEEYhmEYRVKZFcQYvwUoI6wekcWxUI9joQ5g9ThqKm0fhGEYhnFoKnMLwjAMwzgEpiAMwzCMIqmUCkJEuonIMhFZKSIR61ZcRBqKyNciskREfhGRv3rpySIyVURWeOtaXrqIyLNevRaIyOn+1qAwIhItInNFZLK330REZnr1eFtEYr30qt7+Si8/xU+5QxGRmiIySUSWes/lrIr4PETkbu83tUhE3hKRahXheYjIOBHZLCKLQtJKff9FpK9XfoWI9C3qWuVch6e839QCEflARGqG5N3v1WGZiFwUkh7+95iqVqoFiAZWAU2BWGA+0NpvuYqRtR5wurddA1gOtAaeBIZ56cOAJ7zt7sDngABnAjP9rsMB9RkMvAlM9vbfAa7xtkcDA7zt24HR3vY1wNt+yx5Sh/HAzd52LFCzoj0P4ERgDRAX8hz6VYTnAZwLnA4sCkkr1f0HkoHV3rqWt13L5zpcCFTxtp8IqUNr7x1VFWjivbuiy+s95vuP1Ycf2FnAlyH79wP3+y1XCWX/COgKLAPqeWn1gGXe9svAtSHlC8r5vQANcIGgLgAme3/arSF/ioLnAnwJnOVtV/HKSQTUIdF7scoB6RXqeXgKYr33gqziPY+LKsrzwEWdDH25lur+A9cCL4ekFyrnRx0OyLsMmOhtF3o/BZ5Feb3HKqOJKfDnCPCblxbReM36eB0zEwAABPNJREFUdsBMio+dEcl1GwXcB+R7+7WB7aqa6+2HylpQDy8/yyvvN02BLcC/PFPZWM/hZIV6Hqr6O/A0zufZRtz9/ZmK9zwClPb+R+RzCeFGXMsHfK5DZVQQUkRaRI/1FZHqwHvAXaq641BFi0jzvW4i0gPYrKo/hyYXUVRLkOcnVXCmgZdUtR2wm0OHxo3Ieng2+l44k0V9IAG4uIiikf48DkdxckdsfUTkASAXmBhIKqJYudWhMiqI34CGIfsNgA0+yXJYRCQGpxwmqur7XnJxsTMitW6dgJ4ishb4N87MNAqoKSIBj8KhshbUw8tPAjLLU+Bi+A34TVVnevuTcAqjoj2PLsAaVd2iqjnA+8DZVLznEaC09z8in4vXWd4DuF49uxE+16EyKohZQKo3YiMW1+n2sc8yFYmICPAqsERVR4ZkFRc742Ogjzd640wgK9D09hNVvV9VG6hqCu5+f6Wq1wNfA1d6xQ6sR6B+V3rlff/CU9VNwHoRaekldQYWU8GeB860dKaIxHu/sUA9KtTzCKG09/9L4EIRqeW1pi700nxDRLoBQ4GeqronJOtj4BpvJFkTIBX4ifJ6j5V3B1MkLLjRDctxowAe8FueQ8h5Dq7ZuACY5y3dcfbf6cAKb53slRfgBa9eC4E0v+tQRJ3OIziKqan3Y18JvAtU9dKrefsrvfymfssdIn9bYLb3TD7EjYKpcM8DeAhYigvWNQE3SibinwfwFq7fJAf3FX3Tkdx/nJ1/pbf8JQLqsBLXpxD4n48OKf+AV4dlwMUh6WF/j5mrDcMwDKNIKqOJyTAMwygBpiAMwzCMIjEFYRiGYRSJKQjDMAyjSExBGIZhGEViCsKolIhInojM8zyazheRwSJy1P8HEUkJ9dJZwmP6icjzR3ttwyhrqhy+iGEck2SralsAEamL8zKbBAz3VSrDiCCsBWFUelR1M9AfGOjNuk0Rke9EZI63nA0gIhNEpFfgOBGZKCI9izuv1zJ4X0S+8OIOPBmS9xcRWS4i3+BckQTSjxOR90Rklrd08tKfFZH/9bYvEpFvy6LFYxiHwloQhgGo6mrvhVsX58unq6ruFZFU3MzXNGAscDfwkYgk4fwXHS7YTFucF959wDIReQ7njO0hoD3OM+rXwFyv/DPAP1X1exFphHMB0QrnFHCWiHwHPAt0V9V8DCOMmIIwjCABD5kxwPMi0hbIA1oAqOo3IvKCZ5K6HHhPg+6xi2O6qmYBiMhioDFQB/iPqm7x0t8OXAPnSK+1c5EEQKKI1FDVnSJyC/AtcLeqriqD+hrGITEFYRiAiDTFKYPNuH6IdKANzgy7N6ToBOB6nHO0G0tw6n0h23kE/3PF+biJwgXnyS4i71QgA+ei2zDCjtkwjUqPiByHC7H5vDrnZEnARs+E82dceMcArwF3AajqL0d4yZnAeSJS23PnflVI3hRgYIhsgY70xsAQnLnqYhHpeITXNowSYwrCqKzEBYa5AtNwL+aHvLwXgb4iMgNn+tkdOEhV04ElwL+O9MLqXE4/CPzXu/ackOw7gTRxwesXA7eFuH2/R1U34Lx/jhWRakcqg2GUBPPmahilQETica6jTw/0LRjGsYq1IAyjhIhIF1wMhedMORiVAWtBGIZhGEViLQjDMAyjSExBGIZhGEViCsIwDMMoElMQhmEYRpGYgjAMwzCK5P8Bp+i/LBlqLhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there is a bit of randomness in the training scores in different training runs (likely due to different starting weights and which variables are dropped in dropout layers during fitting).  They seem to score about the same.  As a simpler network seems to work than our original model, we will use it (128, 128, 16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Epochs\n",
    "\n",
    "We will look at how the number of epochs affects our error.  The inbuilt fit function in Keras has a way of doing this.  We create a function to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_history(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, \n",
    "                           validation_split, model_path):\n",
    "    \n",
    "    #get train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_splitter(df, seq_length, fut_point, train_split)\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #get scalers and normalized data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler = create_scalers_and_normalize(\n",
    "        X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #create model\n",
    "    model = create_generic_LSTM_model(neurons, dropout, seq_length, features)\n",
    "    \n",
    "    #fit model\n",
    "    history = model.fit(X_train_scaled, y_train_scaled, epochs = epochs, \n",
    "              batch_size = batch_size, validation_split = validation_split, verbose = 1)\n",
    "    \n",
    "    #save model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/750\n",
      "884/884 [==============================] - 5s 5ms/step - loss: 0.0487 - acc: 0.0011 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 2/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 3/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.2213 - val_acc: 0.0000e+00\n",
      "Epoch 4/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.2124 - val_acc: 0.0000e+00\n",
      "Epoch 5/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2224 - val_acc: 0.0000e+00\n",
      "Epoch 6/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2244 - val_acc: 0.0000e+00\n",
      "Epoch 7/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2408 - val_acc: 0.0000e+00\n",
      "Epoch 8/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.2547 - val_acc: 0.0000e+00\n",
      "Epoch 9/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2304 - val_acc: 0.0000e+00\n",
      "Epoch 10/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2309 - val_acc: 0.0000e+00\n",
      "Epoch 11/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2461 - val_acc: 0.0000e+00\n",
      "Epoch 12/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2498 - val_acc: 0.0000e+00\n",
      "Epoch 13/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2729 - val_acc: 0.0000e+00\n",
      "Epoch 14/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2630 - val_acc: 0.0000e+00\n",
      "Epoch 15/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2592 - val_acc: 0.0000e+00\n",
      "Epoch 16/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2727 - val_acc: 0.0000e+00\n",
      "Epoch 17/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2791 - val_acc: 0.0000e+00\n",
      "Epoch 18/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2693 - val_acc: 0.0000e+00\n",
      "Epoch 19/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2592 - val_acc: 0.0000e+00\n",
      "Epoch 20/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
      "Epoch 21/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2408 - val_acc: 0.0000e+00\n",
      "Epoch 22/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2156 - val_acc: 0.0000e+00\n",
      "Epoch 23/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2620 - val_acc: 0.0000e+00\n",
      "Epoch 24/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 25/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2651 - val_acc: 0.0000e+00\n",
      "Epoch 26/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2717 - val_acc: 0.0000e+00\n",
      "Epoch 27/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2821 - val_acc: 0.0000e+00\n",
      "Epoch 28/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2641 - val_acc: 0.0000e+00\n",
      "Epoch 29/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2510 - val_acc: 0.0000e+00\n",
      "Epoch 30/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2411 - val_acc: 0.0000e+00\n",
      "Epoch 31/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2493 - val_acc: 0.0000e+00\n",
      "Epoch 32/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2762 - val_acc: 0.0000e+00\n",
      "Epoch 33/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2813 - val_acc: 0.0000e+00\n",
      "Epoch 34/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.3045 - val_acc: 0.0000e+00\n",
      "Epoch 35/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3061 - val_acc: 0.0000e+00\n",
      "Epoch 36/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2984 - val_acc: 0.0000e+00\n",
      "Epoch 37/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3325 - val_acc: 0.0000e+00\n",
      "Epoch 38/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3369 - val_acc: 0.0000e+00\n",
      "Epoch 39/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3085 - val_acc: 0.0000e+00\n",
      "Epoch 40/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3005 - val_acc: 0.0000e+00\n",
      "Epoch 41/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 42/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 43/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2825 - val_acc: 0.0000e+00\n",
      "Epoch 44/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2809 - val_acc: 0.0000e+00\n",
      "Epoch 45/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2990 - val_acc: 0.0000e+00\n",
      "Epoch 46/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2639 - val_acc: 0.0000e+00\n",
      "Epoch 47/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2696 - val_acc: 0.0000e+00\n",
      "Epoch 48/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2961 - val_acc: 0.0000e+00\n",
      "Epoch 49/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3205 - val_acc: 0.0000e+00\n",
      "Epoch 50/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3250 - val_acc: 0.0000e+00\n",
      "Epoch 51/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3046 - val_acc: 0.0000e+00\n",
      "Epoch 52/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2853 - val_acc: 0.0000e+00\n",
      "Epoch 53/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 54/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2927 - val_acc: 0.0000e+00\n",
      "Epoch 55/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2837 - val_acc: 0.0000e+00\n",
      "Epoch 56/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2804 - val_acc: 0.0000e+00\n",
      "Epoch 57/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2699 - val_acc: 0.0000e+00\n",
      "Epoch 58/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2654 - val_acc: 0.0000e+00\n",
      "Epoch 59/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2490 - val_acc: 0.0000e+00\n",
      "Epoch 60/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2549 - val_acc: 0.0000e+00\n",
      "Epoch 61/750\n",
      "884/884 [==============================] - 1s 943us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2659 - val_acc: 0.0000e+00\n",
      "Epoch 62/750\n",
      "884/884 [==============================] - 1s 966us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 63/750\n",
      "884/884 [==============================] - 1s 974us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3044 - val_acc: 0.0000e+00\n",
      "Epoch 64/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2723 - val_acc: 0.0000e+00\n",
      "Epoch 65/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2764 - val_acc: 0.0000e+00\n",
      "Epoch 66/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2507 - val_acc: 0.0000e+00\n",
      "Epoch 67/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2200 - val_acc: 0.0000e+00\n",
      "Epoch 68/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 69/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1894 - val_acc: 0.0000e+00\n",
      "Epoch 70/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 71/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2246 - val_acc: 0.0000e+00\n",
      "Epoch 72/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2278 - val_acc: 0.0000e+00\n",
      "Epoch 73/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2547 - val_acc: 0.0000e+00\n",
      "Epoch 74/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 75/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2426 - val_acc: 0.0000e+00\n",
      "Epoch 76/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 77/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2287 - val_acc: 0.0000e+00\n",
      "Epoch 78/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2614 - val_acc: 0.0000e+00\n",
      "Epoch 79/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2368 - val_acc: 0.0000e+00\n",
      "Epoch 80/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0000e+00\n",
      "Epoch 81/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1861 - val_acc: 0.0000e+00\n",
      "Epoch 82/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2093 - val_acc: 0.0000e+00\n",
      "Epoch 83/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2625 - val_acc: 0.0000e+00\n",
      "Epoch 84/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2902 - val_acc: 0.0000e+00\n",
      "Epoch 85/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2423 - val_acc: 0.0000e+00\n",
      "Epoch 86/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2390 - val_acc: 0.0000e+00\n",
      "Epoch 87/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2470 - val_acc: 0.0000e+00\n",
      "Epoch 88/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2572 - val_acc: 0.0000e+00\n",
      "Epoch 89/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2572 - val_acc: 0.0000e+00\n",
      "Epoch 90/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1920 - val_acc: 0.0000e+00\n",
      "Epoch 91/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1977 - val_acc: 0.0000e+00\n",
      "Epoch 92/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1989 - val_acc: 0.0000e+00\n",
      "Epoch 93/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1905 - val_acc: 0.0000e+00\n",
      "Epoch 94/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1753 - val_acc: 0.0000e+00\n",
      "Epoch 95/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 96/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1696 - val_acc: 0.0000e+00\n",
      "Epoch 97/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 98/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 99/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 100/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 101/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 102/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0808 - val_acc: 0.0000e+00\n",
      "Epoch 103/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 104/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 105/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 106/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0064\n",
      "Epoch 107/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0619 - val_acc: 0.0000e+00\n",
      "Epoch 108/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0064\n",
      "Epoch 109/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 110/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0525 - val_acc: 0.0064\n",
      "Epoch 111/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0064\n",
      "Epoch 112/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0337 - val_acc: 0.0064\n",
      "Epoch 113/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 114/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 115/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0064\n",
      "Epoch 116/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 117/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 118/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0308 - val_acc: 0.0064\n",
      "Epoch 119/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 120/750\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0064\n",
      "Epoch 121/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0238 - val_acc: 0.0064\n",
      "Epoch 122/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0250 - val_acc: 0.0064\n",
      "Epoch 123/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0064\n",
      "Epoch 124/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 125/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0064\n",
      "Epoch 126/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 127/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 128/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0308 - val_acc: 0.0064\n",
      "Epoch 129/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0064\n",
      "Epoch 130/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0212 - val_acc: 0.0064\n",
      "Epoch 131/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0200 - val_acc: 0.0064\n",
      "Epoch 132/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0220 - val_acc: 0.0064\n",
      "Epoch 133/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0191 - val_acc: 0.0064\n",
      "Epoch 134/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0203 - val_acc: 0.0064\n",
      "Epoch 135/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0214 - val_acc: 0.0064\n",
      "Epoch 136/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 137/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0228 - val_acc: 0.0064\n",
      "Epoch 138/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0217 - val_acc: 0.0064\n",
      "Epoch 139/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0064\n",
      "Epoch 140/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 141/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0064\n",
      "Epoch 142/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0490 - val_acc: 0.0064\n",
      "Epoch 143/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 144/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0064\n",
      "Epoch 145/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0064\n",
      "Epoch 146/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0064\n",
      "Epoch 147/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0064\n",
      "Epoch 148/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0064\n",
      "Epoch 149/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0064\n",
      "Epoch 150/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0064\n",
      "Epoch 151/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0922 - val_acc: 0.0064\n",
      "Epoch 152/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0064\n",
      "Epoch 153/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0064\n",
      "Epoch 154/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0064\n",
      "Epoch 155/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0064\n",
      "Epoch 156/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 157/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1311 - val_acc: 0.0064\n",
      "Epoch 158/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1266 - val_acc: 0.0064\n",
      "Epoch 159/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0268 - val_acc: 0.0064\n",
      "Epoch 160/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0243 - val_acc: 0.0064\n",
      "Epoch 161/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 162/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0064\n",
      "Epoch 163/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0209 - val_acc: 0.0064\n",
      "Epoch 164/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 165/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0064\n",
      "Epoch 166/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0064\n",
      "Epoch 167/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0064\n",
      "Epoch 168/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0252 - val_acc: 0.0064\n",
      "Epoch 169/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 170/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 171/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 172/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0238 - val_acc: 0.0064\n",
      "Epoch 173/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 174/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 175/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 176/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 177/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 178/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 179/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 180/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 181/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0246 - val_acc: 0.0064\n",
      "Epoch 182/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 183/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 184/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0064\n",
      "Epoch 185/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 186/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 187/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0064\n",
      "Epoch 188/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0064\n",
      "Epoch 189/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0458 - val_acc: 0.0000e+00\n",
      "Epoch 190/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0292 - val_acc: 0.0064\n",
      "Epoch 191/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0064\n",
      "Epoch 192/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 193/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 194/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Epoch 195/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0064\n",
      "Epoch 196/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 197/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0064\n",
      "Epoch 198/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 199/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 200/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 201/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 202/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 203/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 204/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 205/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Epoch 206/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0392 - val_acc: 0.0064\n",
      "Epoch 207/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0064\n",
      "Epoch 208/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 209/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0327 - val_acc: 0.0064\n",
      "Epoch 210/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 211/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 212/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0064\n",
      "Epoch 213/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 214/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0064\n",
      "Epoch 215/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0064\n",
      "Epoch 216/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0805 - val_acc: 0.0064\n",
      "Epoch 217/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0064\n",
      "Epoch 218/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0064\n",
      "Epoch 219/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0064\n",
      "Epoch 220/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0064\n",
      "Epoch 221/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0064\n",
      "Epoch 222/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1244 - val_acc: 0.0064\n",
      "Epoch 223/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1798 - val_acc: 0.0064\n",
      "Epoch 224/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0064\n",
      "Epoch 225/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0064\n",
      "Epoch 226/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2251 - val_acc: 0.0064\n",
      "Epoch 227/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0064\n",
      "Epoch 228/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0064\n",
      "Epoch 229/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 230/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0064\n",
      "Epoch 231/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0064\n",
      "Epoch 232/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0522 - val_acc: 0.0064\n",
      "Epoch 233/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0064\n",
      "Epoch 234/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2353 - val_acc: 0.0064\n",
      "Epoch 235/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0064\n",
      "Epoch 236/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0064\n",
      "Epoch 237/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0064\n",
      "Epoch 238/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0064\n",
      "Epoch 239/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0939 - val_acc: 0.0064\n",
      "Epoch 240/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 241/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 242/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 243/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0759 - val_acc: 0.0064\n",
      "Epoch 244/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0064\n",
      "Epoch 245/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 246/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0064\n",
      "Epoch 247/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 248/750\n",
      "884/884 [==============================] - 1s 998us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 249/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0434 - val_acc: 0.0064\n",
      "Epoch 250/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 251/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 252/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0064\n",
      "Epoch 253/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0064\n",
      "Epoch 254/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0064\n",
      "Epoch 255/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0482 - val_acc: 0.0064\n",
      "Epoch 256/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0064\n",
      "Epoch 257/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0064\n",
      "Epoch 258/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 259/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0064\n",
      "Epoch 260/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0064\n",
      "Epoch 261/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0064\n",
      "Epoch 262/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 263/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0667 - val_acc: 0.0064\n",
      "Epoch 264/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0064\n",
      "Epoch 265/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0064\n",
      "Epoch 266/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0633 - val_acc: 0.0064\n",
      "Epoch 267/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0064\n",
      "Epoch 268/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0064\n",
      "Epoch 269/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 270/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0305 - val_acc: 0.0064\n",
      "Epoch 271/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 272/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n",
      "Epoch 273/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 274/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 275/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n",
      "Epoch 276/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0064\n",
      "Epoch 277/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 278/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0064\n",
      "Epoch 279/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 280/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 281/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0551 - val_acc: 0.0064\n",
      "Epoch 282/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 283/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0064\n",
      "Epoch 284/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 285/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 286/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0853 - val_acc: 0.0064\n",
      "Epoch 287/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 288/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 289/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0064\n",
      "Epoch 290/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0064\n",
      "Epoch 291/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 292/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 293/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0609 - val_acc: 0.0064\n",
      "Epoch 294/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0064\n",
      "Epoch 295/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0064\n",
      "Epoch 296/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 297/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0064\n",
      "Epoch 298/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 299/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0064\n",
      "Epoch 301/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 302/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0064\n",
      "Epoch 303/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0064\n",
      "Epoch 304/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 305/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0478 - val_acc: 0.0064\n",
      "Epoch 306/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0064\n",
      "Epoch 307/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0064\n",
      "Epoch 308/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 309/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 310/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0517 - val_acc: 0.0064\n",
      "Epoch 311/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0572 - val_acc: 0.0064\n",
      "Epoch 312/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0064\n",
      "Epoch 313/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 314/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0064\n",
      "Epoch 315/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 316/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0064\n",
      "Epoch 317/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0064\n",
      "Epoch 318/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 319/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 320/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0064\n",
      "Epoch 321/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0064\n",
      "Epoch 322/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0360 - val_acc: 0.0064\n",
      "Epoch 323/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0064\n",
      "Epoch 324/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 325/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 326/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0064\n",
      "Epoch 327/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0490 - val_acc: 0.0064\n",
      "Epoch 328/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0064\n",
      "Epoch 329/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0337 - val_acc: 0.0064\n",
      "Epoch 330/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0351 - val_acc: 0.0064\n",
      "Epoch 331/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 332/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 333/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 334/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0064\n",
      "Epoch 335/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0064\n",
      "Epoch 336/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 337/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 338/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 339/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 340/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0064\n",
      "Epoch 341/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0064\n",
      "Epoch 342/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0447 - val_acc: 0.0064\n",
      "Epoch 343/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 344/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0064\n",
      "Epoch 345/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0064\n",
      "Epoch 346/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1022 - val_acc: 0.0064\n",
      "Epoch 347/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0064\n",
      "Epoch 348/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0611 - val_acc: 0.0064\n",
      "Epoch 349/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 350/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 351/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0064\n",
      "Epoch 352/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 353/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 354/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1487 - val_acc: 0.0064\n",
      "Epoch 355/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 356/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0429 - val_acc: 0.0064\n",
      "Epoch 357/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2296 - val_acc: 0.0064\n",
      "Epoch 358/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0631 - val_acc: 0.0064\n",
      "Epoch 359/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0064\n",
      "Epoch 360/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 361/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0064\n",
      "Epoch 362/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0064\n",
      "Epoch 363/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1088 - val_acc: 0.0064\n",
      "Epoch 364/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0852 - val_acc: 0.0064\n",
      "Epoch 365/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0875 - val_acc: 0.0064\n",
      "Epoch 366/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1504 - val_acc: 0.0064\n",
      "Epoch 367/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1716 - val_acc: 0.0064\n",
      "Epoch 368/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0064\n",
      "Epoch 369/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 370/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Epoch 371/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0064\n",
      "Epoch 372/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0064\n",
      "Epoch 373/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0737 - val_acc: 0.0064\n",
      "Epoch 374/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0064\n",
      "Epoch 375/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1004 - val_acc: 0.0064\n",
      "Epoch 376/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1087 - val_acc: 0.0064\n",
      "Epoch 377/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0720 - val_acc: 0.0064\n",
      "Epoch 378/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 379/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1000 - val_acc: 0.0064\n",
      "Epoch 380/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0596 - val_acc: 0.0064\n",
      "Epoch 381/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0064\n",
      "Epoch 382/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
      "Epoch 383/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0064\n",
      "Epoch 384/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0000e+00\n",
      "Epoch 385/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 386/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0064\n",
      "Epoch 387/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0064\n",
      "Epoch 388/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0853 - val_acc: 0.0064\n",
      "Epoch 389/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0064\n",
      "Epoch 390/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.3276 - val_acc: 0.0000e+00\n",
      "Epoch 391/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 392/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1776 - val_acc: 0.0064\n",
      "Epoch 393/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1679 - val_acc: 0.0064\n",
      "Epoch 394/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0064\n",
      "Epoch 395/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0064\n",
      "Epoch 396/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0064\n",
      "Epoch 397/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2419 - val_acc: 0.0064\n",
      "Epoch 398/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.3176 - val_acc: 0.0000e+00\n",
      "Epoch 399/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1740 - val_acc: 0.0064\n",
      "Epoch 400/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0486 - val_acc: 0.0064\n",
      "Epoch 401/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0064\n",
      "Epoch 402/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0814 - val_acc: 0.0064\n",
      "Epoch 403/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 404/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0648 - val_acc: 0.0064\n",
      "Epoch 405/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0064\n",
      "Epoch 406/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0636 - val_acc: 0.0064\n",
      "Epoch 407/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0064\n",
      "Epoch 408/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0446 - val_acc: 0.0064\n",
      "Epoch 409/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0313 - val_acc: 0.0064\n",
      "Epoch 410/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1795 - val_acc: 0.0000e+00\n",
      "Epoch 411/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Epoch 412/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 413/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0064\n",
      "Epoch 414/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 415/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 416/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 417/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 418/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 419/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0247 - val_acc: 0.0064\n",
      "Epoch 420/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0064\n",
      "Epoch 421/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0935 - val_acc: 0.0064\n",
      "Epoch 422/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0064\n",
      "Epoch 423/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 424/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0596 - val_acc: 0.0000e+00\n",
      "Epoch 425/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0064\n",
      "Epoch 426/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 427/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 428/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0064\n",
      "Epoch 429/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0064\n",
      "Epoch 430/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0064\n",
      "Epoch 431/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0064\n",
      "Epoch 432/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0064\n",
      "Epoch 433/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0064\n",
      "Epoch 434/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0948 - val_acc: 0.0064\n",
      "Epoch 435/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0064\n",
      "Epoch 436/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0064\n",
      "Epoch 437/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0064\n",
      "Epoch 438/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0510 - val_acc: 0.0064\n",
      "Epoch 439/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1250 - val_acc: 0.0064\n",
      "Epoch 440/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0064\n",
      "Epoch 441/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0064\n",
      "Epoch 442/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0064\n",
      "Epoch 443/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0064\n",
      "Epoch 444/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1813 - val_acc: 0.0064\n",
      "Epoch 445/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 446/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1294 - val_acc: 0.0064\n",
      "Epoch 447/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0064\n",
      "Epoch 448/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 449/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0064\n",
      "Epoch 450/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1571 - val_acc: 0.0064\n",
      "Epoch 451/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1130 - val_acc: 0.0064\n",
      "Epoch 452/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0064\n",
      "Epoch 453/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0064\n",
      "Epoch 454/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0064\n",
      "Epoch 455/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2252 - val_acc: 0.0064\n",
      "Epoch 456/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0064\n",
      "Epoch 457/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1601 - val_acc: 0.0064\n",
      "Epoch 458/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0064\n",
      "Epoch 459/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0064\n",
      "Epoch 460/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3171 - val_acc: 0.0000e+00\n",
      "Epoch 461/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0064\n",
      "Epoch 462/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2127 - val_acc: 0.0064\n",
      "Epoch 463/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1646 - val_acc: 0.0064\n",
      "Epoch 464/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1630 - val_acc: 0.0064\n",
      "Epoch 465/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0064\n",
      "Epoch 466/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0064\n",
      "Epoch 467/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0862 - val_acc: 0.0064\n",
      "Epoch 468/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0064\n",
      "Epoch 469/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1291 - val_acc: 0.0064\n",
      "Epoch 470/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0064\n",
      "Epoch 471/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1328 - val_acc: 0.0064\n",
      "Epoch 472/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0064\n",
      "Epoch 473/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1275 - val_acc: 0.0064\n",
      "Epoch 474/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0064\n",
      "Epoch 475/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2502 - val_acc: 0.0000e+00\n",
      "Epoch 476/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2186 - val_acc: 0.0000e+00\n",
      "Epoch 477/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0064\n",
      "Epoch 478/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0064\n",
      "Epoch 479/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0064\n",
      "Epoch 480/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 481/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0447 - val_acc: 0.0064\n",
      "Epoch 482/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0905 - val_acc: 0.0064\n",
      "Epoch 483/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0064\n",
      "Epoch 484/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0327 - val_acc: 0.0064\n",
      "Epoch 485/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0064\n",
      "Epoch 486/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0064\n",
      "Epoch 487/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0064\n",
      "Epoch 488/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0064\n",
      "Epoch 489/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0064\n",
      "Epoch 490/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2512 - val_acc: 0.0000e+00\n",
      "Epoch 491/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1758 - val_acc: 0.0064\n",
      "Epoch 492/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0064\n",
      "Epoch 493/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0240 - val_acc: 0.0064\n",
      "Epoch 494/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1926 - val_acc: 0.0064\n",
      "Epoch 495/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0064\n",
      "Epoch 496/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0064\n",
      "Epoch 497/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0064\n",
      "Epoch 498/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0064\n",
      "Epoch 499/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1595 - val_acc: 0.0064\n",
      "Epoch 500/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0064\n",
      "Epoch 501/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 502/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0064\n",
      "Epoch 503/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0064\n",
      "Epoch 504/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0064\n",
      "Epoch 505/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0064\n",
      "Epoch 506/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0523 - val_acc: 0.0064\n",
      "Epoch 507/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0064\n",
      "Epoch 508/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1311 - val_acc: 0.0064\n",
      "Epoch 509/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 510/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0064\n",
      "Epoch 511/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1239 - val_acc: 0.0064\n",
      "Epoch 512/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0064\n",
      "Epoch 513/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1281 - val_acc: 0.0064\n",
      "Epoch 514/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0664 - val_acc: 0.0064\n",
      "Epoch 515/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0853 - val_acc: 0.0064\n",
      "Epoch 516/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0064\n",
      "Epoch 517/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0064\n",
      "Epoch 518/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0064\n",
      "Epoch 519/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1194 - val_acc: 0.0064\n",
      "Epoch 520/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0064\n",
      "Epoch 521/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0889 - val_acc: 0.0064\n",
      "Epoch 522/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0064\n",
      "Epoch 523/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0064\n",
      "Epoch 524/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0816 - val_acc: 0.0064\n",
      "Epoch 525/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 526/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 527/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 528/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0617 - val_acc: 0.0064\n",
      "Epoch 529/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1284 - val_acc: 0.0064\n",
      "Epoch 530/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0064\n",
      "Epoch 531/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0518 - val_acc: 0.0064\n",
      "Epoch 532/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0380 - val_acc: 0.0064\n",
      "Epoch 533/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0064\n",
      "Epoch 534/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0064\n",
      "Epoch 535/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0064\n",
      "Epoch 536/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0064\n",
      "Epoch 537/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0064\n",
      "Epoch 538/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 539/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 540/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0064\n",
      "Epoch 542/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 543/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0410 - val_acc: 0.0064\n",
      "Epoch 544/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0064\n",
      "Epoch 545/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0064\n",
      "Epoch 546/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0064\n",
      "Epoch 547/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0064\n",
      "Epoch 548/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0064\n",
      "Epoch 549/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1083 - val_acc: 0.0064\n",
      "Epoch 550/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0064\n",
      "Epoch 551/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0064\n",
      "Epoch 552/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0064\n",
      "Epoch 553/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1098 - val_acc: 0.0064\n",
      "Epoch 554/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0923 - val_acc: 0.0064\n",
      "Epoch 555/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 556/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0064\n",
      "Epoch 557/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0064\n",
      "Epoch 558/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0579 - val_acc: 0.0064\n",
      "Epoch 559/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0064\n",
      "Epoch 560/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0064\n",
      "Epoch 561/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 562/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0612 - val_acc: 0.0064\n",
      "Epoch 563/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 564/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 565/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 566/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0064\n",
      "Epoch 567/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0995 - val_acc: 0.0064\n",
      "Epoch 568/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0699 - val_acc: 0.0064\n",
      "Epoch 569/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0658 - val_acc: 0.0064\n",
      "Epoch 570/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0558 - val_acc: 0.0064\n",
      "Epoch 571/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0064\n",
      "Epoch 572/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 573/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0524 - val_acc: 0.0064\n",
      "Epoch 574/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0064\n",
      "Epoch 575/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0695 - val_acc: 0.0064\n",
      "Epoch 576/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 577/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0064\n",
      "Epoch 578/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 579/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0556 - val_acc: 0.0064\n",
      "Epoch 580/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0258 - val_acc: 0.0064\n",
      "Epoch 581/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 582/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0238 - val_acc: 0.0064\n",
      "Epoch 583/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0521 - val_acc: 0.0064\n",
      "Epoch 584/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0697 - val_acc: 0.0064\n",
      "Epoch 585/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0579 - val_acc: 0.0064\n",
      "Epoch 586/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 587/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0064\n",
      "Epoch 588/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0815 - val_acc: 0.0064\n",
      "Epoch 589/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0611 - val_acc: 0.0064\n",
      "Epoch 590/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0624 - val_acc: 0.0064\n",
      "Epoch 591/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0501 - val_acc: 0.0064\n",
      "Epoch 592/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0064\n",
      "Epoch 593/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 594/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0064\n",
      "Epoch 595/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0064\n",
      "Epoch 596/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0064\n",
      "Epoch 597/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0064\n",
      "Epoch 598/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0064\n",
      "Epoch 599/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0601 - val_acc: 0.0064\n",
      "Epoch 600/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0064\n",
      "Epoch 601/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0064\n",
      "Epoch 602/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0064\n",
      "Epoch 603/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1342 - val_acc: 0.0064\n",
      "Epoch 604/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0064\n",
      "Epoch 605/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0585 - val_acc: 0.0064\n",
      "Epoch 606/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0612 - val_acc: 0.0064\n",
      "Epoch 607/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 608/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0064\n",
      "Epoch 609/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 610/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0064\n",
      "Epoch 611/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 612/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0588 - val_acc: 0.0064\n",
      "Epoch 613/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0064\n",
      "Epoch 614/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 615/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0064\n",
      "Epoch 616/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 617/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0064\n",
      "Epoch 618/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 619/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 620/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0064\n",
      "Epoch 621/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1102 - val_acc: 0.0000e+00\n",
      "Epoch 622/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 623/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0064\n",
      "Epoch 624/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0064\n",
      "Epoch 625/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0064\n",
      "Epoch 626/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0972 - val_acc: 0.0064\n",
      "Epoch 627/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0064\n",
      "Epoch 628/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.2032 - val_acc: 0.0064\n",
      "Epoch 629/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0064\n",
      "Epoch 630/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0064\n",
      "Epoch 631/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 632/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0064\n",
      "Epoch 633/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0064\n",
      "Epoch 634/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1091 - val_acc: 0.0064\n",
      "Epoch 635/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.2292 - val_acc: 0.0000e+00\n",
      "Epoch 636/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0412 - val_acc: 0.0064\n",
      "Epoch 637/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0618 - val_acc: 0.0064\n",
      "Epoch 638/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 639/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 640/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 641/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0064\n",
      "Epoch 642/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.2109 - val_acc: 0.0000e+00\n",
      "Epoch 643/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 644/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 645/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 646/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 647/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8981e-04 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 648/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0000e+00\n",
      "Epoch 649/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0000e+00\n",
      "Epoch 650/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 651/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 652/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 653/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0064\n",
      "Epoch 654/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0064\n",
      "Epoch 655/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0064\n",
      "Epoch 656/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0565 - val_acc: 0.0064\n",
      "Epoch 657/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0064\n",
      "Epoch 658/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0064\n",
      "Epoch 659/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0064\n",
      "Epoch 660/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
      "Epoch 661/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0514 - val_acc: 0.0064\n",
      "Epoch 662/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
      "Epoch 663/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 664/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 665/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0965 - val_acc: 0.0064\n",
      "Epoch 666/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0064\n",
      "Epoch 667/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0895 - val_acc: 0.0000e+00\n",
      "Epoch 668/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 669/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1710 - val_acc: 0.0000e+00\n",
      "Epoch 670/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0985 - val_acc: 0.0000e+00\n",
      "Epoch 671/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0992 - val_acc: 0.0000e+00\n",
      "Epoch 672/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 673/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0000e+00\n",
      "Epoch 674/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.6144e-04 - acc: 0.0011 - val_loss: 0.1211 - val_acc: 0.0000e+00\n",
      "Epoch 675/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.2095 - val_acc: 0.0000e+00\n",
      "Epoch 676/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.2117 - val_acc: 0.0000e+00\n",
      "Epoch 677/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1923 - val_acc: 0.0000e+00\n",
      "Epoch 678/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1525 - val_acc: 0.0000e+00\n",
      "Epoch 679/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.3842e-04 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0064\n",
      "Epoch 680/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2786e-04 - acc: 0.0011 - val_loss: 0.0878 - val_acc: 0.0000e+00\n",
      "Epoch 681/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.2281 - val_acc: 0.0000e+00\n",
      "Epoch 682/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1905 - val_acc: 0.0000e+00\n",
      "Epoch 683/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8407e-04 - acc: 0.0011 - val_loss: 0.1899 - val_acc: 0.0000e+00\n",
      "Epoch 684/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.9047e-04 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
      "Epoch 685/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2445e-04 - acc: 0.0011 - val_loss: 0.2294 - val_acc: 0.0000e+00\n",
      "Epoch 686/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0064\n",
      "Epoch 687/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 688/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 689/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.0328e-04 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 690/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.4178e-04 - acc: 0.0011 - val_loss: 0.1798 - val_acc: 0.0000e+00\n",
      "Epoch 691/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.4521e-04 - acc: 0.0011 - val_loss: 0.1883 - val_acc: 0.0000e+00\n",
      "Epoch 692/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9814e-04 - acc: 0.0011 - val_loss: 0.2263 - val_acc: 0.0000e+00\n",
      "Epoch 693/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1625 - val_acc: 0.0000e+00\n",
      "Epoch 694/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0064\n",
      "Epoch 695/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.9964e-04 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0064\n",
      "Epoch 696/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.7760e-04 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0000e+00\n",
      "Epoch 697/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.5698e-04 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0064\n",
      "Epoch 698/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.7964e-04 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0064\n",
      "Epoch 699/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8366e-04 - acc: 0.0011 - val_loss: 0.2153 - val_acc: 0.0000e+00\n",
      "Epoch 700/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 701/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.5448e-04 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 702/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9695e-04 - acc: 0.0011 - val_loss: 0.1200 - val_acc: 0.0000e+00\n",
      "Epoch 703/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.3115e-04 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
      "Epoch 704/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.7888e-04 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0064\n",
      "Epoch 705/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8490e-04 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 706/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9015e-04 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 707/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8740e-04 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 708/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.9509e-04 - acc: 0.0011 - val_loss: 0.0856 - val_acc: 0.0000e+00\n",
      "Epoch 709/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.6185e-04 - acc: 0.0011 - val_loss: 0.2212 - val_acc: 0.0000e+00\n",
      "Epoch 710/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0064\n",
      "Epoch 711/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8333e-04 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0064\n",
      "Epoch 712/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.1888e-04 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
      "Epoch 713/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2312e-04 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0000e+00\n",
      "Epoch 714/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4068e-04 - acc: 0.0011 - val_loss: 0.1299 - val_acc: 0.0000e+00\n",
      "Epoch 715/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.2691e-04 - acc: 0.0011 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 716/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.6039e-04 - acc: 0.0011 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 717/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.8021e-04 - acc: 0.0011 - val_loss: 0.0808 - val_acc: 0.0064\n",
      "Epoch 718/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.0035e-04 - acc: 0.0011 - val_loss: 0.0575 - val_acc: 0.0064\n",
      "Epoch 719/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5192e-04 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 720/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.0503e-04 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0064\n",
      "Epoch 721/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.1417e-04 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0064\n",
      "Epoch 722/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.7059e-04 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0064\n",
      "Epoch 723/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.3322e-04 - acc: 0.0011 - val_loss: 0.1928 - val_acc: 0.0000e+00\n",
      "Epoch 724/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8498e-04 - acc: 0.0011 - val_loss: 0.2225 - val_acc: 0.0000e+00\n",
      "Epoch 725/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.7481e-04 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 726/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.9699e-04 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 727/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.7096e-04 - acc: 0.0011 - val_loss: 0.2337 - val_acc: 0.0000e+00\n",
      "Epoch 728/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.5755e-04 - acc: 0.0011 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 729/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2755e-04 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 730/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9105e-04 - acc: 0.0011 - val_loss: 0.1551 - val_acc: 0.0000e+00\n",
      "Epoch 731/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4742e-04 - acc: 0.0011 - val_loss: 0.2728 - val_acc: 0.0000e+00\n",
      "Epoch 732/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5589e-04 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 733/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5149e-04 - acc: 0.0011 - val_loss: 0.1208 - val_acc: 0.0000e+00\n",
      "Epoch 734/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.5401e-04 - acc: 0.0011 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
      "Epoch 735/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.6362e-04 - acc: 0.0011 - val_loss: 0.1990 - val_acc: 0.0000e+00\n",
      "Epoch 736/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5525e-04 - acc: 0.0011 - val_loss: 0.2068 - val_acc: 0.0000e+00\n",
      "Epoch 737/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.1232e-04 - acc: 0.0011 - val_loss: 0.1245 - val_acc: 0.0000e+00\n",
      "Epoch 738/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.6138e-04 - acc: 0.0011 - val_loss: 0.2785 - val_acc: 0.0000e+00\n",
      "Epoch 739/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4701e-04 - acc: 0.0011 - val_loss: 0.1460 - val_acc: 0.0000e+00\n",
      "Epoch 740/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8677e-04 - acc: 0.0011 - val_loss: 0.2767 - val_acc: 0.0000e+00\n",
      "Epoch 741/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.3100e-04 - acc: 0.0011 - val_loss: 0.2556 - val_acc: 0.0000e+00\n",
      "Epoch 742/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.9881e-04 - acc: 0.0011 - val_loss: 0.2026 - val_acc: 0.0000e+00\n",
      "Epoch 743/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.9943e-04 - acc: 0.0011 - val_loss: 0.2111 - val_acc: 0.0000e+00\n",
      "Epoch 744/750\n",
      "884/884 [==============================] - 1s 998us/step - loss: 8.4887e-04 - acc: 0.0011 - val_loss: 0.2149 - val_acc: 0.0000e+00\n",
      "Epoch 745/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.1897e-04 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 746/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.2436 - val_acc: 0.0000e+00\n",
      "Epoch 747/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 748/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8291e-04 - acc: 0.0011 - val_loss: 0.2478 - val_acc: 0.0000e+00\n",
      "Epoch 749/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8625e-04 - acc: 0.0011 - val_loss: 0.2457 - val_acc: 0.0000e+00\n",
      "Epoch 750/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4249e-04 - acc: 0.0011 - val_loss: 0.2507 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#do so\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 750\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'epoch_test.h5'\n",
    "history = see_history(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, validation_split,\n",
    "                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.21773967786859244,\n",
       "  0.2040790221056877,\n",
       "  0.22132996956889445,\n",
       "  0.21240177932075965,\n",
       "  0.2223886466370179,\n",
       "  0.22437996913989386,\n",
       "  0.24079938614979768,\n",
       "  0.2546698502623118,\n",
       "  0.23038051009942323,\n",
       "  0.2308641295784559,\n",
       "  0.24606414750600472,\n",
       "  0.24976456375458303,\n",
       "  0.27292584092953265,\n",
       "  0.2629669033564054,\n",
       "  0.2592347495448895,\n",
       "  0.27268831584698117,\n",
       "  0.2791194201279909,\n",
       "  0.26932291992199725,\n",
       "  0.2592453255485266,\n",
       "  0.24635906995106965,\n",
       "  0.2407879168406511,\n",
       "  0.2156013117577785,\n",
       "  0.26200704677746844,\n",
       "  0.29046001380834824,\n",
       "  0.26513622567439693,\n",
       "  0.27171278324646825,\n",
       "  0.28213503670233947,\n",
       "  0.2641317162376184,\n",
       "  0.2509617331700447,\n",
       "  0.24109248320261636,\n",
       "  0.2492522929723446,\n",
       "  0.27621900939788574,\n",
       "  0.28133344592956394,\n",
       "  0.3044768877518483,\n",
       "  0.30608795487727875,\n",
       "  0.29841735252203083,\n",
       "  0.3325141666409297,\n",
       "  0.3369232662595235,\n",
       "  0.3085466865927745,\n",
       "  0.30053871545272,\n",
       "  0.29048702388237685,\n",
       "  0.28513279136938924,\n",
       "  0.2825379404119956,\n",
       "  0.2809236962825824,\n",
       "  0.298991658557684,\n",
       "  0.2638520118899835,\n",
       "  0.2695878490041464,\n",
       "  0.296056044789461,\n",
       "  0.3205490251764273,\n",
       "  0.32498846623377925,\n",
       "  0.30456874557794666,\n",
       "  0.285302266287498,\n",
       "  0.29236612889247066,\n",
       "  0.2927302853801312,\n",
       "  0.2837032245901915,\n",
       "  0.28040547305956864,\n",
       "  0.26988356293011934,\n",
       "  0.26535299745125646,\n",
       "  0.2490237136490834,\n",
       "  0.25489834762918645,\n",
       "  0.26590692691313916,\n",
       "  0.2800975888967514,\n",
       "  0.30442478507757187,\n",
       "  0.27228513474647814,\n",
       "  0.27644309057639194,\n",
       "  0.25073397780458134,\n",
       "  0.2200302599141231,\n",
       "  0.20414514237871537,\n",
       "  0.18935077312665108,\n",
       "  0.2070402949093244,\n",
       "  0.22462464773502105,\n",
       "  0.22778031487877554,\n",
       "  0.2547214545118503,\n",
       "  0.2706220243603755,\n",
       "  0.24263946654704902,\n",
       "  0.21014025788276625,\n",
       "  0.22868265775151742,\n",
       "  0.26135082905873275,\n",
       "  0.23676186924179396,\n",
       "  0.17391583543175307,\n",
       "  0.1860732576594903,\n",
       "  0.20927433526286712,\n",
       "  0.2624668845763573,\n",
       "  0.2902399257589609,\n",
       "  0.24230532329051924,\n",
       "  0.2389742486560956,\n",
       "  0.24696859048727232,\n",
       "  0.2571670737786171,\n",
       "  0.2571620125419054,\n",
       "  0.19199943074431175,\n",
       "  0.19769963660301307,\n",
       "  0.19894849337064302,\n",
       "  0.19053507338349635,\n",
       "  0.17529467741648355,\n",
       "  0.1463657234532711,\n",
       "  0.16962145975767037,\n",
       "  0.1254235538534629,\n",
       "  0.09913737718493511,\n",
       "  0.12248845073657158,\n",
       "  0.11858456171093842,\n",
       "  0.08739605899422596,\n",
       "  0.08077840635982844,\n",
       "  0.08037397026633605,\n",
       "  0.08479933784558223,\n",
       "  0.06797701650514053,\n",
       "  0.04690207775013569,\n",
       "  0.06185063117971787,\n",
       "  0.043983601606809176,\n",
       "  0.042631383603199936,\n",
       "  0.05251030671672943,\n",
       "  0.050630503214704685,\n",
       "  0.033686268859757826,\n",
       "  0.042040991716277905,\n",
       "  0.03256679784196118,\n",
       "  0.03966395236933843,\n",
       "  0.03541062858242255,\n",
       "  0.02793747243972925,\n",
       "  0.030793169919305887,\n",
       "  0.03535431924347694,\n",
       "  0.02718501466398056,\n",
       "  0.023785947523533534,\n",
       "  0.02496870185654515,\n",
       "  0.038379865913436964,\n",
       "  0.031148844541838534,\n",
       "  0.03764598458432234,\n",
       "  0.054292042763569415,\n",
       "  0.02986823593099148,\n",
       "  0.030845567249716856,\n",
       "  0.02725625611268557,\n",
       "  0.02119299614181121,\n",
       "  0.019964760318637278,\n",
       "  0.02198022621898697,\n",
       "  0.019139170091455944,\n",
       "  0.02031320152589335,\n",
       "  0.02143512629211331,\n",
       "  0.022988847128521554,\n",
       "  0.022845440185987033,\n",
       "  0.021688605312449045,\n",
       "  0.03254200644695606,\n",
       "  0.044401345643191,\n",
       "  0.06904701969753473,\n",
       "  0.04902646713890135,\n",
       "  0.04785852586755004,\n",
       "  0.08483548498211,\n",
       "  0.09269595790940982,\n",
       "  0.0906207670386021,\n",
       "  0.1018763206517085,\n",
       "  0.08634224383590314,\n",
       "  0.13103921014146927,\n",
       "  0.08350161792567143,\n",
       "  0.09217153164820793,\n",
       "  0.09055773240442459,\n",
       "  0.09291042167788897,\n",
       "  0.09195678146221699,\n",
       "  0.11655936686274333,\n",
       "  0.07396987825632095,\n",
       "  0.13106398991285226,\n",
       "  0.12661282164164078,\n",
       "  0.026847208205323953,\n",
       "  0.024342430325654838,\n",
       "  0.022973444587431658,\n",
       "  0.03437572445433874,\n",
       "  0.020870009150642615,\n",
       "  0.029983969420218505,\n",
       "  0.028088180204996697,\n",
       "  0.023929101797059562,\n",
       "  0.045568702169335805,\n",
       "  0.025161140729697086,\n",
       "  0.029614553661443867,\n",
       "  0.03533399776101877,\n",
       "  0.027775314278327502,\n",
       "  0.023808856345474336,\n",
       "  0.026138981368440468,\n",
       "  0.04150448273867369,\n",
       "  0.08012834377586842,\n",
       "  0.03230716661812785,\n",
       "  0.03214682451186654,\n",
       "  0.06753305746958806,\n",
       "  0.0537026665913753,\n",
       "  0.03471090415349373,\n",
       "  0.02458154351916164,\n",
       "  0.03196269310175035,\n",
       "  0.038075149178695984,\n",
       "  0.027174182009333983,\n",
       "  0.0368879960778241,\n",
       "  0.027370740617744815,\n",
       "  0.03060771194167244,\n",
       "  0.038275330154320754,\n",
       "  0.04575790810542038,\n",
       "  0.02917799750008644,\n",
       "  0.029343157714137282,\n",
       "  0.03574128546274434,\n",
       "  0.037243018225313,\n",
       "  0.038070992805445805,\n",
       "  0.04022858217836191,\n",
       "  0.03298251740992642,\n",
       "  0.033484485848114275,\n",
       "  0.035714336581384905,\n",
       "  0.031047210551034182,\n",
       "  0.03848744480488583,\n",
       "  0.03321384403926249,\n",
       "  0.03534654911177663,\n",
       "  0.029845739792411525,\n",
       "  0.04110163841874172,\n",
       "  0.04526920472749342,\n",
       "  0.03918192088484573,\n",
       "  0.068018882535398,\n",
       "  0.04109079892842624,\n",
       "  0.03269289168290412,\n",
       "  0.03740630195571635,\n",
       "  0.03544855426447705,\n",
       "  0.03334549058061571,\n",
       "  0.044428964551442705,\n",
       "  0.08422487670890032,\n",
       "  0.09371287449716757,\n",
       "  0.0804708725354897,\n",
       "  0.05485280881373164,\n",
       "  0.08312752591565442,\n",
       "  0.07014023073805639,\n",
       "  0.04678733248072557,\n",
       "  0.08443027583715053,\n",
       "  0.12441478378306596,\n",
       "  0.17980177867680025,\n",
       "  0.1302503309188745,\n",
       "  0.1730529515980146,\n",
       "  0.22506423495136774,\n",
       "  0.11689342477191718,\n",
       "  0.05590399138581676,\n",
       "  0.033162158752719946,\n",
       "  0.056764943686385565,\n",
       "  0.09284857445611404,\n",
       "  0.052215630224404425,\n",
       "  0.07118716946420953,\n",
       "  0.23525988950561255,\n",
       "  0.06714133861570214,\n",
       "  0.07265697336660172,\n",
       "  0.07828007875464092,\n",
       "  0.11345930290050231,\n",
       "  0.09394628933081642,\n",
       "  0.039145895232183814,\n",
       "  0.04171127712545104,\n",
       "  0.03738911081559192,\n",
       "  0.07594771517249636,\n",
       "  0.07597199343861295,\n",
       "  0.0480658055927891,\n",
       "  0.04281592465793857,\n",
       "  0.03303138450838816,\n",
       "  0.03361925567524173,\n",
       "  0.04340786819991011,\n",
       "  0.03468471600745733,\n",
       "  0.037242333142039105,\n",
       "  0.04019603092605487,\n",
       "  0.11063733030683719,\n",
       "  0.05352619903472563,\n",
       "  0.04824128908176835,\n",
       "  0.09892054960036124,\n",
       "  0.05997907366149892,\n",
       "  0.05970514693464606,\n",
       "  0.07441400321654211,\n",
       "  0.08594287945650136,\n",
       "  0.08130809966212091,\n",
       "  0.04948130214157013,\n",
       "  0.0666720217678887,\n",
       "  0.07211592043630588,\n",
       "  0.05426359496031625,\n",
       "  0.06334618401403229,\n",
       "  0.04065114020919188,\n",
       "  0.03695004576076873,\n",
       "  0.03321962447789235,\n",
       "  0.030459993853209875,\n",
       "  0.03636936788471081,\n",
       "  0.04635667353152083,\n",
       "  0.04170886554325429,\n",
       "  0.04062526997847435,\n",
       "  0.04075809255337868,\n",
       "  0.05471915560655105,\n",
       "  0.06847627631699045,\n",
       "  0.04832056545628569,\n",
       "  0.03665348439692305,\n",
       "  0.03674174287619117,\n",
       "  0.05509696365931095,\n",
       "  0.047491677571088076,\n",
       "  0.05375134458359426,\n",
       "  0.04810933734720143,\n",
       "  0.04748346180153581,\n",
       "  0.08533622806844039,\n",
       "  0.04745308020247672,\n",
       "  0.04814938866557219,\n",
       "  0.0637190200221271,\n",
       "  0.05415795653915176,\n",
       "  0.042950923584449366,\n",
       "  0.06400160526092617,\n",
       "  0.060897341021933615,\n",
       "  0.05051073325702395,\n",
       "  0.058256169816908926,\n",
       "  0.04355449833644506,\n",
       "  0.08119238541724208,\n",
       "  0.06909609058847985,\n",
       "  0.040842940421918265,\n",
       "  0.05630783394026833,\n",
       "  0.046257376682777435,\n",
       "  0.08647502111032224,\n",
       "  0.08449696872431116,\n",
       "  0.06647669600967604,\n",
       "  0.04782192797686618,\n",
       "  0.046165982189659886,\n",
       "  0.04373833965151929,\n",
       "  0.04790021837927783,\n",
       "  0.037210934228287675,\n",
       "  0.05165850981855048,\n",
       "  0.0571784751656919,\n",
       "  0.07452102767255826,\n",
       "  0.04658508616595123,\n",
       "  0.05820390890137507,\n",
       "  0.06218558106905757,\n",
       "  0.038946138062060646,\n",
       "  0.05542309551189343,\n",
       "  0.03774533548559516,\n",
       "  0.04810736063891687,\n",
       "  0.053827560399300776,\n",
       "  0.05544524710291089,\n",
       "  0.03604578887088559,\n",
       "  0.06084193548378654,\n",
       "  0.04632877201462785,\n",
       "  0.07395696437034087,\n",
       "  0.043263617891054124,\n",
       "  0.049040114208578296,\n",
       "  0.032035182373454936,\n",
       "  0.03369702327733812,\n",
       "  0.03506870702123986,\n",
       "  0.0419698992314247,\n",
       "  0.048746232313509934,\n",
       "  0.041272741802132286,\n",
       "  0.049157037471349425,\n",
       "  0.07247554756796513,\n",
       "  0.04505788171902681,\n",
       "  0.0415782715456608,\n",
       "  0.04271102540242749,\n",
       "  0.03907701290714053,\n",
       "  0.049870839748436056,\n",
       "  0.06759816316816096,\n",
       "  0.04473045657579906,\n",
       "  0.04110706408914083,\n",
       "  0.0835979893648376,\n",
       "  0.07723467038848843,\n",
       "  0.10220622531592082,\n",
       "  0.07849688929481766,\n",
       "  0.06105176328370968,\n",
       "  0.04165385737537573,\n",
       "  0.06845360885684688,\n",
       "  0.03225256199351488,\n",
       "  0.04438654487379468,\n",
       "  0.06720891691004045,\n",
       "  0.14867044458738887,\n",
       "  0.04220190247258124,\n",
       "  0.04286573540705901,\n",
       "  0.22962551599798295,\n",
       "  0.06305348208078589,\n",
       "  0.08827459383517122,\n",
       "  0.06716876668043625,\n",
       "  0.08793429144395468,\n",
       "  0.053048903994166695,\n",
       "  0.10884978306981233,\n",
       "  0.08515850427106787,\n",
       "  0.0874977585596916,\n",
       "  0.15044391842988822,\n",
       "  0.1715943556613265,\n",
       "  0.13832762910244176,\n",
       "  0.04092615198057432,\n",
       "  0.04530837919372015,\n",
       "  0.054795220446510196,\n",
       "  0.06317643054689352,\n",
       "  0.0737002015961573,\n",
       "  0.04024709079366846,\n",
       "  0.10036420638267046,\n",
       "  0.1087498274894479,\n",
       "  0.07203435446493901,\n",
       "  0.041747706870620065,\n",
       "  0.10002328665592732,\n",
       "  0.05956543473383555,\n",
       "  0.11846271778146426,\n",
       "  0.05097441418239704,\n",
       "  0.08585448405490471,\n",
       "  0.04949490231676744,\n",
       "  0.041605027010425545,\n",
       "  0.06816726068082528,\n",
       "  0.11687137038470843,\n",
       "  0.08528033018303223,\n",
       "  0.1118079613512143,\n",
       "  0.3275867477298165,\n",
       "  0.07965151163247916,\n",
       "  0.177631971008407,\n",
       "  0.16786368701081628,\n",
       "  0.1509242779455888,\n",
       "  0.07785355075238606,\n",
       "  0.1495959313156513,\n",
       "  0.2418600083925785,\n",
       "  0.3176341448695614,\n",
       "  0.1740175117380344,\n",
       "  0.04857801684202292,\n",
       "  0.035913038664521314,\n",
       "  0.08139130984170315,\n",
       "  0.07324832902313808,\n",
       "  0.06482694312356986,\n",
       "  0.05891210153603401,\n",
       "  0.06360597378359391,\n",
       "  0.043261573840983406,\n",
       "  0.044638095471339345,\n",
       "  0.031324307147700056,\n",
       "  0.17953273482047594,\n",
       "  0.11345658542062992,\n",
       "  0.03174011153765978,\n",
       "  0.05085409671450273,\n",
       "  0.04761587570493038,\n",
       "  0.06195234106137203,\n",
       "  0.09783595248770255,\n",
       "  0.029527995210045423,\n",
       "  0.04005643577338793,\n",
       "  0.024739055392833855,\n",
       "  0.04448064342618753,\n",
       "  0.09349822383135176,\n",
       "  0.1052715342778426,\n",
       "  0.06696338736667083,\n",
       "  0.05963281957575908,\n",
       "  0.06280012213839935,\n",
       "  0.049558694737079814,\n",
       "  0.04370044883436117,\n",
       "  0.07437413544035874,\n",
       "  0.0878888480604077,\n",
       "  0.07732026333896777,\n",
       "  0.08237463412567592,\n",
       "  0.09151921889338738,\n",
       "  0.07110204795996349,\n",
       "  0.09477412519164574,\n",
       "  0.12292837342008567,\n",
       "  0.09258536860728875,\n",
       "  0.10512815005122086,\n",
       "  0.05096000041335057,\n",
       "  0.12500391910091424,\n",
       "  0.07124946118356326,\n",
       "  0.10854583916564782,\n",
       "  0.0848804441973185,\n",
       "  0.1252327484007065,\n",
       "  0.18129411893777359,\n",
       "  0.09911301302222106,\n",
       "  0.12943206565120283,\n",
       "  0.06601017035352878,\n",
       "  0.07751443437658824,\n",
       "  0.14496003129543403,\n",
       "  0.15705501020718843,\n",
       "  0.11303659175068904,\n",
       "  0.06691453687082498,\n",
       "  0.10341471194838867,\n",
       "  0.17385931867055404,\n",
       "  0.22520024463152274,\n",
       "  0.09804405176486725,\n",
       "  0.16010413557673112,\n",
       "  0.09435156599069253,\n",
       "  0.09335262137345779,\n",
       "  0.317084092933398,\n",
       "  0.134793629631018,\n",
       "  0.21266698971008643,\n",
       "  0.16460132694397217,\n",
       "  0.16301138412493926,\n",
       "  0.05682023318532186,\n",
       "  0.08925561692852241,\n",
       "  0.08623720915653767,\n",
       "  0.14737822268253717,\n",
       "  0.12905956747440192,\n",
       "  0.07143174766156918,\n",
       "  0.13283253298738065,\n",
       "  0.10289551222171539,\n",
       "  0.12750020690071276,\n",
       "  0.15695738047361374,\n",
       "  0.25024604682738966,\n",
       "  0.21857057760159174,\n",
       "  0.13493104374561554,\n",
       "  0.15357873741632852,\n",
       "  0.08065512442053893,\n",
       "  0.048062010548817806,\n",
       "  0.0446759989628425,\n",
       "  0.09054393025162892,\n",
       "  0.14635795526779616,\n",
       "  0.03267868856588999,\n",
       "  0.08590424142013757,\n",
       "  0.10589049288477653,\n",
       "  0.09865796704513904,\n",
       "  0.11452321321345292,\n",
       "  0.16543453559279442,\n",
       "  0.25123543158555645,\n",
       "  0.17584050628237236,\n",
       "  0.08581693690174665,\n",
       "  0.024023829863812678,\n",
       "  0.19258932129312784,\n",
       "  0.07782019894474591,\n",
       "  0.11149079075608498,\n",
       "  0.10092809567084679,\n",
       "  0.14015760592734203,\n",
       "  0.15947031592711425,\n",
       "  0.1272136689378665,\n",
       "  0.04058675661396522,\n",
       "  0.11113717485792361,\n",
       "  0.07833720609927788,\n",
       "  0.15280809860007885,\n",
       "  0.026512114737087335,\n",
       "  0.05227477977482172,\n",
       "  0.11790200618979259,\n",
       "  0.1311264892992301,\n",
       "  0.05768469544366384,\n",
       "  0.14997583522628516,\n",
       "  0.12392233436306317,\n",
       "  0.08577734246276893,\n",
       "  0.128062419879895,\n",
       "  0.06641867181333976,\n",
       "  0.08530527152694188,\n",
       "  0.08030476538130106,\n",
       "  0.14011437273942506,\n",
       "  0.05907582398504019,\n",
       "  0.11941236653962196,\n",
       "  0.07951810946449256,\n",
       "  0.088902019823973,\n",
       "  0.07885777052396382,\n",
       "  0.13482470710117084,\n",
       "  0.08163791274031003,\n",
       "  0.04296970190719152,\n",
       "  0.07315184008807708,\n",
       "  0.044396812812640116,\n",
       "  0.061712659656619415,\n",
       "  0.12842222093007502,\n",
       "  0.11376915893589075,\n",
       "  0.05182161961849301,\n",
       "  0.03801566997590738,\n",
       "  0.10093501176780616,\n",
       "  0.0949764767040809,\n",
       "  0.05085891765805009,\n",
       "  0.06439263397493424,\n",
       "  0.07126743322572647,\n",
       "  0.04274831213152561,\n",
       "  0.10726331283027928,\n",
       "  0.06610928100939745,\n",
       "  0.0570916844627414,\n",
       "  0.04842624145870408,\n",
       "  0.04096502298489213,\n",
       "  0.08768342547596265,\n",
       "  0.07207589238308944,\n",
       "  0.09037427053762934,\n",
       "  0.07835569939552209,\n",
       "  0.09988682549924423,\n",
       "  0.10828137552986543,\n",
       "  0.11540600067625444,\n",
       "  0.1033427873865152,\n",
       "  0.08182261891376513,\n",
       "  0.1098464300067952,\n",
       "  0.09229934067489245,\n",
       "  0.0740330396220088,\n",
       "  0.08062873396258323,\n",
       "  0.08211801671542418,\n",
       "  0.05790154067560648,\n",
       "  0.07453025762851422,\n",
       "  0.05275155934027563,\n",
       "  0.047642737424048856,\n",
       "  0.06116273399824516,\n",
       "  0.07084208774643067,\n",
       "  0.06486401993494767,\n",
       "  0.057040645908086725,\n",
       "  0.046200817689681664,\n",
       "  0.09952317608090547,\n",
       "  0.06989200150546356,\n",
       "  0.06579487516473119,\n",
       "  0.05579398610653021,\n",
       "  0.0897455195394846,\n",
       "  0.11819264407341297,\n",
       "  0.052386011116397686,\n",
       "  0.04386208239847269,\n",
       "  0.0695169808772894,\n",
       "  0.0672383978485297,\n",
       "  0.05907831773257408,\n",
       "  0.04218637620886931,\n",
       "  0.055613454622335926,\n",
       "  0.025813605803518724,\n",
       "  0.04049293501063799,\n",
       "  0.023813839118259076,\n",
       "  0.05208049069803495,\n",
       "  0.06974992385277382,\n",
       "  0.05790141637986287,\n",
       "  0.041297840575377144,\n",
       "  0.09669611187508473,\n",
       "  0.081474899338224,\n",
       "  0.06113945038463825,\n",
       "  0.06237813250090067,\n",
       "  0.05012309594223133,\n",
       "  0.03992902891089519,\n",
       "  0.03721204586327076,\n",
       "  0.04140477761244162,\n",
       "  0.04982214573866282,\n",
       "  0.07538049018535858,\n",
       "  0.05822108447169646,\n",
       "  0.06272092337409656,\n",
       "  0.060097236592227064,\n",
       "  0.06725353611489901,\n",
       "  0.056342886904111274,\n",
       "  0.09841596311292587,\n",
       "  0.13421734484533468,\n",
       "  0.11059255219804935,\n",
       "  0.058453926434501625,\n",
       "  0.06120221239204208,\n",
       "  0.07749135613154906,\n",
       "  0.10478757828091964,\n",
       "  0.04047074708610009,\n",
       "  0.09378258926937214,\n",
       "  0.07296582662428801,\n",
       "  0.058849464337795206,\n",
       "  0.07099764994703807,\n",
       "  0.0775050498927251,\n",
       "  0.08309580314044769,\n",
       "  0.1354571003228044,\n",
       "  0.08805038151928248,\n",
       "  0.16349251931294417,\n",
       "  0.11194181511512934,\n",
       "  0.08583503536497936,\n",
       "  0.11015751131643088,\n",
       "  0.04510166013661104,\n",
       "  0.07609409858018924,\n",
       "  0.06498970100894952,\n",
       "  0.1282381037584482,\n",
       "  0.0972141780389043,\n",
       "  0.11252926184962957,\n",
       "  0.2032374419654027,\n",
       "  0.07886501458974984,\n",
       "  0.10501048993319273,\n",
       "  0.041962964090112694,\n",
       "  0.10582130913359997,\n",
       "  0.08028915806267506,\n",
       "  0.10913548367814375,\n",
       "  0.22923634277704436,\n",
       "  0.04121918147668625,\n",
       "  0.0618070929000775,\n",
       "  0.057658017660753846,\n",
       "  0.09368912849384241,\n",
       "  0.1269650486512826,\n",
       "  0.08918030985081807,\n",
       "  0.21093640395273,\n",
       "  0.183357192012362,\n",
       "  0.13864373883757836,\n",
       "  0.14325992486033684,\n",
       "  0.14447533769103196,\n",
       "  0.11051712677073784,\n",
       "  0.09731999703515799,\n",
       "  0.06292723219555157,\n",
       "  0.0622305774058287,\n",
       "  0.09399747318373276,\n",
       "  0.11150816288322975,\n",
       "  0.0594219411126314,\n",
       "  0.09880498987741959,\n",
       "  0.06381663360083714,\n",
       "  0.05647817344810718,\n",
       "  0.04933190386360272,\n",
       "  0.07169419230941014,\n",
       "  0.07560890062879293,\n",
       "  0.14530494021108517,\n",
       "  0.05143964376587134,\n",
       "  0.12506690544959825,\n",
       "  0.14049363403748244,\n",
       "  0.13052302130903953,\n",
       "  0.09654235371794456,\n",
       "  0.06734664628329949,\n",
       "  0.08946517320015492,\n",
       "  0.07074183072799291,\n",
       "  0.17101671847586447,\n",
       "  0.0985160570543928,\n",
       "  0.09917662498087455,\n",
       "  0.09499473695476086,\n",
       "  0.1046058473487695,\n",
       "  0.1210560058362973,\n",
       "  0.20947699793256247,\n",
       "  0.21174133483033913,\n",
       "  0.19229963183020934,\n",
       "  0.15249636019460666,\n",
       "  0.09269466518591611,\n",
       "  0.08779519414290404,\n",
       "  0.22806212903024295,\n",
       "  0.19045211670872492,\n",
       "  0.1898876189803466,\n",
       "  0.09278055251790927,\n",
       "  0.22943047161858815,\n",
       "  0.04587198793888092,\n",
       "  0.07076545916975309,\n",
       "  0.04045278813021305,\n",
       "  0.0417318857060029,\n",
       "  0.17978698430726162,\n",
       "  0.18826958369941282,\n",
       "  0.22634701306621233,\n",
       "  0.16250884661880824,\n",
       "  0.09245519750775436,\n",
       "  0.05380521442454595,\n",
       "  0.0892981699643991,\n",
       "  0.06301817890161122,\n",
       "  0.08664832875514641,\n",
       "  0.2152708190947007,\n",
       "  0.1202244758605957,\n",
       "  0.16433875692578462,\n",
       "  0.1199647452777777,\n",
       "  0.10328814692986317,\n",
       "  0.05830444247485735,\n",
       "  0.13578140788162366,\n",
       "  0.18428967234033805,\n",
       "  0.14698701695753977,\n",
       "  0.08555590891494201,\n",
       "  0.22117648961452338,\n",
       "  0.0812305587893113,\n",
       "  0.054016211428321324,\n",
       "  0.0779338361074527,\n",
       "  0.09792421729518817,\n",
       "  0.129850034816907,\n",
       "  0.12481112190737174,\n",
       "  0.12062722778855225,\n",
       "  0.0808310581323428,\n",
       "  0.057538363915414385,\n",
       "  0.11334367000903839,\n",
       "  0.0937147779772297,\n",
       "  0.07734281027641816,\n",
       "  0.07272511266936095,\n",
       "  0.19277872804265755,\n",
       "  0.22246330613509202,\n",
       "  0.08606421211973214,\n",
       "  0.12704597814724997,\n",
       "  0.2336750203409256,\n",
       "  0.14882193095026872,\n",
       "  0.20746504066464228,\n",
       "  0.1551330971221129,\n",
       "  0.2728346685568492,\n",
       "  0.11248227853614551,\n",
       "  0.12081643795737854,\n",
       "  0.164761343684334,\n",
       "  0.19897276425781923,\n",
       "  0.20681180480198982,\n",
       "  0.12446101563863265,\n",
       "  0.27850608661388737,\n",
       "  0.1460061832689322,\n",
       "  0.27669583786374485,\n",
       "  0.25560439301606935,\n",
       "  0.20260522810694498,\n",
       "  0.21106693435173768,\n",
       "  0.2149251111998008,\n",
       "  0.20753050010460308,\n",
       "  0.24358563831983468,\n",
       "  0.18335827401815316,\n",
       "  0.24779249689517877,\n",
       "  0.2456943860802895,\n",
       "  0.2507116932135362],\n",
       " 'val_acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'loss': [0.04865558694087272,\n",
       "  0.010815827340325889,\n",
       "  0.007631163707011426,\n",
       "  0.006586509175194065,\n",
       "  0.006235843083960304,\n",
       "  0.006176610074819348,\n",
       "  0.005959122317392227,\n",
       "  0.006303942551608809,\n",
       "  0.0061936873133500775,\n",
       "  0.005975651394626404,\n",
       "  0.0056071177870877995,\n",
       "  0.005778091074688132,\n",
       "  0.005918484463512358,\n",
       "  0.005785123318669753,\n",
       "  0.005550741028394634,\n",
       "  0.005298383201038406,\n",
       "  0.005302979513935374,\n",
       "  0.005261640119201997,\n",
       "  0.005229902849848723,\n",
       "  0.005207403200547889,\n",
       "  0.005054967703373588,\n",
       "  0.005205648180046772,\n",
       "  0.004946514310913658,\n",
       "  0.005425102448267904,\n",
       "  0.005348737808829384,\n",
       "  0.005198238004521547,\n",
       "  0.004933994472009968,\n",
       "  0.005131647637644909,\n",
       "  0.004832836394767146,\n",
       "  0.005002683626985118,\n",
       "  0.00474068181530248,\n",
       "  0.004829950761302834,\n",
       "  0.004891402606443582,\n",
       "  0.004896175137371229,\n",
       "  0.004563891503757616,\n",
       "  0.005070578713576853,\n",
       "  0.0047928295266810314,\n",
       "  0.004748525815421707,\n",
       "  0.004713191492778009,\n",
       "  0.004724177609859413,\n",
       "  0.00493054762609067,\n",
       "  0.004624265467335061,\n",
       "  0.004508516578450462,\n",
       "  0.004416013545276622,\n",
       "  0.004871519861902991,\n",
       "  0.004745487479821724,\n",
       "  0.004724029953090044,\n",
       "  0.004561625129218757,\n",
       "  0.004773808320840964,\n",
       "  0.004644825325528691,\n",
       "  0.0046496469468485175,\n",
       "  0.004781218146593457,\n",
       "  0.004338196234364585,\n",
       "  0.004729462966609459,\n",
       "  0.0046659826819376166,\n",
       "  0.004498369880104901,\n",
       "  0.004521128567719486,\n",
       "  0.004750409452202498,\n",
       "  0.005002947201809058,\n",
       "  0.00473054904676131,\n",
       "  0.004489023265812327,\n",
       "  0.004625062511947293,\n",
       "  0.00442318521372603,\n",
       "  0.0046475686067588865,\n",
       "  0.004312615127332205,\n",
       "  0.004333646093575259,\n",
       "  0.0043124472300998225,\n",
       "  0.004814620174012438,\n",
       "  0.004642279163356955,\n",
       "  0.004646122400813243,\n",
       "  0.00404057834440699,\n",
       "  0.004166018582324232,\n",
       "  0.0043316068932650045,\n",
       "  0.004347648140784707,\n",
       "  0.004754158213094079,\n",
       "  0.004671937630119906,\n",
       "  0.004288028963584436,\n",
       "  0.004134407285938031,\n",
       "  0.004345187184093225,\n",
       "  0.004351860818314067,\n",
       "  0.004816947028681433,\n",
       "  0.004250237478019155,\n",
       "  0.004372760297401863,\n",
       "  0.004280004235262649,\n",
       "  0.00421720127495031,\n",
       "  0.004202892455984564,\n",
       "  0.004212680626744868,\n",
       "  0.004346944976437887,\n",
       "  0.004386331896588409,\n",
       "  0.00444829669186837,\n",
       "  0.0043271671447532075,\n",
       "  0.004327441989212419,\n",
       "  0.0042216389911982535,\n",
       "  0.004138192129258185,\n",
       "  0.004351135050431231,\n",
       "  0.004348762793786723,\n",
       "  0.004024604118399625,\n",
       "  0.004220370977602865,\n",
       "  0.004408691708436783,\n",
       "  0.0040814093023336315,\n",
       "  0.004067911649527391,\n",
       "  0.004166833472720503,\n",
       "  0.004119336664069832,\n",
       "  0.003990673516957064,\n",
       "  0.004009870995611492,\n",
       "  0.0039449380036460325,\n",
       "  0.0041779501814546895,\n",
       "  0.004179052193122347,\n",
       "  0.003955753979471205,\n",
       "  0.004068821050201404,\n",
       "  0.004064993112141528,\n",
       "  0.004183540892960057,\n",
       "  0.0041481356359849685,\n",
       "  0.0040223472414546695,\n",
       "  0.004057151823814503,\n",
       "  0.004023247358401841,\n",
       "  0.004017481437096229,\n",
       "  0.0040173342249175,\n",
       "  0.004221882140137492,\n",
       "  0.003975091749650523,\n",
       "  0.0041169947639057135,\n",
       "  0.0038234389248004864,\n",
       "  0.004061721663551228,\n",
       "  0.004343257519538721,\n",
       "  0.004273276984674763,\n",
       "  0.004021605701139407,\n",
       "  0.004057608386796659,\n",
       "  0.0040379873396854055,\n",
       "  0.0039056344231700197,\n",
       "  0.0037486222709583886,\n",
       "  0.003976117859581882,\n",
       "  0.003991349218876788,\n",
       "  0.0038839598434947734,\n",
       "  0.003754363071839262,\n",
       "  0.003916395377216026,\n",
       "  0.003849170404608568,\n",
       "  0.003798944136018262,\n",
       "  0.004085437610652719,\n",
       "  0.003942987857369613,\n",
       "  0.003936193193355365,\n",
       "  0.003897603851957963,\n",
       "  0.0038737640379005157,\n",
       "  0.003768889629598117,\n",
       "  0.0037058627420437956,\n",
       "  0.0037451924322114,\n",
       "  0.0037280120718297107,\n",
       "  0.004237469719781865,\n",
       "  0.0038241174733645504,\n",
       "  0.0038731038250130224,\n",
       "  0.0037182936996929517,\n",
       "  0.0038194730172009623,\n",
       "  0.004044465101176527,\n",
       "  0.003693037183862601,\n",
       "  0.0036157722863035774,\n",
       "  0.0037796754954694625,\n",
       "  0.003689244451692404,\n",
       "  0.0038559229757923344,\n",
       "  0.0035605039257910185,\n",
       "  0.0036485946244176697,\n",
       "  0.0035752030510910497,\n",
       "  0.003716241636806551,\n",
       "  0.0038375826573580907,\n",
       "  0.003968256106389459,\n",
       "  0.003910729119014754,\n",
       "  0.0035164548964892847,\n",
       "  0.0037180734208334086,\n",
       "  0.0035778120332882147,\n",
       "  0.003807088914348394,\n",
       "  0.0036695994799155994,\n",
       "  0.0036996076309134787,\n",
       "  0.0038492976281185092,\n",
       "  0.0036236620897941323,\n",
       "  0.0037288209781623804,\n",
       "  0.00358576811133669,\n",
       "  0.003937254350093021,\n",
       "  0.0036712110051000282,\n",
       "  0.0037773973203150397,\n",
       "  0.003811416488005969,\n",
       "  0.003725823778785529,\n",
       "  0.0036633435133170355,\n",
       "  0.003871944031311511,\n",
       "  0.0034221748956289495,\n",
       "  0.0035769791527739746,\n",
       "  0.003457790102632674,\n",
       "  0.0035635948189580604,\n",
       "  0.0033964735763442463,\n",
       "  0.003720206754256832,\n",
       "  0.0036001822034664012,\n",
       "  0.003725545746337504,\n",
       "  0.003472248793946267,\n",
       "  0.0033697700085817957,\n",
       "  0.0034864931261984473,\n",
       "  0.0036427566393940156,\n",
       "  0.0036062650757576276,\n",
       "  0.003336547688492553,\n",
       "  0.0033910534780775933,\n",
       "  0.00342143644321693,\n",
       "  0.0036924687346940803,\n",
       "  0.0034794333829161,\n",
       "  0.0035870066987207304,\n",
       "  0.003288627971949823,\n",
       "  0.003510608899352305,\n",
       "  0.003457134192371193,\n",
       "  0.0035769044731351718,\n",
       "  0.0033937160729544395,\n",
       "  0.003474509132798441,\n",
       "  0.0033267571599269077,\n",
       "  0.0033833079958730692,\n",
       "  0.0032539786792010472,\n",
       "  0.0033956483939906997,\n",
       "  0.0034448373293697967,\n",
       "  0.0032296861475544277,\n",
       "  0.0032721079898602014,\n",
       "  0.003463052345937059,\n",
       "  0.003382958332708788,\n",
       "  0.003363788932797866,\n",
       "  0.0033258975175845676,\n",
       "  0.003319546514995632,\n",
       "  0.0035807255895732486,\n",
       "  0.003422670136943325,\n",
       "  0.0034749045413897724,\n",
       "  0.003450672546764035,\n",
       "  0.0033325962048040797,\n",
       "  0.003379264646272988,\n",
       "  0.0033537169499112066,\n",
       "  0.0034965419145174563,\n",
       "  0.0031860667634839657,\n",
       "  0.003317730459152843,\n",
       "  0.003185710168076991,\n",
       "  0.0033025982772838746,\n",
       "  0.003446030818195634,\n",
       "  0.0035656817822097655,\n",
       "  0.0033426421780847182,\n",
       "  0.0033519635676528534,\n",
       "  0.003186674653742108,\n",
       "  0.0031817839881278813,\n",
       "  0.003345041552651252,\n",
       "  0.003475449566320596,\n",
       "  0.0032987258127338474,\n",
       "  0.003451782353517359,\n",
       "  0.0032935282995089957,\n",
       "  0.0034010115762270685,\n",
       "  0.003359007790297,\n",
       "  0.003301895076063424,\n",
       "  0.003275115972140391,\n",
       "  0.0032424015357534136,\n",
       "  0.003126183557387323,\n",
       "  0.003307767386223733,\n",
       "  0.00326949351559903,\n",
       "  0.003149498123422737,\n",
       "  0.0031727565245964137,\n",
       "  0.0031595941573988257,\n",
       "  0.003571316791588769,\n",
       "  0.003284197469764469,\n",
       "  0.003214118456493271,\n",
       "  0.0031758944579817323,\n",
       "  0.0032360967021115225,\n",
       "  0.0031730645447885153,\n",
       "  0.003107629733252849,\n",
       "  0.0032101986040593005,\n",
       "  0.003435690381576842,\n",
       "  0.003144922723142405,\n",
       "  0.0031260811319212298,\n",
       "  0.0031009626962514216,\n",
       "  0.0031266074714027515,\n",
       "  0.0032174439028293165,\n",
       "  0.0033245607641656204,\n",
       "  0.003388366320621374,\n",
       "  0.003366680572449959,\n",
       "  0.003417663385762888,\n",
       "  0.003238125856991065,\n",
       "  0.003087971306814732,\n",
       "  0.003411856523137624,\n",
       "  0.0031024880762047626,\n",
       "  0.0032588897496293305,\n",
       "  0.0032241847587336377,\n",
       "  0.003205306926000509,\n",
       "  0.003394726651185508,\n",
       "  0.0032706388611582473,\n",
       "  0.0031674779199350337,\n",
       "  0.003094631712883711,\n",
       "  0.0031327923514345045,\n",
       "  0.0031770047145933586,\n",
       "  0.0031570965072300235,\n",
       "  0.0032754873201605015,\n",
       "  0.003266251495327143,\n",
       "  0.003154202270620751,\n",
       "  0.0031265961511979276,\n",
       "  0.003174596281755901,\n",
       "  0.00317992977861197,\n",
       "  0.0031963700335894234,\n",
       "  0.003242521838609517,\n",
       "  0.0030846859705613346,\n",
       "  0.0032513899353598308,\n",
       "  0.0031426037531093235,\n",
       "  0.0031790848046001807,\n",
       "  0.0032141377961861467,\n",
       "  0.0032614367909737907,\n",
       "  0.003083322337318667,\n",
       "  0.0031045422524770055,\n",
       "  0.00322439642496643,\n",
       "  0.0031433340132539897,\n",
       "  0.0031450759067423472,\n",
       "  0.003056626693172827,\n",
       "  0.0031059463971981364,\n",
       "  0.0029966154944876472,\n",
       "  0.0032847666569323832,\n",
       "  0.0032393174515657837,\n",
       "  0.0030234852685630995,\n",
       "  0.003158915287507403,\n",
       "  0.002994842216271351,\n",
       "  0.0031397193722949445,\n",
       "  0.0032469879738919066,\n",
       "  0.003019599241891463,\n",
       "  0.0030651211093824645,\n",
       "  0.0031575462938922697,\n",
       "  0.00320660958500638,\n",
       "  0.0031379783037223967,\n",
       "  0.0031172224505892974,\n",
       "  0.0030877096241348468,\n",
       "  0.0030663954905272204,\n",
       "  0.0031633238367129507,\n",
       "  0.003053093384909212,\n",
       "  0.0028915798177782497,\n",
       "  0.002960646461813428,\n",
       "  0.0029490909789903806,\n",
       "  0.0030743367148234565,\n",
       "  0.003058799891205867,\n",
       "  0.0032997131400332867,\n",
       "  0.0027663257548256833,\n",
       "  0.0030534054158988717,\n",
       "  0.0030581869524208263,\n",
       "  0.002922607988237121,\n",
       "  0.0029701757944311223,\n",
       "  0.0028382088073499803,\n",
       "  0.002966363887972624,\n",
       "  0.002925786895601593,\n",
       "  0.0031460023967641916,\n",
       "  0.002981970752526193,\n",
       "  0.003024795140051262,\n",
       "  0.0035304599315164045,\n",
       "  0.0031119727559084267,\n",
       "  0.003083676078706575,\n",
       "  0.003019728434453318,\n",
       "  0.0028530436892450126,\n",
       "  0.0029036046134316407,\n",
       "  0.00281859245530553,\n",
       "  0.003069436226073838,\n",
       "  0.0029173887374798232,\n",
       "  0.003163598833934349,\n",
       "  0.0031488160413112574,\n",
       "  0.0030709534190274876,\n",
       "  0.0030363201536659605,\n",
       "  0.0029820482630063504,\n",
       "  0.003100031133471436,\n",
       "  0.0030032355165555734,\n",
       "  0.0029597267902527866,\n",
       "  0.002928895030878653,\n",
       "  0.0028435292546279156,\n",
       "  0.002883431741365177,\n",
       "  0.0029396103648679558,\n",
       "  0.0030674276235028762,\n",
       "  0.0030205088090235832,\n",
       "  0.0027594491375854653,\n",
       "  0.0028530093514659693,\n",
       "  0.0028830714422653165,\n",
       "  0.002848368694339942,\n",
       "  0.0029532138565850205,\n",
       "  0.0033103995050442706,\n",
       "  0.0031098529277158674,\n",
       "  0.0030532505982702944,\n",
       "  0.0028852050411788854,\n",
       "  0.002890648381422143,\n",
       "  0.0029596635972769145,\n",
       "  0.0029391920440556374,\n",
       "  0.002971486222184352,\n",
       "  0.003020278957769342,\n",
       "  0.00305476988353914,\n",
       "  0.0030169024667386557,\n",
       "  0.0029032086222369343,\n",
       "  0.0028452799946271996,\n",
       "  0.0029879284830873504,\n",
       "  0.002974630378785109,\n",
       "  0.003005594086761658,\n",
       "  0.0029007437474587385,\n",
       "  0.0030001505610967112,\n",
       "  0.0030280949391964062,\n",
       "  0.002805775939592274,\n",
       "  0.002839686374319085,\n",
       "  0.002859199185733477,\n",
       "  0.002738393766266121,\n",
       "  0.0027587383851720806,\n",
       "  0.0029442185753054614,\n",
       "  0.002626689111948755,\n",
       "  0.0029363569769822904,\n",
       "  0.002773689245173025,\n",
       "  0.002942209689334305,\n",
       "  0.00262024770680461,\n",
       "  0.0026726540055850784,\n",
       "  0.0027062529155445114,\n",
       "  0.0026230682056329773,\n",
       "  0.0028113788762867318,\n",
       "  0.002770331816756213,\n",
       "  0.0027069425962578794,\n",
       "  0.0026482489308746896,\n",
       "  0.002830844473650013,\n",
       "  0.00275345105673629,\n",
       "  0.002787033274529578,\n",
       "  0.0027292041230221947,\n",
       "  0.0028435134990520065,\n",
       "  0.0030115772991091416,\n",
       "  0.0028925258813771457,\n",
       "  0.0029155353707897716,\n",
       "  0.002913925057167516,\n",
       "  0.0026013553721990386,\n",
       "  0.002874879211785769,\n",
       "  0.00284220035739951,\n",
       "  0.002647684217005024,\n",
       "  0.0027622862105843573,\n",
       "  0.0025641074698055963,\n",
       "  0.002524693982203689,\n",
       "  0.0027751794223972847,\n",
       "  0.002693724568840538,\n",
       "  0.002589973739066005,\n",
       "  0.0024892279174499113,\n",
       "  0.0025167139647402107,\n",
       "  0.0026610182931149436,\n",
       "  0.002575025179452891,\n",
       "  0.0025227095971802646,\n",
       "  0.0023058143010303983,\n",
       "  0.002645633396233234,\n",
       "  0.0024996706552179826,\n",
       "  0.0024434666442200203,\n",
       "  0.0024474488836776346,\n",
       "  0.0024986572677429715,\n",
       "  0.002413535200910668,\n",
       "  0.0023639341710952884,\n",
       "  0.0024696940722626665,\n",
       "  0.0026361108894514687,\n",
       "  0.0024421236833886187,\n",
       "  0.0024459533165820044,\n",
       "  0.002237477250253925,\n",
       "  0.002454315481825449,\n",
       "  0.002512144610681887,\n",
       "  0.00258949348319541,\n",
       "  0.0023420403028808837,\n",
       "  0.0026519054413153644,\n",
       "  0.002626907769422051,\n",
       "  0.0023903828988702993,\n",
       "  0.002509419068828967,\n",
       "  0.002596831665589259,\n",
       "  0.002480001241491256,\n",
       "  0.0024316743937030233,\n",
       "  0.00238886044352269,\n",
       "  0.0027284127537885944,\n",
       "  0.0026556683569404875,\n",
       "  0.002507960679835526,\n",
       "  0.0023428089790282205,\n",
       "  0.0022893334987543826,\n",
       "  0.002375285264433307,\n",
       "  0.002278582373111429,\n",
       "  0.0025015719881812237,\n",
       "  0.0022293688203692775,\n",
       "  0.002119410010813251,\n",
       "  0.0021589343558272083,\n",
       "  0.002304482638279642,\n",
       "  0.0024452931079086406,\n",
       "  0.002488740585002694,\n",
       "  0.0024818300519231285,\n",
       "  0.002364624511846657,\n",
       "  0.002373542086689046,\n",
       "  0.00223174637996874,\n",
       "  0.002240980047167898,\n",
       "  0.0024001242706712285,\n",
       "  0.002295247685771048,\n",
       "  0.002245771899351606,\n",
       "  0.0024323466073772216,\n",
       "  0.002241139395512236,\n",
       "  0.002200476170993701,\n",
       "  0.0021436108293104495,\n",
       "  0.002084289502027988,\n",
       "  0.0020515687318046773,\n",
       "  0.002051561897013724,\n",
       "  0.00209035400756344,\n",
       "  0.001912794414616919,\n",
       "  0.001976879724992515,\n",
       "  0.0020321292615162706,\n",
       "  0.0019062894430196932,\n",
       "  0.0019666210509103415,\n",
       "  0.002167662914328243,\n",
       "  0.0021130122408709105,\n",
       "  0.0021117984794493242,\n",
       "  0.00210528569380285,\n",
       "  0.002307924238661498,\n",
       "  0.002178504666928792,\n",
       "  0.002036625702709499,\n",
       "  0.001980047529179822,\n",
       "  0.00209581568875093,\n",
       "  0.002402251362969163,\n",
       "  0.0020545501777126845,\n",
       "  0.002112919966188761,\n",
       "  0.0020045164721803023,\n",
       "  0.0020293057780308285,\n",
       "  0.0019612831149958244,\n",
       "  0.0019065465944570518,\n",
       "  0.001828537256208278,\n",
       "  0.0018587210436869935,\n",
       "  0.0020474214823200153,\n",
       "  0.0019435225448642785,\n",
       "  0.002121551720872184,\n",
       "  0.0019896390502303165,\n",
       "  0.0021126296621962236,\n",
       "  0.0018453063655063104,\n",
       "  0.001867881686873397,\n",
       "  0.0018094310308364116,\n",
       "  0.001764221227521338,\n",
       "  0.0017325993167969706,\n",
       "  0.0017867446676891178,\n",
       "  0.0017864191504321756,\n",
       "  0.0016723534664375144,\n",
       "  0.0017790914865050515,\n",
       "  0.001802121962281576,\n",
       "  0.0018630119691691383,\n",
       "  0.0018384790314546874,\n",
       "  0.0019300795545826805,\n",
       "  0.001796847168246613,\n",
       "  0.0019210934258651882,\n",
       "  0.0017976003732717684,\n",
       "  0.0018284772607030102,\n",
       "  0.0017384375704713672,\n",
       "  0.0017176796913956085,\n",
       "  0.0017111645869244884,\n",
       "  0.001644765619479322,\n",
       "  0.001640724472288565,\n",
       "  0.001782584873795071,\n",
       "  0.0016565866524994172,\n",
       "  0.0016257225299291986,\n",
       "  0.001706586494869068,\n",
       "  0.0015936149384329155,\n",
       "  0.0017794170227255757,\n",
       "  0.001772649397618428,\n",
       "  0.0016879472893144413,\n",
       "  0.0017848246998461259,\n",
       "  0.001810158200970771,\n",
       "  0.0018685696987915633,\n",
       "  0.0018299301502577186,\n",
       "  0.0015224117424330627,\n",
       "  0.00155641624758787,\n",
       "  0.0016510357155266526,\n",
       "  0.0015730607129498574,\n",
       "  0.0015674610158672969,\n",
       "  0.0016106382524383959,\n",
       "  0.001726436625736264,\n",
       "  0.0017691035707569703,\n",
       "  0.0017920059359493366,\n",
       "  0.0017293106461137668,\n",
       "  0.0016329647689779622,\n",
       "  0.0016405382109342388,\n",
       "  0.0015642056202124046,\n",
       "  0.0015045178093319564,\n",
       "  0.0016705206852423119,\n",
       "  0.0017040000335056319,\n",
       "  0.0017457280426003813,\n",
       "  0.0013929882057314544,\n",
       "  0.0015879028378796187,\n",
       "  0.0015115122330834356,\n",
       "  0.001522128332229289,\n",
       "  0.0016493502002403275,\n",
       "  0.0015953169583566317,\n",
       "  0.0015089038350699444,\n",
       "  0.0015882154298752411,\n",
       "  0.0016399258784570508,\n",
       "  0.0016075238412692806,\n",
       "  0.0016413609490927932,\n",
       "  0.0017393970613397355,\n",
       "  0.0014734442621823485,\n",
       "  0.0013975147911183098,\n",
       "  0.0014238476582562627,\n",
       "  0.0015143037797900008,\n",
       "  0.0016271896761467014,\n",
       "  0.001473460819496356,\n",
       "  0.0015329365308788432,\n",
       "  0.00146907154466468,\n",
       "  0.0014147363609436276,\n",
       "  0.0014931539055676414,\n",
       "  0.0014578145554676922,\n",
       "  0.0014656973692980422,\n",
       "  0.0014370251415356387,\n",
       "  0.0013812946569705508,\n",
       "  0.0014561193914055758,\n",
       "  0.0014704278653394852,\n",
       "  0.0013535887490730412,\n",
       "  0.0013514185356970757,\n",
       "  0.0014234807371789784,\n",
       "  0.0013763168774022642,\n",
       "  0.0014217126528770405,\n",
       "  0.001314111456919748,\n",
       "  0.0013030416667208547,\n",
       "  0.0015199213790205808,\n",
       "  0.001345886505415402,\n",
       "  0.0012534748656439227,\n",
       "  0.0013297758806850846,\n",
       "  0.0013725420642366035,\n",
       "  0.0013240865725134732,\n",
       "  0.0013308869798591874,\n",
       "  0.0012548105586825857,\n",
       "  0.0012598628782966423,\n",
       "  0.001443995488386146,\n",
       "  0.0013993576651531781,\n",
       "  0.0013011338097586958,\n",
       "  0.0012767254622501418,\n",
       "  0.001310781501992121,\n",
       "  0.0012371344123103096,\n",
       "  0.001185754559274628,\n",
       "  0.0013048390318466797,\n",
       "  0.001287928879328443,\n",
       "  0.001353673199170619,\n",
       "  0.0013047829075459375,\n",
       "  0.0012873568096960898,\n",
       "  0.001269351777924031,\n",
       "  0.0012524866828762366,\n",
       "  0.0014718245536855916,\n",
       "  0.0012355171306252615,\n",
       "  0.001148995796399722,\n",
       "  0.001186575346027935,\n",
       "  0.001285838404126735,\n",
       "  0.001322731928271979,\n",
       "  0.0011605589489380901,\n",
       "  0.0011667267775491757,\n",
       "  0.001040410478515087,\n",
       "  0.0010724193000390587,\n",
       "  0.0012598124754665697,\n",
       "  0.0011764216743519202,\n",
       "  0.0012969480626226079,\n",
       "  0.001209160898774188,\n",
       "  0.0012295160593245836,\n",
       "  0.0011881994846281152,\n",
       "  0.001097214091105631,\n",
       "  0.0011452494762791531,\n",
       "  0.0012902300657358914,\n",
       "  0.0012484477712810713,\n",
       "  0.0011644862055972354,\n",
       "  0.0011276286300819587,\n",
       "  0.0010525910636806244,\n",
       "  0.0011355981238110504,\n",
       "  0.0011600528762578898,\n",
       "  0.0009898074161960866,\n",
       "  0.001126911957870444,\n",
       "  0.001162941624490519,\n",
       "  0.0011807919355589745,\n",
       "  0.0011761647694411253,\n",
       "  0.0011712183071747085,\n",
       "  0.0012036666992579785,\n",
       "  0.001092476579592441,\n",
       "  0.0012188238013805441,\n",
       "  0.0011666797220546803,\n",
       "  0.0011606856483157,\n",
       "  0.0011664073929038927,\n",
       "  0.001155096058295492,\n",
       "  0.0011872400021880056,\n",
       "  0.0012285763021701803,\n",
       "  0.0011881856280442208,\n",
       "  0.0011550739241081261,\n",
       "  0.0011155398473527063,\n",
       "  0.0011051205293448195,\n",
       "  0.0011660829028409666,\n",
       "  0.0012275137410739361,\n",
       "  0.001122831221042007,\n",
       "  0.0010188283415603961,\n",
       "  0.001077404168562972,\n",
       "  0.0011875635683030834,\n",
       "  0.0010902236328498203,\n",
       "  0.0010083801069874232,\n",
       "  0.0009614378303432694,\n",
       "  0.0010181669942819728,\n",
       "  0.0010582774538310808,\n",
       "  0.0010240531955293603,\n",
       "  0.0010234717937076792,\n",
       "  0.0009384196400705607,\n",
       "  0.0009278574630795089,\n",
       "  0.0010055194501406872,\n",
       "  0.001128449837721429,\n",
       "  0.0009840650790017013,\n",
       "  0.000990468055764171,\n",
       "  0.0009244506677182821,\n",
       "  0.0011171862510416437,\n",
       "  0.0010475974674315541,\n",
       "  0.001101677602039001,\n",
       "  0.0009032834581482937,\n",
       "  0.0009417835579831068,\n",
       "  0.0009452141826652091,\n",
       "  0.0008981396640098877,\n",
       "  0.0010833771576961647,\n",
       "  0.00107476267936256,\n",
       "  0.0009996401893008686,\n",
       "  0.000977596813260801,\n",
       "  0.0009569832038479895,\n",
       "  0.0009796358228817044,\n",
       "  0.0008836565710439839,\n",
       "  0.0010236216291818953,\n",
       "  0.000954477384589545,\n",
       "  0.000896953511193007,\n",
       "  0.0008311538261201283,\n",
       "  0.0008788759445105742,\n",
       "  0.0009848969078272987,\n",
       "  0.0008901470876509552,\n",
       "  0.0009874039123096078,\n",
       "  0.000995086841032381,\n",
       "  0.0009618486734465337,\n",
       "  0.0010287610332511063,\n",
       "  0.000883325154006026,\n",
       "  0.0009188775986652164,\n",
       "  0.0009231233386727412,\n",
       "  0.0008406795366936915,\n",
       "  0.0008269140580605834,\n",
       "  0.0008603885640259579,\n",
       "  0.0007802084153117738,\n",
       "  0.0008003468094793954,\n",
       "  0.0008519232951049857,\n",
       "  0.0009050344241302612,\n",
       "  0.0008141744070121707,\n",
       "  0.0008705944924855529,\n",
       "  0.0008332229888896832,\n",
       "  0.0008849836770040552,\n",
       "  0.0008748086428531019,\n",
       "  0.0007969949250130565,\n",
       "  0.0007709635048156511,\n",
       "  0.000757546321071718,\n",
       "  0.000927552018247174,\n",
       "  0.0008910508479762873,\n",
       "  0.0008474184875481875,\n",
       "  0.0008558852348383938,\n",
       "  0.0008514853988719337,\n",
       "  0.0009540090894714267,\n",
       "  0.0009636233375846025,\n",
       "  0.0008552533890988796,\n",
       "  0.0008123220530300658,\n",
       "  0.0008613795041511197,\n",
       "  0.0008470141012811553,\n",
       "  0.0008867677038838893,\n",
       "  0.0007310014395085395,\n",
       "  0.0007988078365886238,\n",
       "  0.0007994323268288333,\n",
       "  0.0008488743823038507,\n",
       "  0.0009189670838571545,\n",
       "  0.0010776957233617614,\n",
       "  0.001092762703168716,\n",
       "  0.000882910425738933,\n",
       "  0.0008862513163320855,\n",
       "  0.0008424859895893453],\n",
       " 'acc': [0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss history by epoch\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the loss history by reading it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read into dataframe\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048656</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.212402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_acc      loss       acc\n",
       "0  0.217740      0.0  0.048656  0.001131\n",
       "1  0.204079      0.0  0.010816  0.001131\n",
       "2  0.221330      0.0  0.007631  0.001131\n",
       "3  0.212402      0.0  0.006587  0.001131\n",
       "4  0.222389      0.0  0.006236  0.001131"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at columns\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4acfd630>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.plot(y = ['val_loss', 'loss'], title = 'Loss History by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall loss decreases and validation loss seem to decrease a great deal in the first few epochs, but the validation loss is very noisy after about 100 epochs, even though the overall loss seems to continue to decrease.  We choose 100 epochs moving forward as this seems to be a good trade-off zone where we might not be running into overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Amount\n",
    "\n",
    "Now, we consider dropout amount (percentage of weights dropped in each iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 5ms/step - loss: 0.0606 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 910us/step - loss: 0.0079 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 897us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 897us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 914us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0819 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 923us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 901us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0878 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0909 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 956us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 759us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 712us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0743 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0805 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0816 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0815 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 882us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0792 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 907us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0810 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0758 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0742 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0771 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 720us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0869 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 813us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0913 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 835us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0839 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 912us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 675us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 863us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0832 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 661us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 714us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 719us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0952 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 870us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1170 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1158 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 842us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 932us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1152 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1142 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1352 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 899us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 880us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 861us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 887us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1318 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.022935218843989646, RMSE: 0.15144378113342802\n",
      "Test Set- Score: 0.1439503347096236, RMSE: 0.379407873810789\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 6ms/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 719us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1089 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 769us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1005 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0873 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0889 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 868us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0525 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0590 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 718us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 724us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 878us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0578 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 837us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0609 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 835us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0735 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 865us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.013468831473101791, RMSE: 0.1160552948947259\n",
      "Test Set- Score: 0.07443509574817575, RMSE: 0.2728279599824324\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 6ms/step - loss: 0.1064 - acc: 0.0000e+00 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0166 - acc: 0.0011 - val_loss: 0.0819 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0942 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0986 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 813us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 852us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0949 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0958 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0886 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0909 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 759us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 727us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0905 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0898 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0895 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0870 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 922us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0777 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 898us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 700us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0838 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0962 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 691us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1302 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.025177637824358848, RMSE: 0.15867462879855382\n",
      "Test Set- Score: 0.15909677938274716, RMSE: 0.3988693763411114\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 7s 7ms/step - loss: 0.0606 - acc: 0.0000e+00 - val_loss: 0.1839 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.1909 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.1858 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1766 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 938us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1669 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 909us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 714us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1636 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1605 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1681 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1576 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1560 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1637 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1646 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1693 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1704 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1625 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 925us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1599 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1495 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1424 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1287 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1278 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1403 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1449 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 861us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1407 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 825us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 718us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1334 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 869us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1240 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1309 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 676us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1287 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1004 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1054 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 724us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 715us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0965 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.019156914093316747, RMSE: 0.1384085044110973\n",
      "Test Set- Score: 0.11600389623123666, RMSE: 0.340593447134904\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 7s 8ms/step - loss: 0.0794 - acc: 0.0000e+00 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0135 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 675us/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0088 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0081 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1266 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 898us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 716us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1367 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1160 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1184 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1231 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1372 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1188 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 849us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1098 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1195 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1124 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0873 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1037 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1077 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0943 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0913 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0977 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 768us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0814 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 698us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0799 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 716us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 696us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1044 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0959 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 711us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 706us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0834 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1047 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.016391489937758217, RMSE: 0.12802925422636116\n",
      "Test Set- Score: 0.09563112388486447, RMSE: 0.30924282349775634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5b7b9470>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at dropout\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "dropout_list = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "#create lists to store results\n",
    "dropouts = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for dropout in dropout_list:\n",
    "    dropouts.append(dropout)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neuron_length, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Dropouts': dropouts, 'Train Scores': train_scores})\n",
    "\n",
    "results.plot(x = 'Dropouts', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a578ba6d8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results\n",
    "results.plot(x = 'Dropouts', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dropout value of 0.30 is best according to our training scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Split\n",
    "\n",
    "We try several different train/test split sizes to get the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 780 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "780/780 [==============================] - 2s 3ms/step - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0072\n",
      "Epoch 2/100\n",
      "780/780 [==============================] - 1s 982us/step - loss: 0.0192 - acc: 0.0013 - val_loss: 0.0373 - val_acc: 0.0072\n",
      "Epoch 3/100\n",
      "780/780 [==============================] - 1s 972us/step - loss: 0.0140 - acc: 0.0013 - val_loss: 0.0201 - val_acc: 0.0072\n",
      "Epoch 4/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0143 - acc: 0.0013 - val_loss: 0.0277 - val_acc: 0.0072\n",
      "Epoch 5/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0132 - acc: 0.0013 - val_loss: 0.0369 - val_acc: 0.0072\n",
      "Epoch 6/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.0013 - val_loss: 0.0188 - val_acc: 0.0072\n",
      "Epoch 7/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0013 - val_loss: 0.0241 - val_acc: 0.0072\n",
      "Epoch 8/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0013 - val_loss: 0.0278 - val_acc: 0.0072\n",
      "Epoch 9/100\n",
      "780/780 [==============================] - 1s 990us/step - loss: 0.0111 - acc: 0.0013 - val_loss: 0.0259 - val_acc: 0.0072\n",
      "Epoch 10/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.0013 - val_loss: 0.0202 - val_acc: 0.0072\n",
      "Epoch 11/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0013 - val_loss: 0.0234 - val_acc: 0.0072\n",
      "Epoch 12/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0013 - val_loss: 0.0214 - val_acc: 0.0072\n",
      "Epoch 13/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0013 - val_loss: 0.0197 - val_acc: 0.0072\n",
      "Epoch 14/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0204 - val_acc: 0.0072\n",
      "Epoch 15/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0013 - val_loss: 0.0181 - val_acc: 0.0072\n",
      "Epoch 16/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0013 - val_loss: 0.0207 - val_acc: 0.0072\n",
      "Epoch 17/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0013 - val_loss: 0.0176 - val_acc: 0.0072\n",
      "Epoch 18/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0189 - val_acc: 0.0072\n",
      "Epoch 19/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0013 - val_loss: 0.0189 - val_acc: 0.0072\n",
      "Epoch 20/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.0013 - val_loss: 0.0158 - val_acc: 0.0072\n",
      "Epoch 21/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0191 - val_acc: 0.0072\n",
      "Epoch 22/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0013 - val_loss: 0.0255 - val_acc: 0.0072\n",
      "Epoch 23/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0191 - val_acc: 0.0072\n",
      "Epoch 24/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0216 - val_acc: 0.0072\n",
      "Epoch 25/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0187 - val_acc: 0.0072\n",
      "Epoch 26/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0176 - val_acc: 0.0072\n",
      "Epoch 27/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0170 - val_acc: 0.0072\n",
      "Epoch 28/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0150 - val_acc: 0.0072\n",
      "Epoch 29/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0213 - val_acc: 0.0072\n",
      "Epoch 30/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0229 - val_acc: 0.0072\n",
      "Epoch 31/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0211 - val_acc: 0.0072\n",
      "Epoch 32/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0013 - val_loss: 0.0147 - val_acc: 0.0072\n",
      "Epoch 33/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0251 - val_acc: 0.0072\n",
      "Epoch 34/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0013 - val_loss: 0.0178 - val_acc: 0.0072\n",
      "Epoch 35/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0146 - val_acc: 0.0072\n",
      "Epoch 36/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.0013 - val_loss: 0.0156 - val_acc: 0.0072\n",
      "Epoch 37/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0195 - val_acc: 0.0072\n",
      "Epoch 38/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0213 - val_acc: 0.0072\n",
      "Epoch 39/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0172 - val_acc: 0.0072\n",
      "Epoch 40/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0174 - val_acc: 0.0072\n",
      "Epoch 41/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0147 - val_acc: 0.0072\n",
      "Epoch 42/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0158 - val_acc: 0.0072\n",
      "Epoch 43/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0145 - val_acc: 0.0072\n",
      "Epoch 44/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0280 - val_acc: 0.0072\n",
      "Epoch 45/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0176 - val_acc: 0.0072\n",
      "Epoch 46/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0189 - val_acc: 0.0072\n",
      "Epoch 47/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0166 - val_acc: 0.0072\n",
      "Epoch 48/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0200 - val_acc: 0.0072\n",
      "Epoch 49/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0152 - val_acc: 0.0072\n",
      "Epoch 50/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0159 - val_acc: 0.0072\n",
      "Epoch 51/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0207 - val_acc: 0.0072\n",
      "Epoch 52/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0149 - val_acc: 0.0072\n",
      "Epoch 53/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0147 - val_acc: 0.0072\n",
      "Epoch 54/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0166 - val_acc: 0.0072\n",
      "Epoch 55/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0179 - val_acc: 0.0072\n",
      "Epoch 56/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0173 - val_acc: 0.0072\n",
      "Epoch 57/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0231 - val_acc: 0.0072\n",
      "Epoch 58/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0184 - val_acc: 0.0072\n",
      "Epoch 59/100\n",
      "780/780 [==============================] - 1s 986us/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0178 - val_acc: 0.0072\n",
      "Epoch 60/100\n",
      "780/780 [==============================] - 1s 991us/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0204 - val_acc: 0.0072\n",
      "Epoch 61/100\n",
      "780/780 [==============================] - 1s 990us/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0202 - val_acc: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0186 - val_acc: 0.0072\n",
      "Epoch 63/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0177 - val_acc: 0.0072\n",
      "Epoch 64/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0013 - val_loss: 0.0152 - val_acc: 0.0072\n",
      "Epoch 65/100\n",
      "780/780 [==============================] - 1s 981us/step - loss: 0.0116 - acc: 0.0013 - val_loss: 0.0156 - val_acc: 0.0072\n",
      "Epoch 66/100\n",
      "780/780 [==============================] - 1s 985us/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0202 - val_acc: 0.0072\n",
      "Epoch 67/100\n",
      "780/780 [==============================] - 1s 999us/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0188 - val_acc: 0.0072\n",
      "Epoch 68/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0162 - val_acc: 0.0072\n",
      "Epoch 69/100\n",
      "780/780 [==============================] - 1s 999us/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0160 - val_acc: 0.0072\n",
      "Epoch 70/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0013 - val_loss: 0.0154 - val_acc: 0.0072\n",
      "Epoch 71/100\n",
      "780/780 [==============================] - 1s 988us/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0184 - val_acc: 0.0072\n",
      "Epoch 72/100\n",
      "780/780 [==============================] - 1s 982us/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0171 - val_acc: 0.0072\n",
      "Epoch 73/100\n",
      "780/780 [==============================] - 1s 978us/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0185 - val_acc: 0.0072\n",
      "Epoch 74/100\n",
      "780/780 [==============================] - 1s 974us/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0191 - val_acc: 0.0072\n",
      "Epoch 75/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0188 - val_acc: 0.0072\n",
      "Epoch 76/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0200 - val_acc: 0.0072\n",
      "Epoch 77/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0155 - val_acc: 0.0072\n",
      "Epoch 78/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0170 - val_acc: 0.0072\n",
      "Epoch 79/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.0013 - val_loss: 0.0157 - val_acc: 0.0072\n",
      "Epoch 80/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0148 - val_acc: 0.0072\n",
      "Epoch 81/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0215 - val_acc: 0.0072\n",
      "Epoch 82/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0205 - val_acc: 0.0072\n",
      "Epoch 83/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0149 - val_acc: 0.0072\n",
      "Epoch 84/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0178 - val_acc: 0.0072\n",
      "Epoch 85/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0222 - val_acc: 0.0072\n",
      "Epoch 86/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0164 - val_acc: 0.0072\n",
      "Epoch 87/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0198 - val_acc: 0.0072\n",
      "Epoch 88/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0165 - val_acc: 0.0072\n",
      "Epoch 89/100\n",
      "780/780 [==============================] - 1s 995us/step - loss: 0.0092 - acc: 0.0013 - val_loss: 0.0177 - val_acc: 0.0072\n",
      "Epoch 90/100\n",
      "780/780 [==============================] - 1s 995us/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0154 - val_acc: 0.0072\n",
      "Epoch 91/100\n",
      "780/780 [==============================] - 1s 999us/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0197 - val_acc: 0.0072\n",
      "Epoch 92/100\n",
      "780/780 [==============================] - 1s 976us/step - loss: 0.0091 - acc: 0.0013 - val_loss: 0.0179 - val_acc: 0.0072\n",
      "Epoch 93/100\n",
      "780/780 [==============================] - 1s 999us/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0181 - val_acc: 0.0072\n",
      "Epoch 94/100\n",
      "780/780 [==============================] - 1s 981us/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0175 - val_acc: 0.0072\n",
      "Epoch 95/100\n",
      "780/780 [==============================] - 1s 991us/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0158 - val_acc: 0.0072\n",
      "Epoch 96/100\n",
      "780/780 [==============================] - 1s 992us/step - loss: 0.0092 - acc: 0.0013 - val_loss: 0.0187 - val_acc: 0.0072\n",
      "Epoch 97/100\n",
      "780/780 [==============================] - 1s 991us/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0167 - val_acc: 0.0072\n",
      "Epoch 98/100\n",
      "780/780 [==============================] - 1s 988us/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0179 - val_acc: 0.0072\n",
      "Epoch 99/100\n",
      "780/780 [==============================] - 1s 994us/step - loss: 0.0092 - acc: 0.0013 - val_loss: 0.0198 - val_acc: 0.0072\n",
      "Epoch 100/100\n",
      "780/780 [==============================] - 1s 973us/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0177 - val_acc: 0.0072\n",
      "Training Set- Score: 0.010185538756626623, RMSE: 0.10092343016676862\n",
      "Test Set- Score: 0.12115435341214822, RMSE: 0.3480723393378857\n",
      "Train on 832 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "832/832 [==============================] - 3s 3ms/step - loss: 0.0515 - acc: 0.0000e+00 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0012 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0071 - acc: 0.0012 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "832/832 [==============================] - 1s 990us/step - loss: 0.0066 - acc: 0.0012 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "832/832 [==============================] - 1s 961us/step - loss: 0.0064 - acc: 0.0012 - val_loss: 0.1468 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "832/832 [==============================] - 1s 988us/step - loss: 0.0063 - acc: 0.0012 - val_loss: 0.1496 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0012 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0012 - val_loss: 0.1568 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0012 - val_loss: 0.1553 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "832/832 [==============================] - 1s 982us/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.1581 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "832/832 [==============================] - 1s 976us/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "832/832 [==============================] - 1s 936us/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "832/832 [==============================] - 1s 967us/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "832/832 [==============================] - 1s 957us/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1611 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "832/832 [==============================] - 1s 991us/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "832/832 [==============================] - 1s 965us/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.1504 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "832/832 [==============================] - 1s 961us/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.1532 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "832/832 [==============================] - 1s 958us/step - loss: 0.0056 - acc: 0.0012 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "832/832 [==============================] - 1s 969us/step - loss: 0.0056 - acc: 0.0012 - val_loss: 0.1508 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "832/832 [==============================] - 1s 956us/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "832/832 [==============================] - 1s 979us/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "832/832 [==============================] - 1s 971us/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1556 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.1578 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.1572 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.1613 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.1579 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1585 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1539 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "832/832 [==============================] - 1s 986us/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "832/832 [==============================] - 1s 999us/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1588 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "832/832 [==============================] - 1s 999us/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1563 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "832/832 [==============================] - 1s 993us/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1561 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "832/832 [==============================] - 1s 992us/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1494 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "832/832 [==============================] - 1s 977us/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1543 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "832/832 [==============================] - 1s 989us/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "832/832 [==============================] - 1s 1000us/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1526 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "832/832 [==============================] - 1s 997us/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "832/832 [==============================] - 1s 966us/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "832/832 [==============================] - 1s 992us/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1317 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1384 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1478 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1394 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1449 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1425 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "832/832 [==============================] - 1s 974us/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "832/832 [==============================] - 1s 969us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1554 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "832/832 [==============================] - 1s 981us/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "832/832 [==============================] - 1s 1000us/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "832/832 [==============================] - 1s 995us/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "832/832 [==============================] - 1s 979us/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1485 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "832/832 [==============================] - 1s 969us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "832/832 [==============================] - 1s 982us/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1522 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "832/832 [==============================] - 1s 972us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "832/832 [==============================] - 1s 978us/step - loss: 0.0040 - acc: 0.0012 - val_loss: 0.1640 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "832/832 [==============================] - 1s 995us/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1608 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "832/832 [==============================] - 1s 997us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1569 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "832/832 [==============================] - 1s 987us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "832/832 [==============================] - 1s 994us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1797 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "832/832 [==============================] - 1s 992us/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1849 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "832/832 [==============================] - 1s 992us/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1938 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "832/832 [==============================] - 1s 992us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1494 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "832/832 [==============================] - 1s 960us/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "832/832 [==============================] - 1s 988us/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0012 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1482 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1423 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1537 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0012 - val_loss: 0.1738 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1783 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1729 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1858 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1841 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1713 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0012 - val_loss: 0.1670 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1697 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1823 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1769 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1802 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0012 - val_loss: 0.1866 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1952 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0012 - val_loss: 0.2021 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1990 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1805 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.1780 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.1773 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1790 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.029981414116804883, RMSE: 0.17315141962110758\n",
      "Test Set- Score: 0.22321889169362127, RMSE: 0.4724604657467345\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0469 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.0869 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 957us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0958 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 972us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 993us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 990us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 993us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1089 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0993 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 986us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0992 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 989us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0962 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1026 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 980us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 982us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 986us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0922 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1134 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0956 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0864 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0895 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1001 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0943 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1611 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1296 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 994us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1109 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1881 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1711 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1653 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1796 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1851 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1938 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1963 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1723 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1639 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1297 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1541 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1494 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1314 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2034 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1906 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1728 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1532 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1222 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1518 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1235 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0949 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.01728471737140073, RMSE: 0.13147135570686388\n",
      "Test Set- Score: 0.1011350815710814, RMSE: 0.3180174233765839\n",
      "Train on 935 samples, validate on 166 samples\n",
      "Epoch 1/100\n",
      "935/935 [==============================] - 3s 4ms/step - loss: 0.0705 - acc: 0.0011 - val_loss: 0.0254 - val_acc: 0.0060\n",
      "Epoch 2/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.0011 - val_loss: 0.0188 - val_acc: 0.0060\n",
      "Epoch 3/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0060\n",
      "Epoch 4/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0060\n",
      "Epoch 5/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0060\n",
      "Epoch 6/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0060\n",
      "Epoch 7/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0869 - val_acc: 0.0060\n",
      "Epoch 8/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0819 - val_acc: 0.0060\n",
      "Epoch 9/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0060\n",
      "Epoch 10/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0060\n",
      "Epoch 11/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0060\n",
      "Epoch 12/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0957 - val_acc: 0.0060\n",
      "Epoch 13/100\n",
      "935/935 [==============================] - 1s 987us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0060\n",
      "Epoch 14/100\n",
      "935/935 [==============================] - 1s 996us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0060\n",
      "Epoch 15/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0060\n",
      "Epoch 16/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0060\n",
      "Epoch 17/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1095 - val_acc: 0.0060\n",
      "Epoch 18/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0060\n",
      "Epoch 19/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1072 - val_acc: 0.0060\n",
      "Epoch 20/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1088 - val_acc: 0.0060\n",
      "Epoch 21/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1237 - val_acc: 0.0060\n",
      "Epoch 22/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0060\n",
      "Epoch 23/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0060\n",
      "Epoch 24/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0060\n",
      "Epoch 25/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1014 - val_acc: 0.0060\n",
      "Epoch 26/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0949 - val_acc: 0.0060\n",
      "Epoch 27/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1030 - val_acc: 0.0060\n",
      "Epoch 28/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0060\n",
      "Epoch 29/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1090 - val_acc: 0.0060\n",
      "Epoch 30/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1756 - val_acc: 0.0060\n",
      "Epoch 31/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0060\n",
      "Epoch 32/100\n",
      "935/935 [==============================] - 1s 987us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0060\n",
      "Epoch 33/100\n",
      "935/935 [==============================] - 1s 977us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0060\n",
      "Epoch 34/100\n",
      "935/935 [==============================] - 1s 977us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0060\n",
      "Epoch 35/100\n",
      "935/935 [==============================] - 1s 948us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0060\n",
      "Epoch 36/100\n",
      "935/935 [==============================] - 1s 977us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0060\n",
      "Epoch 37/100\n",
      "935/935 [==============================] - 1s 982us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1083 - val_acc: 0.0060\n",
      "Epoch 38/100\n",
      "935/935 [==============================] - 1s 978us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0060\n",
      "Epoch 39/100\n",
      "935/935 [==============================] - 1s 990us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1636 - val_acc: 0.0060\n",
      "Epoch 40/100\n",
      "935/935 [==============================] - 1s 988us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0060\n",
      "Epoch 41/100\n",
      "935/935 [==============================] - 1s 985us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1041 - val_acc: 0.0060\n",
      "Epoch 42/100\n",
      "935/935 [==============================] - 1s 988us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1424 - val_acc: 0.0060\n",
      "Epoch 43/100\n",
      "935/935 [==============================] - 1s 988us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0060\n",
      "Epoch 44/100\n",
      "935/935 [==============================] - 1s 986us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0060\n",
      "Epoch 45/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0060\n",
      "Epoch 46/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0060\n",
      "Epoch 47/100\n",
      "935/935 [==============================] - 1s 986us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1563 - val_acc: 0.0060\n",
      "Epoch 48/100\n",
      "935/935 [==============================] - 1s 987us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1382 - val_acc: 0.0060\n",
      "Epoch 49/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1744 - val_acc: 0.0060\n",
      "Epoch 50/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0060\n",
      "Epoch 51/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1797 - val_acc: 0.0060\n",
      "Epoch 52/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1974 - val_acc: 0.0060\n",
      "Epoch 53/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1537 - val_acc: 0.0060\n",
      "Epoch 54/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0060\n",
      "Epoch 55/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2100 - val_acc: 0.0060\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1988 - val_acc: 0.0060\n",
      "Epoch 57/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0060\n",
      "Epoch 58/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1665 - val_acc: 0.0060\n",
      "Epoch 59/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1523 - val_acc: 0.0060\n",
      "Epoch 60/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0060\n",
      "Epoch 61/100\n",
      "935/935 [==============================] - 1s 989us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2164 - val_acc: 0.0060\n",
      "Epoch 62/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2221 - val_acc: 0.0060\n",
      "Epoch 63/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0060\n",
      "Epoch 64/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2106 - val_acc: 0.0060\n",
      "Epoch 65/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1979 - val_acc: 0.0060\n",
      "Epoch 66/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1460 - val_acc: 0.0060\n",
      "Epoch 67/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1639 - val_acc: 0.0060\n",
      "Epoch 68/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1644 - val_acc: 0.0060\n",
      "Epoch 69/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1829 - val_acc: 0.0060\n",
      "Epoch 70/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1577 - val_acc: 0.0060\n",
      "Epoch 71/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1513 - val_acc: 0.0060\n",
      "Epoch 72/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1368 - val_acc: 0.0060\n",
      "Epoch 73/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0060\n",
      "Epoch 74/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0060\n",
      "Epoch 75/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1837 - val_acc: 0.0060\n",
      "Epoch 76/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1586 - val_acc: 0.0060\n",
      "Epoch 77/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0060\n",
      "Epoch 78/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1735 - val_acc: 0.0060\n",
      "Epoch 79/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0060\n",
      "Epoch 80/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1920 - val_acc: 0.0060\n",
      "Epoch 81/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1293 - val_acc: 0.0060\n",
      "Epoch 82/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0060\n",
      "Epoch 83/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0060\n",
      "Epoch 84/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0060\n",
      "Epoch 85/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1758 - val_acc: 0.0060\n",
      "Epoch 86/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1457 - val_acc: 0.0060\n",
      "Epoch 87/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0060\n",
      "Epoch 88/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1069 - val_acc: 0.0060\n",
      "Epoch 89/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1876 - val_acc: 0.0060\n",
      "Epoch 90/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0060\n",
      "Epoch 91/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2428 - val_acc: 0.0060\n",
      "Epoch 92/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0060\n",
      "Epoch 93/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0060\n",
      "Epoch 94/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0060\n",
      "Epoch 95/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0060\n",
      "Epoch 96/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0060\n",
      "Epoch 97/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0755 - val_acc: 0.0060\n",
      "Epoch 98/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0060\n",
      "Epoch 99/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0060\n",
      "Epoch 100/100\n",
      "935/935 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1416 - val_acc: 0.0060\n",
      "Training Set- Score: 0.024763654727153785, RMSE: 0.1573647188131882\n",
      "Test Set- Score: 0.1606020407100034, RMSE: 0.40075184430018956\n"
     ]
    }
   ],
   "source": [
    "#look at train/test split\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "dropout = 0.3\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "split_list = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "#create lists to store results\n",
    "train_splits = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for train_split in split_list:\n",
    "    train_splits.append(train_split)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Train_Test_Splits': train_splits, 'Train Scores': train_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2868cc18>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results\n",
    "results.plot.bar(x = 'Train_Test_Splits', y = 'Train Scores', color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the way train/test split works with this time series data, we will actually take a look at a graph for this one after training a model.  It may be that training/test performance is different.  We will test with the best (lowest) score of 0.75/0.25 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 780 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "780/780 [==============================] - 4s 4ms/step - loss: 0.0458 - acc: 0.0013 - val_loss: 0.0393 - val_acc: 0.0072\n",
      "Epoch 2/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0072\n",
      "Epoch 3/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.0013 - val_loss: 0.0345 - val_acc: 0.0072\n",
      "Epoch 4/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 0.0013 - val_loss: 0.0259 - val_acc: 0.0072\n",
      "Epoch 5/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.0013 - val_loss: 0.0187 - val_acc: 0.0072\n",
      "Epoch 6/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0013 - val_loss: 0.0261 - val_acc: 0.0072\n",
      "Epoch 7/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0013 - val_loss: 0.0208 - val_acc: 0.0072\n",
      "Epoch 8/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0013 - val_loss: 0.0191 - val_acc: 0.0072\n",
      "Epoch 9/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0013 - val_loss: 0.0214 - val_acc: 0.0072\n",
      "Epoch 10/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.0013 - val_loss: 0.0291 - val_acc: 0.0072\n",
      "Epoch 11/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0013 - val_loss: 0.0282 - val_acc: 0.0072\n",
      "Epoch 12/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0013 - val_loss: 0.0209 - val_acc: 0.0072\n",
      "Epoch 13/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0013 - val_loss: 0.0209 - val_acc: 0.0072\n",
      "Epoch 14/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0013 - val_loss: 0.0272 - val_acc: 0.0072\n",
      "Epoch 15/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0013 - val_loss: 0.0240 - val_acc: 0.0072\n",
      "Epoch 16/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0013 - val_loss: 0.0183 - val_acc: 0.0072\n",
      "Epoch 17/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0013 - val_loss: 0.0188 - val_acc: 0.0072\n",
      "Epoch 18/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0013 - val_loss: 0.0166 - val_acc: 0.0072\n",
      "Epoch 19/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0013 - val_loss: 0.0269 - val_acc: 0.0072\n",
      "Epoch 20/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0013 - val_loss: 0.0230 - val_acc: 0.0072\n",
      "Epoch 21/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0243 - val_acc: 0.0072\n",
      "Epoch 22/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.0013 - val_loss: 0.0154 - val_acc: 0.0072\n",
      "Epoch 23/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.0013 - val_loss: 0.0187 - val_acc: 0.0072\n",
      "Epoch 24/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0226 - val_acc: 0.0072\n",
      "Epoch 25/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0152 - val_acc: 0.0072\n",
      "Epoch 26/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0192 - val_acc: 0.0072\n",
      "Epoch 27/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0191 - val_acc: 0.0072\n",
      "Epoch 28/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0013 - val_loss: 0.0247 - val_acc: 0.0072\n",
      "Epoch 29/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0013 - val_loss: 0.0221 - val_acc: 0.0072\n",
      "Epoch 30/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0156 - val_acc: 0.0072\n",
      "Epoch 31/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0203 - val_acc: 0.0072\n",
      "Epoch 32/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0197 - val_acc: 0.0072\n",
      "Epoch 33/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0013 - val_loss: 0.0152 - val_acc: 0.0072\n",
      "Epoch 34/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0176 - val_acc: 0.0072\n",
      "Epoch 35/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0013 - val_loss: 0.0172 - val_acc: 0.0072\n",
      "Epoch 36/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0169 - val_acc: 0.0072\n",
      "Epoch 37/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0201 - val_acc: 0.0072\n",
      "Epoch 38/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0207 - val_acc: 0.0072\n",
      "Epoch 39/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0157 - val_acc: 0.0072\n",
      "Epoch 40/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0013 - val_loss: 0.0175 - val_acc: 0.0072\n",
      "Epoch 41/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0202 - val_acc: 0.0072\n",
      "Epoch 42/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0181 - val_acc: 0.0072\n",
      "Epoch 43/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0177 - val_acc: 0.0072\n",
      "Epoch 44/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0013 - val_loss: 0.0167 - val_acc: 0.0072\n",
      "Epoch 45/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0226 - val_acc: 0.0072\n",
      "Epoch 46/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0143 - val_acc: 0.0072\n",
      "Epoch 47/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0013 - val_loss: 0.0216 - val_acc: 0.0072\n",
      "Epoch 48/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0013 - val_loss: 0.0263 - val_acc: 0.0072\n",
      "Epoch 49/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0013 - val_loss: 0.0147 - val_acc: 0.0072\n",
      "Epoch 50/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0166 - val_acc: 0.0072\n",
      "Epoch 51/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0013 - val_loss: 0.0158 - val_acc: 0.0072\n",
      "Epoch 52/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0219 - val_acc: 0.0072\n",
      "Epoch 53/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0013 - val_loss: 0.0189 - val_acc: 0.0072\n",
      "Epoch 54/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0013 - val_loss: 0.0159 - val_acc: 0.0072\n",
      "Epoch 55/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0202 - val_acc: 0.0072\n",
      "Epoch 56/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0143 - val_acc: 0.0072\n",
      "Epoch 57/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0270 - val_acc: 0.0072\n",
      "Epoch 58/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0155 - val_acc: 0.0072\n",
      "Epoch 59/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0204 - val_acc: 0.0072\n",
      "Epoch 60/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0202 - val_acc: 0.0072\n",
      "Epoch 61/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0013 - val_loss: 0.0253 - val_acc: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0013 - val_loss: 0.0153 - val_acc: 0.0072\n",
      "Epoch 63/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0185 - val_acc: 0.0072\n",
      "Epoch 64/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0220 - val_acc: 0.0072\n",
      "Epoch 65/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0153 - val_acc: 0.0072\n",
      "Epoch 66/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0229 - val_acc: 0.0072\n",
      "Epoch 67/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0170 - val_acc: 0.0072\n",
      "Epoch 68/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0170 - val_acc: 0.0072\n",
      "Epoch 69/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0013 - val_loss: 0.0191 - val_acc: 0.0072\n",
      "Epoch 70/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0150 - val_acc: 0.0072\n",
      "Epoch 71/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0013 - val_loss: 0.0152 - val_acc: 0.0072\n",
      "Epoch 72/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0161 - val_acc: 0.0072\n",
      "Epoch 73/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0160 - val_acc: 0.0072\n",
      "Epoch 74/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0176 - val_acc: 0.0072\n",
      "Epoch 75/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0194 - val_acc: 0.0072\n",
      "Epoch 76/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0171 - val_acc: 0.0072\n",
      "Epoch 77/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0164 - val_acc: 0.0072\n",
      "Epoch 78/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0180 - val_acc: 0.0072\n",
      "Epoch 79/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0161 - val_acc: 0.0072\n",
      "Epoch 80/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0172 - val_acc: 0.0072\n",
      "Epoch 81/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0013 - val_loss: 0.0151 - val_acc: 0.0072\n",
      "Epoch 82/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0298 - val_acc: 0.0072\n",
      "Epoch 83/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0166 - val_acc: 0.0072\n",
      "Epoch 84/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0171 - val_acc: 0.0072\n",
      "Epoch 85/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0190 - val_acc: 0.0072\n",
      "Epoch 86/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0154 - val_acc: 0.0072\n",
      "Epoch 87/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0013 - val_loss: 0.0183 - val_acc: 0.0072\n",
      "Epoch 88/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0206 - val_acc: 0.0072\n",
      "Epoch 89/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.0013 - val_loss: 0.0165 - val_acc: 0.0072\n",
      "Epoch 90/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0151 - val_acc: 0.0072\n",
      "Epoch 91/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.0160 - val_acc: 0.0072\n",
      "Epoch 92/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0177 - val_acc: 0.0072\n",
      "Epoch 93/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0290 - val_acc: 0.0072\n",
      "Epoch 94/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0013 - val_loss: 0.0164 - val_acc: 0.0072\n",
      "Epoch 95/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0198 - val_acc: 0.0072\n",
      "Epoch 96/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0164 - val_acc: 0.0072\n",
      "Epoch 97/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0161 - val_acc: 0.0072\n",
      "Epoch 98/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0013 - val_loss: 0.0146 - val_acc: 0.00720e\n",
      "Epoch 99/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0013 - val_loss: 0.0179 - val_acc: 0.0072\n",
      "Epoch 100/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0013 - val_loss: 0.0178 - val_acc: 0.0072\n",
      "Training Set- Score: 0.009976510770115717, RMSE: 0.09988248480146916\n",
      "Test Set- Score: 0.14471191791147966, RMSE: 0.38041019690786376\n"
     ]
    }
   ],
   "source": [
    "#train a model with 0.75 train/test split\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.75\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.3\n",
    "model_path = 'three_quarters_split.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a 0.75 train/test split actually does not do well as the scale is wrong for the test set.  We will still use a split of 0.85 going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try several different validation set splits (a validation set is the portion of the training set used to test the training sets performance in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 4s 5ms/step - loss: 0.0366 - acc: 0.0011 - val_loss: 0.1240 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 0.0263 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1471 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0909 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1208 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1588 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1292 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0981 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1754 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1271 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1608 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1480 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1628 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1003 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1479 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1577 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1469 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1485 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1404 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1812 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1885 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1690 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2048 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2061 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1805 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1542 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1543 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0872 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 1s 953us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1477 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 1s 942us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1931 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 1s 947us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2060 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 1s 976us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 1s 996us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 1s 982us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2209 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 1s 972us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0971 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1540 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1341 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1235 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1360 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1313 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2015 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0905 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0952 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1948 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0471 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 1s 988us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 1s 993us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1044 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1040 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 1s 990us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1918 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 1s 972us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1241 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 1s 985us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1493 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 1s 973us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1542 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 1s 976us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0494 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1006 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0935 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1734 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0551 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0096\n",
      "Training Set- Score: 0.011220602075067851, RMSE: 0.10592734337775045\n",
      "Test Set- Score: 0.0380219264846781, RMSE: 0.1949921190322268\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 5ms/step - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.0011 - val_loss: 0.1144 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 993us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1177 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1397 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1427 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1436 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1427 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1295 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1495 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1579 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1666 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1633 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1518 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1630 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1732 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1768 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1931 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2093 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1721 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1743 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1522 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1943 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2161 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2349 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2201 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2026 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2316 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2605 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2869 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2675 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2859 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2493 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2704 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2993 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3101 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3169 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 972us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2993 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 998us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3188 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2709 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2608 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2691 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2656 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2512 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 1000us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2774 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2496 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2768 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3003 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 990us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3053 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3585 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3991 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3219 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3215 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3872 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3955 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3408 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 993us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3128 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 982us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3137 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3096 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3263 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 986us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3457 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3958 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3385 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3944 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3330 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3050 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2753 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3277 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3211 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3432 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3617 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3212 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2566 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2872 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3237 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3257 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.05214053215458989, RMSE: 0.22834301424521375\n",
      "Test Set- Score: 0.3413664841133615, RMSE: 0.5842657649677597\n",
      "Train on 832 samples, validate on 208 samples\n",
      "Epoch 1/100\n",
      "832/832 [==============================] - 5s 6ms/step - loss: 0.0490 - acc: 0.0012 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.0012 - val_loss: 0.0810 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0012 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0071 - acc: 0.0012 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0012 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "832/832 [==============================] - 1s 974us/step - loss: 0.0064 - acc: 0.0012 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "832/832 [==============================] - 1s 980us/step - loss: 0.0061 - acc: 0.0012 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0012 - val_loss: 0.0956 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0012 - val_loss: 0.0946 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0012 - val_loss: 0.0883 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0012 - val_loss: 0.0994 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0012 - val_loss: 0.0997 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0012 - val_loss: 0.1008 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0012 - val_loss: 0.1001 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0012 - val_loss: 0.1030 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.0959 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0012 - val_loss: 0.1003 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0012 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.0997 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.1016 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0012 - val_loss: 0.0970 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0012 - val_loss: 0.0926 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.1052 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0012 - val_loss: 0.1072 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0012 - val_loss: 0.1035 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0012 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.0935 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1001 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.1010 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.0986 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.1015 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0012 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0974 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.0925 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0862 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.0833 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.0869 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.0870 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.0663 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0679 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0825 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.0823 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0834 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0781 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0012 - val_loss: 0.0744 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.0664 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0813 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0012 - val_loss: 0.0942 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0012 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0012 - val_loss: 0.0878 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0012 - val_loss: 0.0845 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.0752 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0753 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.0815 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0732 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.0816 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0012 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.0972 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.0815 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.0864 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.0821 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.0742 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.0912 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1030 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1235 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0012 - val_loss: 0.1222 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0012 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.0919 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "832/832 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0012 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.0969 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0012 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.02587735657221996, RMSE: 0.1608644043044326\n",
      "Test Set- Score: 0.16349588269772736, RMSE: 0.40434624110745404\n",
      "Train on 780 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      "780/780 [==============================] - 7s 9ms/step - loss: 0.0451 - acc: 0.0013 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0013 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.0013 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 0.0013 - val_loss: 0.1200 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0013 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0013 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0013 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0059 - acc: 0.0013 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0013 - val_loss: 0.1174 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0013 - val_loss: 0.1188 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0013 - val_loss: 0.1201 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0013 - val_loss: 0.1211 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0013 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0013 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0013 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0013 - val_loss: 0.1208 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0013 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0013 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0013 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0013 - val_loss: 0.1232 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0013 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0013 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0013 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0013 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0013 - val_loss: 0.1160 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0013 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0013 - val_loss: 0.1262 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0013 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0013 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0013 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0013 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0013 - val_loss: 0.1239 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0013 - val_loss: 0.1172 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0013 - val_loss: 0.1144 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0013 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0013 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0013 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0013 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0013 - val_loss: 0.1102 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0013 - val_loss: 0.1131 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1192 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0013 - val_loss: 0.1250 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0013 - val_loss: 0.1297 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0013 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0013 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0013 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0013 - val_loss: 0.1297 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0013 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0013 - val_loss: 0.1244 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1275 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0013 - val_loss: 0.1266 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0013 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0013 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0013 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0013 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1238 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0013 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1223 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1194 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1203 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0013 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0013 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1128 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0013 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0013 - val_loss: 0.1192 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1177 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1088 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1059 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1142 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1096 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0013 - val_loss: 0.1113 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0013 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1029 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0013 - val_loss: 0.1170 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0013 - val_loss: 0.1329 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0013 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0013 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0013 - val_loss: 0.1132 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.031163107507074107, RMSE: 0.17653075513086694\n",
      "Test Set- Score: 0.20079419697108475, RMSE: 0.448100654954983\n"
     ]
    }
   ],
   "source": [
    "#look at validation split\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "dropout = 0.3\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "train_split = 0.85\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "split_list = [0.1, 0.15, 0.2, 0.25]\n",
    "\n",
    "#create lists to store results\n",
    "validation_splits = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for validation_split in split_list:\n",
    "    validation_splits.append(validation_split)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Validation Split': train_splits, 'Train Scores': train_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4296a748>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Validation Split': validation_splits, 'Train Scores': train_scores})\n",
    "results.plot.bar(x = 'Validation Split', y = 'Train Scores', color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a validation split of 0.1 as it gives the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Size\n",
    "\n",
    "Finally, we will try a few different batch sizes (how much data is fed at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 8s 8ms/step - loss: 0.0349 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.0636 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 3s 4ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1094 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0195 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0244 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0659 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1223 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0800 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0404 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0776 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1399 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0247 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0215 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1557 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0187 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0243 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2309 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0448 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0154 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0165 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0435 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1004 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0233 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0237 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0240 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 3s 4ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0266 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0524 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0284 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0248 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0206 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0250 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0286 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0231 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0263 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0651 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0233 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0244 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0315 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 3s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0096\n",
      "Training Set- Score: 0.009083484179483584, RMSE: 0.09530731440704635\n",
      "Test Set- Score: 0.04494056299976681, RMSE: 0.21199189371239366\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 7s 8ms/step - loss: 0.0232 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1395 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1800 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1613 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.3420 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1131 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1725 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1388 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.3695 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.3355 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1986 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1973 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.2042 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1209 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.2298 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1563 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0309 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1351 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1069 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0599 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1312 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0677 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0869 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0805 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1234 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1354 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0847 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1443 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1116 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0724 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0392 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0560 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0633 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1928 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0971 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1506 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1055 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1400 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0534 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0922 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1203 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1063 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0696 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0423 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0369 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0190 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0215 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0969 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2038 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.009033311373339249, RMSE: 0.09504373400355885\n",
      "Test Set- Score: 0.05362525541821252, RMSE: 0.23157127502825672\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 7s 7ms/step - loss: 0.0774 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 0.0011 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1000 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1574 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1142 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1855 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 1s 972us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 1s 957us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1808 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 1s 996us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1841 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 1s 991us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1226 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1683 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1311 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 1s 978us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 1s 974us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2175 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 1s 971us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1905 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 1s 971us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1797 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 1s 966us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 1s 981us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1758 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 1s 973us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1167 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1676 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1683 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1121 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 1s 976us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1822 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 1s 964us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 1s 967us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0096\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 1s 971us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1461 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 1s 966us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1608 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0963 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1779 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0593 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 1s 994us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.2213 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 1s 966us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 1s 962us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1522 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2113 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 1s 996us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0946 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1890 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1928 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2461 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1431 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1339 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 1s 988us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1568 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 962us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 1s 956us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 998us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 996us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1730 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 1s 994us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 1s 988us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0679 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 1s 949us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 1s 956us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 1s 994us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0735 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 1s 1000us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1312 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 1s 971us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 1s 986us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0827 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0544 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0636 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 1s 970us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 1s 949us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 1s 964us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 1s 957us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 1s 983us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 1s 999us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0752 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0477 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1114 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 1s 985us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0096\n",
      "Training Set- Score: 0.01190078908828302, RMSE: 0.10909073786661734\n",
      "Test Set- Score: 0.03896604494556137, RMSE: 0.19739818881023546\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ad4423ca7fc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#create dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Batch Size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train Scores'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7313\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7315\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7317\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7359\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#look at batch size\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "dropout = 0.3\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "validation_split = 0.1\n",
    "train_split = 0.85\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "sizes = [16, 32, 64]\n",
    "\n",
    "#create lists to store results\n",
    "batch_sizes = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for batch_size in sizes:\n",
    "    batch_sizes.append(batch_size)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Batch Size': train_splits, 'Train Scores': train_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5093bf60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Batch Size': batch_sizes, 'Train Scores': train_scores})\n",
    "results.plot(x = 'Batch Size', y = 'Train Scores', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a batch size of 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-visiting Time Windows\n",
    "\n",
    "With selected hyperparameters, we can now look at and graph results for different sequence lengths and future points.\n",
    "\n",
    "We begin with our standard 30 day sequence length and a 5 day future point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 8s 9ms/step - loss: 0.0335 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1361 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.2047 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1494 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.2521 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2790 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.2200 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1207 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1985 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1640 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1544 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1950 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1764 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0352 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0819 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0442 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1174 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0225 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0618 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0560 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0686 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0419 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1013 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0679 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1295 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1697 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1506 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1428 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1593 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1909 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1681 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0394 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2691 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0179 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0211 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0520 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0607 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0556 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0096\n",
      "Training Set- Score: 0.011701747552993205, RMSE: 0.10817461602886883\n",
      "Test Set- Score: 0.041876696738535946, RMSE: 0.2046379650468992\n"
     ]
    }
   ],
   "source": [
    "#train a model with\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to do well enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try 5 days sequence 1 day ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 958 samples, validate on 107 samples\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 7s 7ms/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 0s 438us/step - loss: 0.0050 - acc: 0.0010 - val_loss: 0.0393 - val_acc: 0.0093\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 0s 437us/step - loss: 0.0039 - acc: 0.0010 - val_loss: 0.0107 - val_acc: 0.0093\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 0s 412us/step - loss: 0.0040 - acc: 0.0010 - val_loss: 0.0097 - val_acc: 0.0093\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 0s 404us/step - loss: 0.0036 - acc: 0.0010 - val_loss: 0.0091 - val_acc: 0.0093\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 0s 436us/step - loss: 0.0038 - acc: 0.0010 - val_loss: 0.0093 - val_acc: 0.0093\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 0s 437us/step - loss: 0.0037 - acc: 0.0010 - val_loss: 0.0114 - val_acc: 0.0093\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 0s 436us/step - loss: 0.0036 - acc: 0.0010 - val_loss: 0.0149 - val_acc: 0.0093\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 0s 426us/step - loss: 0.0036 - acc: 0.0010 - val_loss: 0.0270 - val_acc: 0.0093\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 0s 419us/step - loss: 0.0033 - acc: 0.0010 - val_loss: 0.0125 - val_acc: 0.0093\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 0s 432us/step - loss: 0.0032 - acc: 0.0010 - val_loss: 0.0224 - val_acc: 0.0093\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 0s 442us/step - loss: 0.0032 - acc: 0.0010 - val_loss: 0.0222 - val_acc: 0.0093\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 0s 450us/step - loss: 0.0034 - acc: 0.0010 - val_loss: 0.0112 - val_acc: 0.0093\n",
      "Epoch 14/100\n",
      "958/958 [==============================] - 0s 447us/step - loss: 0.0034 - acc: 0.0010 - val_loss: 0.0360 - val_acc: 0.0093\n",
      "Epoch 15/100\n",
      "958/958 [==============================] - 0s 434us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0309 - val_acc: 0.0093\n",
      "Epoch 16/100\n",
      "958/958 [==============================] - 0s 441us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0307 - val_acc: 0.0093\n",
      "Epoch 17/100\n",
      "958/958 [==============================] - 0s 444us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0293 - val_acc: 0.0093\n",
      "Epoch 18/100\n",
      "958/958 [==============================] - 0s 423us/step - loss: 0.0033 - acc: 0.0010 - val_loss: 0.0209 - val_acc: 0.0093\n",
      "Epoch 19/100\n",
      "958/958 [==============================] - 0s 436us/step - loss: 0.0030 - acc: 0.0010 - val_loss: 0.0240 - val_acc: 0.0093\n",
      "Epoch 20/100\n",
      "958/958 [==============================] - 0s 454us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0196 - val_acc: 0.0093\n",
      "Epoch 21/100\n",
      "958/958 [==============================] - 0s 446us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0294 - val_acc: 0.0093\n",
      "Epoch 22/100\n",
      "958/958 [==============================] - 0s 422us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0631 - val_acc: 0.0093\n",
      "Epoch 23/100\n",
      "958/958 [==============================] - 0s 452us/step - loss: 0.0028 - acc: 0.0010 - val_loss: 0.0303 - val_acc: 0.0093\n",
      "Epoch 24/100\n",
      "958/958 [==============================] - 0s 450us/step - loss: 0.0029 - acc: 0.0010 - val_loss: 0.0519 - val_acc: 0.0093\n",
      "Epoch 25/100\n",
      "958/958 [==============================] - 0s 457us/step - loss: 0.0030 - acc: 0.0010 - val_loss: 0.0288 - val_acc: 0.0093\n",
      "Epoch 26/100\n",
      "958/958 [==============================] - 0s 451us/step - loss: 0.0031 - acc: 0.0010 - val_loss: 0.0290 - val_acc: 0.0093\n",
      "Epoch 27/100\n",
      "958/958 [==============================] - 0s 479us/step - loss: 0.0027 - acc: 0.0010 - val_loss: 0.0409 - val_acc: 0.0093\n",
      "Epoch 28/100\n",
      "958/958 [==============================] - 0s 468us/step - loss: 0.0027 - acc: 0.0010 - val_loss: 0.0162 - val_acc: 0.0093\n",
      "Epoch 29/100\n",
      "958/958 [==============================] - 0s 460us/step - loss: 0.0027 - acc: 0.0010 - val_loss: 0.0743 - val_acc: 0.0093\n",
      "Epoch 30/100\n",
      "958/958 [==============================] - 0s 452us/step - loss: 0.0028 - acc: 0.0010 - val_loss: 0.0505 - val_acc: 0.0093\n",
      "Epoch 31/100\n",
      "958/958 [==============================] - 0s 445us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0545 - val_acc: 0.0093\n",
      "Epoch 32/100\n",
      "958/958 [==============================] - 0s 421us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0553 - val_acc: 0.0093\n",
      "Epoch 33/100\n",
      "958/958 [==============================] - 0s 446us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0395 - val_acc: 0.0093\n",
      "Epoch 34/100\n",
      "958/958 [==============================] - 0s 422us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0322 - val_acc: 0.0093\n",
      "Epoch 35/100\n",
      "958/958 [==============================] - 0s 403us/step - loss: 0.0027 - acc: 0.0010 - val_loss: 0.0326 - val_acc: 0.0093\n",
      "Epoch 36/100\n",
      "958/958 [==============================] - 0s 441us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0446 - val_acc: 0.0093\n",
      "Epoch 37/100\n",
      "958/958 [==============================] - 0s 435us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0601 - val_acc: 0.0093\n",
      "Epoch 38/100\n",
      "958/958 [==============================] - 0s 443us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0423 - val_acc: 0.0093\n",
      "Epoch 39/100\n",
      "958/958 [==============================] - 0s 458us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0089 - val_acc: 0.0093\n",
      "Epoch 40/100\n",
      "958/958 [==============================] - 0s 450us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0295 - val_acc: 0.0093\n",
      "Epoch 41/100\n",
      "958/958 [==============================] - 0s 464us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0337 - val_acc: 0.0093\n",
      "Epoch 42/100\n",
      "958/958 [==============================] - 0s 460us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0287 - val_acc: 0.0093\n",
      "Epoch 43/100\n",
      "958/958 [==============================] - 0s 468us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0574 - val_acc: 0.0093\n",
      "Epoch 44/100\n",
      "958/958 [==============================] - 0s 439us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0520 - val_acc: 0.0093\n",
      "Epoch 45/100\n",
      "958/958 [==============================] - 0s 441us/step - loss: 0.0024 - acc: 0.0010 - val_loss: 0.0308 - val_acc: 0.0093\n",
      "Epoch 46/100\n",
      "958/958 [==============================] - 0s 428us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0222 - val_acc: 0.0093\n",
      "Epoch 47/100\n",
      "958/958 [==============================] - 0s 454us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0235 - val_acc: 0.0093\n",
      "Epoch 48/100\n",
      "958/958 [==============================] - 0s 414us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0205 - val_acc: 0.0093\n",
      "Epoch 49/100\n",
      "958/958 [==============================] - 0s 453us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0158 - val_acc: 0.0093\n",
      "Epoch 50/100\n",
      "958/958 [==============================] - 0s 437us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0813 - val_acc: 0.0093\n",
      "Epoch 51/100\n",
      "958/958 [==============================] - 0s 435us/step - loss: 0.0024 - acc: 0.0010 - val_loss: 0.0292 - val_acc: 0.0093\n",
      "Epoch 52/100\n",
      "958/958 [==============================] - 0s 428us/step - loss: 0.0026 - acc: 0.0010 - val_loss: 0.0341 - val_acc: 0.0093\n",
      "Epoch 53/100\n",
      "958/958 [==============================] - 0s 431us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0114 - val_acc: 0.0093\n",
      "Epoch 54/100\n",
      "958/958 [==============================] - 0s 423us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0215 - val_acc: 0.0093\n",
      "Epoch 55/100\n",
      "958/958 [==============================] - 0s 389us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0332 - val_acc: 0.0093\n",
      "Epoch 56/100\n",
      "958/958 [==============================] - 0s 435us/step - loss: 0.0024 - acc: 0.0010 - val_loss: 0.0276 - val_acc: 0.0093\n",
      "Epoch 57/100\n",
      "958/958 [==============================] - 0s 437us/step - loss: 0.0020 - acc: 0.0010 - val_loss: 0.0118 - val_acc: 0.0093\n",
      "Epoch 58/100\n",
      "958/958 [==============================] - 0s 438us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0196 - val_acc: 0.0093\n",
      "Epoch 59/100\n",
      "958/958 [==============================] - 0s 444us/step - loss: 0.0024 - acc: 0.0010 - val_loss: 0.0152 - val_acc: 0.0093\n",
      "Epoch 60/100\n",
      "958/958 [==============================] - 0s 444us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0103 - val_acc: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "958/958 [==============================] - 0s 439us/step - loss: 0.0025 - acc: 0.0010 - val_loss: 0.0430 - val_acc: 0.0093\n",
      "Epoch 62/100\n",
      "958/958 [==============================] - 0s 442us/step - loss: 0.0024 - acc: 0.0010 - val_loss: 0.0220 - val_acc: 0.0093\n",
      "Epoch 63/100\n",
      "958/958 [==============================] - 0s 446us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0238 - val_acc: 0.0093\n",
      "Epoch 64/100\n",
      "958/958 [==============================] - 0s 441us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0346 - val_acc: 0.0093\n",
      "Epoch 65/100\n",
      "958/958 [==============================] - 0s 445us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0273 - val_acc: 0.0093\n",
      "Epoch 66/100\n",
      "958/958 [==============================] - 0s 406us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0192 - val_acc: 0.0093\n",
      "Epoch 67/100\n",
      "958/958 [==============================] - 0s 424us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0378 - val_acc: 0.0093\n",
      "Epoch 68/100\n",
      "958/958 [==============================] - 0s 414us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0354 - val_acc: 0.0093\n",
      "Epoch 69/100\n",
      "958/958 [==============================] - 0s 436us/step - loss: 0.0024 - acc: 0.0010 - val_loss: 0.0078 - val_acc: 0.0093\n",
      "Epoch 70/100\n",
      "958/958 [==============================] - 0s 427us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0275 - val_acc: 0.0093\n",
      "Epoch 71/100\n",
      "958/958 [==============================] - 0s 370us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0371 - val_acc: 0.0093\n",
      "Epoch 72/100\n",
      "958/958 [==============================] - 0s 383us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0157 - val_acc: 0.0093\n",
      "Epoch 73/100\n",
      "958/958 [==============================] - 0s 403us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0163 - val_acc: 0.0093\n",
      "Epoch 74/100\n",
      "958/958 [==============================] - 0s 433us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0121 - val_acc: 0.0093\n",
      "Epoch 75/100\n",
      "958/958 [==============================] - 0s 438us/step - loss: 0.0023 - acc: 0.0010 - val_loss: 0.0128 - val_acc: 0.0093\n",
      "Epoch 76/100\n",
      "958/958 [==============================] - 0s 392us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0212 - val_acc: 0.0093\n",
      "Epoch 77/100\n",
      "958/958 [==============================] - 0s 373us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0430 - val_acc: 0.0093\n",
      "Epoch 78/100\n",
      "958/958 [==============================] - 0s 374us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0086 - val_acc: 0.0093\n",
      "Epoch 79/100\n",
      "958/958 [==============================] - 0s 378us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0175 - val_acc: 0.0093\n",
      "Epoch 80/100\n",
      "958/958 [==============================] - 0s 370us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0157 - val_acc: 0.0093\n",
      "Epoch 81/100\n",
      "958/958 [==============================] - 0s 374us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0379 - val_acc: 0.0093\n",
      "Epoch 82/100\n",
      "958/958 [==============================] - 0s 373us/step - loss: 0.0020 - acc: 0.0010 - val_loss: 0.0255 - val_acc: 0.0093\n",
      "Epoch 83/100\n",
      "958/958 [==============================] - 0s 423us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0208 - val_acc: 0.0093\n",
      "Epoch 84/100\n",
      "958/958 [==============================] - 0s 404us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0084 - val_acc: 0.0093\n",
      "Epoch 85/100\n",
      "958/958 [==============================] - 0s 380us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0189 - val_acc: 0.0093\n",
      "Epoch 86/100\n",
      "958/958 [==============================] - 0s 382us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0087 - val_acc: 0.0093\n",
      "Epoch 87/100\n",
      "958/958 [==============================] - 0s 410us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0129 - val_acc: 0.0093\n",
      "Epoch 88/100\n",
      "958/958 [==============================] - 0s 396us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0278 - val_acc: 0.0093\n",
      "Epoch 89/100\n",
      "958/958 [==============================] - 0s 395us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0518 - val_acc: 0.0093\n",
      "Epoch 90/100\n",
      "958/958 [==============================] - 0s 432us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0314 - val_acc: 0.0093\n",
      "Epoch 91/100\n",
      "958/958 [==============================] - 0s 411us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0194 - val_acc: 0.0093\n",
      "Epoch 92/100\n",
      "958/958 [==============================] - 0s 400us/step - loss: 0.0020 - acc: 0.0010 - val_loss: 0.0239 - val_acc: 0.0093\n",
      "Epoch 93/100\n",
      "958/958 [==============================] - 0s 382us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0500 - val_acc: 0.0093\n",
      "Epoch 94/100\n",
      "958/958 [==============================] - 0s 394us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0090 - val_acc: 0.0093\n",
      "Epoch 95/100\n",
      "958/958 [==============================] - 0s 385us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0154 - val_acc: 0.0093\n",
      "Epoch 96/100\n",
      "958/958 [==============================] - 0s 379us/step - loss: 0.0020 - acc: 0.0010 - val_loss: 0.0117 - val_acc: 0.0093\n",
      "Epoch 97/100\n",
      "958/958 [==============================] - 0s 386us/step - loss: 0.0022 - acc: 0.0010 - val_loss: 0.0106 - val_acc: 0.0093\n",
      "Epoch 98/100\n",
      "958/958 [==============================] - 0s 402us/step - loss: 0.0019 - acc: 0.0010 - val_loss: 0.0364 - val_acc: 0.0093\n",
      "Epoch 99/100\n",
      "958/958 [==============================] - 0s 391us/step - loss: 0.0020 - acc: 0.0010 - val_loss: 0.0190 - val_acc: 0.0093\n",
      "Epoch 100/100\n",
      "958/958 [==============================] - 0s 398us/step - loss: 0.0021 - acc: 0.0010 - val_loss: 0.0188 - val_acc: 0.0093\n",
      "Training Set- Score: 0.003616460582718008, RMSE: 0.06013701507988244\n",
      "Test Set- Score: 0.011549950022488199, RMSE: 0.10747069378434383\n"
     ]
    }
   ],
   "source": [
    "#train a model with 5 days sequence, 1 day future point\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model_short.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also now has the range in a good place.\n",
    "\n",
    "We now use 30 days to predict 30 days out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 917 samples, validate on 102 samples\n",
      "Epoch 1/100\n",
      "917/917 [==============================] - 9s 9ms/step - loss: 0.0432 - acc: 0.0011 - val_loss: 0.2430 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0268 - acc: 0.0011 - val_loss: 0.1091 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0267 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0257 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0098\n",
      "Epoch 5/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0254 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0098\n",
      "Epoch 6/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0245 - acc: 0.0011 - val_loss: 0.2494 - val_acc: 0.0098\n",
      "Epoch 7/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0250 - acc: 0.0011 - val_loss: 0.2669 - val_acc: 0.0098\n",
      "Epoch 8/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0244 - acc: 0.0011 - val_loss: 0.3536 - val_acc: 0.0098\n",
      "Epoch 9/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0242 - acc: 0.0011 - val_loss: 0.4347 - val_acc: 0.0098\n",
      "Epoch 10/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0239 - acc: 0.0011 - val_loss: 0.6170 - val_acc: 0.0098\n",
      "Epoch 11/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0232 - acc: 0.0011 - val_loss: 0.5061 - val_acc: 0.0098\n",
      "Epoch 12/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0234 - acc: 0.0011 - val_loss: 0.5176 - val_acc: 0.0098\n",
      "Epoch 13/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0229 - acc: 0.0011 - val_loss: 0.4239 - val_acc: 0.0098\n",
      "Epoch 14/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0231 - acc: 0.0011 - val_loss: 0.9342 - val_acc: 0.0098\n",
      "Epoch 15/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0230 - acc: 0.0011 - val_loss: 0.5143 - val_acc: 0.0098\n",
      "Epoch 16/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0233 - acc: 0.0011 - val_loss: 0.5511 - val_acc: 0.0098\n",
      "Epoch 17/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0227 - acc: 0.0011 - val_loss: 0.4072 - val_acc: 0.0098\n",
      "Epoch 18/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0233 - acc: 0.0011 - val_loss: 1.2787 - val_acc: 0.0098\n",
      "Epoch 19/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0235 - acc: 0.0011 - val_loss: 0.5751 - val_acc: 0.0098\n",
      "Epoch 20/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0224 - acc: 0.0011 - val_loss: 0.2136 - val_acc: 0.0098\n",
      "Epoch 21/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0228 - acc: 0.0011 - val_loss: 0.3377 - val_acc: 0.0098\n",
      "Epoch 22/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0221 - acc: 0.0011 - val_loss: 0.4926 - val_acc: 0.0098\n",
      "Epoch 23/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0224 - acc: 0.0011 - val_loss: 0.2764 - val_acc: 0.0098\n",
      "Epoch 24/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0223 - acc: 0.0011 - val_loss: 2.2185 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0217 - acc: 0.0011 - val_loss: 0.5344 - val_acc: 0.0098\n",
      "Epoch 26/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0222 - acc: 0.0011 - val_loss: 1.2151 - val_acc: 0.0098\n",
      "Epoch 27/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0215 - acc: 0.0011 - val_loss: 2.4355 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0223 - acc: 0.0011 - val_loss: 0.3676 - val_acc: 0.0098\n",
      "Epoch 29/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0222 - acc: 0.0011 - val_loss: 0.1603 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0220 - acc: 0.0011 - val_loss: 0.2121 - val_acc: 0.0098\n",
      "Epoch 31/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0221 - acc: 0.0011 - val_loss: 0.3464 - val_acc: 0.0098\n",
      "Epoch 32/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.0011 - val_loss: 0.6152 - val_acc: 0.0098\n",
      "Epoch 33/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0213 - acc: 0.0011 - val_loss: 0.7001 - val_acc: 0.0098\n",
      "Epoch 34/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0206 - acc: 0.0011 - val_loss: 0.5386 - val_acc: 0.0098\n",
      "Epoch 35/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0217 - acc: 0.0011 - val_loss: 2.8986 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0224 - acc: 0.0011 - val_loss: 2.7053 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0221 - acc: 0.0011 - val_loss: 2.3915 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0225 - acc: 0.0011 - val_loss: 1.9830 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0223 - acc: 0.0011 - val_loss: 1.3403 - val_acc: 0.0098\n",
      "Epoch 40/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0212 - acc: 0.0011 - val_loss: 0.8802 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0215 - acc: 0.0011 - val_loss: 0.5996 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0211 - acc: 0.0011 - val_loss: 0.4098 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0214 - acc: 0.0011 - val_loss: 0.6104 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0206 - acc: 0.0011 - val_loss: 1.0175 - val_acc: 0.0098\n",
      "Epoch 45/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0221 - acc: 0.0011 - val_loss: 2.8266 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0205 - acc: 0.0011 - val_loss: 1.1185 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0204 - acc: 0.0011 - val_loss: 1.0549 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0207 - acc: 0.0011 - val_loss: 0.7765 - val_acc: 0.0098\n",
      "Epoch 49/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0205 - acc: 0.0011 - val_loss: 0.9072 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.0011 - val_loss: 0.7216 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0211 - acc: 0.0011 - val_loss: 0.3000 - val_acc: 0.0098\n",
      "Epoch 52/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0216 - acc: 0.0011 - val_loss: 0.2664 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0212 - acc: 0.0011 - val_loss: 0.8773 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0202 - acc: 0.0011 - val_loss: 1.5125 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.0011 - val_loss: 1.3344 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0191 - acc: 0.0011 - val_loss: 1.3089 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.0011 - val_loss: 0.4617 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.0011 - val_loss: 0.6854 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.0011 - val_loss: 0.6843 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.0011 - val_loss: 0.7284 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917/917 [==============================] - 1s 2ms/step - loss: 0.0183 - acc: 0.0011 - val_loss: 0.8832 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.0011 - val_loss: 1.6965 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.0011 - val_loss: 0.3479 - val_acc: 0.0098\n",
      "Epoch 64/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.0011 - val_loss: 0.9412 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.0011 - val_loss: 0.2073 - val_acc: 0.0098\n",
      "Epoch 66/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.0011 - val_loss: 1.4747 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0166 - acc: 0.0011 - val_loss: 0.8020 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0170 - acc: 0.0011 - val_loss: 0.3315 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0159 - acc: 0.0011 - val_loss: 0.7145 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.0011 - val_loss: 0.7197 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.0011 - val_loss: 0.4145 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0171 - acc: 0.0011 - val_loss: 0.4097 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0171 - acc: 0.0011 - val_loss: 0.1987 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0160 - acc: 0.0011 - val_loss: 0.5713 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0151 - acc: 0.0011 - val_loss: 0.3083 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0158 - acc: 0.0011 - val_loss: 0.2699 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0145 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0098\n",
      "Epoch 78/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0138 - acc: 0.0011 - val_loss: 0.3592 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0136 - acc: 0.0011 - val_loss: 0.2956 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0147 - acc: 0.0011 - val_loss: 0.2327 - val_acc: 0.0098\n",
      "Epoch 81/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0140 - acc: 0.0011 - val_loss: 0.4273 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0135 - acc: 0.0011 - val_loss: 0.2349 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0135 - acc: 0.0011 - val_loss: 0.3179 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0130 - acc: 0.0011 - val_loss: 0.3202 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0132 - acc: 0.0011 - val_loss: 0.5346 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0139 - acc: 0.0011 - val_loss: 0.2365 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0127 - acc: 0.0011 - val_loss: 0.2612 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0134 - acc: 0.0011 - val_loss: 0.4778 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0134 - acc: 0.0011 - val_loss: 0.3480 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0136 - acc: 0.0011 - val_loss: 0.4921 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.4117 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.3125 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0130 - acc: 0.0011 - val_loss: 0.2991 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0131 - acc: 0.0011 - val_loss: 0.3317 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3052 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.4725 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 0.3810 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 0.3804 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 0.5762 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 0.3331 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.04342681878375235, RMSE: 0.2083910237600275\n",
      "Test Set- Score: 0.2218315914273262, RMSE: 0.47099001202501756\n"
     ]
    }
   ],
   "source": [
    "#train a model with 30 days sequence, 30 day future point\n",
    "seq_length = 30\n",
    "fut_point = 30\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model_months.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That this is not completely bad is nice.  Our magnitude seems to be somewhat more on point.\n",
    "\n",
    "Now, for a very long conmparison, 180 days sequence for 80 days in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 764 samples, validate on 85 samples\n",
      "Epoch 1/100\n",
      "764/764 [==============================] - 16s 22ms/step - loss: 0.1159 - acc: 0.0013 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.1047 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.1018 - acc: 0.0000e+00 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0998 - acc: 0.0000e+00 - val_loss: 0.3174 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0980 - acc: 0.0000e+00 - val_loss: 0.7098 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0964 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "764/764 [==============================] - 7s 10ms/step - loss: 0.0962 - acc: 0.0000e+00 - val_loss: 0.5764 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "764/764 [==============================] - 7s 10ms/step - loss: 0.0940 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0914 - acc: 0.0000e+00 - val_loss: 0.5698 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0873 - acc: 0.0000e+00 - val_loss: 1.8194 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0805 - acc: 0.0000e+00 - val_loss: 1.9321 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0870 - acc: 0.0000e+00 - val_loss: 0.1642 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0836 - acc: 0.0000e+00 - val_loss: 0.2501 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0758 - acc: 0.0000e+00 - val_loss: 0.4283 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0655 - acc: 0.0000e+00 - val_loss: 0.0961 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0509 - acc: 0.0013 - val_loss: 0.0704 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0403 - acc: 0.0013 - val_loss: 0.2344 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0300 - acc: 0.0026 - val_loss: 0.1824 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0225 - acc: 0.0026 - val_loss: 0.2142 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0231 - acc: 0.0026 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0205 - acc: 0.0026 - val_loss: 0.2242 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0342 - acc: 0.0013 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0289 - acc: 0.0026 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0346 - acc: 0.0013 - val_loss: 1.8297 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0462 - acc: 0.0013 - val_loss: 0.1700 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0772 - acc: 0.0013 - val_loss: 0.0726 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0455 - acc: 0.0013 - val_loss: 0.6927 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0758 - acc: 0.0000e+00 - val_loss: 1.1408 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0944 - acc: 0.0000e+00 - val_loss: 0.4754 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0933 - acc: 0.0000e+00 - val_loss: 0.8377 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0895 - acc: 0.0000e+00 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0898 - acc: 0.0000e+00 - val_loss: 0.1027 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0966 - acc: 0.0000e+00 - val_loss: 0.2751 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0979 - acc: 0.0000e+00 - val_loss: 0.3609 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0891 - acc: 0.0000e+00 - val_loss: 1.2516 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0843 - acc: 0.0013 - val_loss: 1.5537 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0503 - acc: 0.0013 - val_loss: 0.3451 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0421 - acc: 0.0013 - val_loss: 0.4055 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0367 - acc: 0.0013 - val_loss: 0.3785 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0631 - acc: 0.0013 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.1042 - acc: 0.0000e+00 - val_loss: 0.7797 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "764/764 [==============================] - 9s 11ms/step - loss: 0.0938 - acc: 0.0000e+00 - val_loss: 0.2435 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0851 - acc: 0.0000e+00 - val_loss: 0.2048 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0816 - acc: 0.0000e+00 - val_loss: 0.9630 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0672 - acc: 0.0000e+00 - val_loss: 0.1638 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0790 - acc: 0.0000e+00 - val_loss: 0.1167 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "764/764 [==============================] - 10s 13ms/step - loss: 0.0563 - acc: 0.0013 - val_loss: 0.3741 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0682 - acc: 0.0013 - val_loss: 0.3658 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.1604 - acc: 0.0026 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "764/764 [==============================] - 9s 12ms/step - loss: 0.1123 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.1062 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.1046 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.1011 - acc: 0.0000e+00 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.1013 - acc: 0.0000e+00 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0942 - acc: 0.0013 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "764/764 [==============================] - 9s 11ms/step - loss: 0.0906 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "764/764 [==============================] - 9s 11ms/step - loss: 0.0787 - acc: 0.0013 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0856 - acc: 0.0013 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.1034 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.1000 - acc: 0.0000e+00 - val_loss: 0.0705 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.0787 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0993 - acc: 0.0000e+00 - val_loss: 0.0605 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0952 - acc: 0.0013 - val_loss: 0.1007 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0986 - acc: 0.0000e+00 - val_loss: 0.0790 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0977 - acc: 0.0013 - val_loss: 0.0834 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0953 - acc: 0.0000e+00 - val_loss: 0.3516 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0941 - acc: 0.0000e+00 - val_loss: 0.3919 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.2772 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0954 - acc: 0.0000e+00 - val_loss: 0.3945 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0967 - acc: 0.0013 - val_loss: 0.4471 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0986 - acc: 0.0000e+00 - val_loss: 0.7673 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0960 - acc: 0.0000e+00 - val_loss: 0.6379 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0965 - acc: 0.0000e+00 - val_loss: 0.9293 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0951 - acc: 0.0000e+00 - val_loss: 1.3939 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0960 - acc: 0.0000e+00 - val_loss: 1.1143 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0947 - acc: 0.0013 - val_loss: 1.9663 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0938 - acc: 0.0000e+00 - val_loss: 1.9977 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0950 - acc: 0.0000e+00 - val_loss: 2.1084 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0920 - acc: 0.0000e+00 - val_loss: 1.9418 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "764/764 [==============================] - 8s 11ms/step - loss: 0.0842 - acc: 0.0013 - val_loss: 1.4238 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0888 - acc: 0.0000e+00 - val_loss: 0.7065 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0931 - acc: 0.0013 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0782 - acc: 0.0013 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0783 - acc: 0.0013 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0722 - acc: 0.0013 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0667 - acc: 0.0013 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0567 - acc: 0.0013 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0333 - acc: 0.0026 - val_loss: 0.2375 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0216 - acc: 0.0026 - val_loss: 0.4443 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0177 - acc: 0.0026 - val_loss: 0.3558 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0475 - acc: 0.0013 - val_loss: 0.0459 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0715 - acc: 0.0013 - val_loss: 0.0496 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0941 - acc: 0.0000e+00 - val_loss: 0.9585 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0872 - acc: 0.0013 - val_loss: 1.0515 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0784 - acc: 0.0013 - val_loss: 0.6712 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0755 - acc: 0.0013 - val_loss: 0.8425 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0773 - acc: 0.0013 - val_loss: 0.8025 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "764/764 [==============================] - 8s 10ms/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 1.2324 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.17618478725371428, RMSE: 0.41974371615750755\n",
      "Test Set- Score: 0.9810804033279419, RMSE: 0.9904950294312141\n"
     ]
    }
   ],
   "source": [
    "#train a model with 180 days sequence, 80 day future point\n",
    "seq_length = 180\n",
    "fut_point = 80\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "dropout = 0.3\n",
    "model_path = 'final_model_long.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is problematic, but not necessarily surprising.  We still seem to run into issues with very long future time points.  This is to some extent due to the fact that it is easier to predict the stock market on a short time window as the market does not change much over a few days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Stock\n",
    "\n",
    "There are actually 30 Dow Jones Stocks.  We need a function to produce a model for a generic csv filepath.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to produce predictions for a generic filepath\n",
    "def generic_stock_predictions(filepath, stock_name, seq_length, fut_point):\n",
    "    \n",
    "    #define variables\n",
    "    train_split = 0.85\n",
    "    neurons = [128, 128, 16]\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    validation_split = 0.1\n",
    "    dropout = 0.3\n",
    "    \n",
    "    #define model path\n",
    "    model_path = stock_name + '_model.h5'\n",
    "    \n",
    "    #read in data frame and drop unnescessary columns\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.drop(['volume', 'unadjustedVolume', 'change', 'changePercent', 'vwap', 'label', \n",
    "             'changeOverTime'], 1, inplace = True)\n",
    "    df.set_index('date', inplace = True)\n",
    "    \n",
    "    #fit model\n",
    "    y_train, y_test, y_train_preds, y_test_preds, train_score, test_score = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    #return\n",
    "    return y_train, y_test, y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-59a59be5020e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-59a59be5020e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    We test this function with our Wal-Mart data.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "We test this function with our Wal-Mart data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "y_train4, y_test4, y_train_preds4, y_test_preds4, train_score4, test_score4 = generic_stock_predictions(filepath,\n",
    "                                                                                                       'WMT',\n",
    "                                                                                                       30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train4, y_test4, y_train_preds4, y_test_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to have a function that looks at predicted profitability on the last day of our data set as we wish to test this for all of the stocks in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted profitability function\n",
    "def predicted_profit(filepath, stock_name, seq_length, fut_point):\n",
    "    \n",
    "    #fit model\n",
    "    y_train, y_test, y_train_preds, y_test_preds, train_score, test_score = generic_stock_predictions(\n",
    "        filepath, stock_name, seq_length, fut_point)\n",
    "    \n",
    "    #get values\n",
    "    start_close = y_test[-1-fut_point]\n",
    "    end_close = y_test[-1]\n",
    "    pred_close = y_test_preds[-1]\n",
    "    actual_profit = (end_close - start_close)*100/start_close\n",
    "    pred_profit = (pred_close - start_close)*100/start_close\n",
    "    \n",
    "    #create dictionary for output\n",
    "    stock_dictionary = {'Stock': stock_name, 'Start Close': start_close, 'End Close': end_close, \n",
    "                       'Predicted Close': pred_close, 'Actual Profit': actual_profit, 'Predicted Profit': pred_profit}\n",
    "    \n",
    "    return stock_dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 3s 4ms/step - loss: 0.0301 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0079 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.0965 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1170 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1715 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1586 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2363 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.3076 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1152 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1040 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2022 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.2474 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1075 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1063 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1040 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1963 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0792 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0565 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0579 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1192 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1167 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0581 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0695 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1089 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0704 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1914 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0971 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0441 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0529 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0586 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0429 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0810 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0412 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1950 - val_acc: 0.0096\n",
      "Training Set- Score: 0.02298800197716516, RMSE: 0.1516179474111332\n",
      "Test Set- Score: 0.0861236231158609, RMSE: 0.2934682659434592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Stock': 'WMT',\n",
       " 'Start Close': 96.74,\n",
       " 'End Close': 96.94,\n",
       " 'Predicted Close': 89.99704,\n",
       " 'Actual Profit': 0.20673971469919666,\n",
       " 'Predicted Profit': -6.970188345129337}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test function\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "dictionary = predicted_profit(filepath, 'WMT', 30, 5)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation\n",
    "\n",
    "There is variation observed in these results from run to run (with the same parameters).  As a quick test, let us look at the results of doing this 10 times with the profitability function on the Walmart data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 4s 4ms/step - loss: 0.0322 - acc: 0.0011 - val_loss: 0.0833 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2162 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2169 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0698 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0284 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2143 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1256 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0491 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0235 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0303 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0689 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1382 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1055 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1560 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0943 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2072 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1898 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0654 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1682 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1203 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1828 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0173 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0199 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0194 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0177 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0449 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0366 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0607 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0161 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0171 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0182 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0201 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0894 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.7684 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2814 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3034 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1482 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1665 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3633 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1786 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1974 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2235 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2563 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0698 - val_acc: 0.0096\n",
      "Training Set- Score: 0.010572359586456933, RMSE: 0.10282198007457809\n",
      "Test Set- Score: 0.029469502927816433, RMSE: 0.17166683700650057\n",
      "Iteration 1\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 5s 5ms/step - loss: 0.0307 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.2249 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.3867 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.4025 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.5866 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.5421 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.7785 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1713 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.4628 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.3639 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.8625 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.6918 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2473 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.4082 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.3119 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.3858 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2448 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1827 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.5565 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.2368 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2413 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2012 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0995 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.4158 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.3800 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.3013 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1764 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0532 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0962 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0393 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0734 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0343 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1721 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1312 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2358 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2523 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1096 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0898 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2266 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2038 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2053 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1808 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1311 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1772 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1652 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1023 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1262 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1190 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0719 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0254 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0388 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2129 - val_acc: 0.0096\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1891 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1637 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1017 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3627 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0161 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0963 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0327 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0486 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.01664086662304516, RMSE: 0.1289994830340229\n",
      "Test Set- Score: 0.11597704854996307, RMSE: 0.3405540317628953\n",
      "Iteration 2\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 5s 5ms/step - loss: 0.0395 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1600 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1016 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.0624 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1802 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1241 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1288 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1271 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1090 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2123 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1785 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0995 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0759 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1477 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1372 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0599 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1871 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2069 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0573 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1235 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1899 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1137 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1022 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1705 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1580 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3638 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1015 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.3516 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3433 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1656 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.8735 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1486 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0919 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0753 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1724 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1150 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0796 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0560 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0308 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0838 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0292 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0234 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0205 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0266 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0771 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.014757539097291345, RMSE: 0.12148061202221261\n",
      "Test Set- Score: 0.08691510817278987, RMSE: 0.29481368382893947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 5s 6ms/step - loss: 0.0323 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1209 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1037 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1428 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1456 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1117 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1689 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0482 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0519 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2000 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1868 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1768 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0963 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0244 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0832 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0889 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1139 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1040 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0985 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0350 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1469 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1762 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1041 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1767 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1026 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2294 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0204 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0550 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3734 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0431 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2954 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0450 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0214 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1414 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0369 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0226 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0252 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0195 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0343 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0720 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2057 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0260 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0394 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0245 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0182 - val_acc: 0.0096\n",
      "Training Set- Score: 0.006019731073711927, RMSE: 0.07758692591997654\n",
      "Test Set- Score: 0.01641433297292046, RMSE: 0.12811843338458545\n",
      "Iteration 4\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 6s 6ms/step - loss: 0.0332 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0260 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1599 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.2077 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.3155 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.3110 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.3362 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.3034 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.5856 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.2763 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.4139 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1721 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2634 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1682 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2085 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1633 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2220 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2114 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.3370 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.3393 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1517 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1089 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1400 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1397 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1236 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1083 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1852 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1060 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0601 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1315 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0872 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1982 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0841 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1628 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1184 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1396 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0720 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1003 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1558 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0796 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2941 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2944 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2663 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1468 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3581 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.4920 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2318 - val_acc: 0.0096\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3224 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3280 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.4548 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3253 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1623 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.6948 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2481 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2641 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2298 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.4041 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2982 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3345 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.03704414550537387, RMSE: 0.19246855718629438\n",
      "Test Set- Score: 0.29063258773606754, RMSE: 0.5391035037319527\n",
      "Iteration 5\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 6s 6ms/step - loss: 0.0429 - acc: 0.0011 - val_loss: 0.0366 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0081 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0079 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.1091 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0962 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2247 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0612 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0990 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2006 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1124 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2080 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.2560 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0997 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1023 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2068 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1987 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0663 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1312 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0889 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1363 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0423 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0639 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0766 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0442 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 1.0504 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0387 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0473 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0605 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0705 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0229 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0612 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1932 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0096\n",
      "Training Set- Score: 0.011220896860154775, RMSE: 0.10592873481805952\n",
      "Test Set- Score: 0.04596735990565756, RMSE: 0.21439999977998497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 7s 7ms/step - loss: 0.0256 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.1081 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1026 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0957 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1485 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1608 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0388 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1027 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1634 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1891 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0771 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1341 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1124 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2283 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0482 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0758 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1419 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0223 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2064 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0808 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0957 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0704 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0706 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0956 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1042 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0692 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0503 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0485 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0958 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1296 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0816 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0646 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0490 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0994 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0699 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0885 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2715 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1734 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0805 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0309 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0178 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1218 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1618 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0792 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0814 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0096\n",
      "Training Set- Score: 0.009010068241220253, RMSE: 0.09492137926315786\n",
      "Test Set- Score: 0.04269788916344228, RMSE: 0.20663467560756177\n",
      "Iteration 7\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 7s 7ms/step - loss: 0.0438 - acc: 0.0011 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.0421 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0841 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1964 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1995 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.2615 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.2680 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.2306 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.3301 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1910 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2486 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.3072 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2676 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2833 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2625 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2253 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1855 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0829 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0733 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2456 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0942 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0872 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0752 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1864 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1396 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1295 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2273 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1030 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0981 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0800 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0759 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0541 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0351 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0689 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0825 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0948 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0511 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0191 - val_acc: 0.0096\n",
      "Training Set- Score: 0.005765992789887465, RMSE: 0.07593413455019728\n",
      "Test Set- Score: 0.013936846051365137, RMSE: 0.1180544198722146\n",
      "Iteration 8\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n",
      "936/936 [==============================] - 7s 7ms/step - loss: 0.0296 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0790 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.0733 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1414 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0997 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1928 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.2381 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2248 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1701 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.2779 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2281 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1150 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1675 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1537 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2328 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2385 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2867 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1945 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0856 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0228 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0736 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1163 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0550 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0431 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1167 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0388 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1200 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1044 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1542 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1922 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1104 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0869 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0593 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1367 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0912 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0584 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0833 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0514 - val_acc: 0.0096\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0096\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0963 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0096\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1004 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2707 - val_acc: 0.0096\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0248 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0366 - val_acc: 0.0096\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0096\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1831 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0470 - val_acc: 0.0096\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0096\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1006 - val_acc: 0.0096\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1192 - val_acc: 0.0096\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0096\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0096\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0410 - val_acc: 0.0096\n",
      "Training Set- Score: 0.007686098145607573, RMSE: 0.08767039492101979\n",
      "Test Set- Score: 0.02816557997594709, RMSE: 0.16782604081592073\n",
      "Iteration 9\n",
      "Train on 936 samples, validate on 104 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 8s 8ms/step - loss: 0.0301 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0096\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0081 - acc: 0.0011 - val_loss: 0.1493 - val_acc: 0.0096\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0096\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0096\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.2300 - val_acc: 0.0096\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2149 - val_acc: 0.0096\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.2017 - val_acc: 0.0096\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.5064 - val_acc: 0.0096\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.4849 - val_acc: 0.0096\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0096\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.4504 - val_acc: 0.0096\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.3618 - val_acc: 0.0096\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1523 - val_acc: 0.0096\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.3537 - val_acc: 0.0096\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.4177 - val_acc: 0.0096\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1395 - val_acc: 0.0096\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0096\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0096\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0096\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0096\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1633 - val_acc: 0.0096\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1297 - val_acc: 0.0096\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0736 - val_acc: 0.0096\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1538 - val_acc: 0.0096\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0096\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0887 - val_acc: 0.0096\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2705 - val_acc: 0.0096\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0096\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1807 - val_acc: 0.0096\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0096\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0997 - val_acc: 0.0096\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1747 - val_acc: 0.0096\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2021 - val_acc: 0.0096\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0096\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0096\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0388 - val_acc: 0.0096\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0096\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1696 - val_acc: 0.0096\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0096\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0096\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0096\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2332 - val_acc: 0.0096\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0096\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0096\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0096\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0096\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1936 - val_acc: 0.0096\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0096\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0096\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0096\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0096\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1026 - val_acc: 0.0096\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1152 - val_acc: 0.0096\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0096\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0737 - val_acc: 0.0096\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0096\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0096\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0096\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0945 - val_acc: 0.0096\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0096\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1296 - val_acc: 0.0096\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0096\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0096\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0096\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0096\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0096\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0965 - val_acc: 0.0096\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0213 - val_acc: 0.0096\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0096\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1743 - val_acc: 0.0096\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0810 - val_acc: 0.0096\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0503 - val_acc: 0.0096\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0396 - val_acc: 0.0096\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2435 - val_acc: 0.0096\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0096\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0096\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1144 - val_acc: 0.0096\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0572 - val_acc: 0.0096\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0697 - val_acc: 0.0096\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1925 - val_acc: 0.0096\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0096\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0096\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0096\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0096\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0096\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1168 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0942 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0096\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0096\n",
      "Training Set- Score: 0.010007301533523087, RMSE: 0.10003650100599824\n",
      "Test Set- Score: 0.05974869324785212, RMSE: 0.2444354582458366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Profit</th>\n",
       "      <th>End Close</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Predicted Close</th>\n",
       "      <th>Predicted Profit</th>\n",
       "      <th>Start Close</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>0</td>\n",
       "      <td>95.444633</td>\n",
       "      <td>-1.339019</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>1</td>\n",
       "      <td>82.609009</td>\n",
       "      <td>-14.607185</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>2</td>\n",
       "      <td>87.471794</td>\n",
       "      <td>-9.580531</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>3</td>\n",
       "      <td>94.318314</td>\n",
       "      <td>-2.503294</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>4</td>\n",
       "      <td>78.312904</td>\n",
       "      <td>-19.048062</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>5</td>\n",
       "      <td>93.001678</td>\n",
       "      <td>-3.864298</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>6</td>\n",
       "      <td>86.849220</td>\n",
       "      <td>-10.224085</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>7</td>\n",
       "      <td>96.656815</td>\n",
       "      <td>-0.085989</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>8</td>\n",
       "      <td>87.342468</td>\n",
       "      <td>-9.714215</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.20674</td>\n",
       "      <td>96.94</td>\n",
       "      <td>9</td>\n",
       "      <td>88.176918</td>\n",
       "      <td>-8.851646</td>\n",
       "      <td>96.74</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Profit  End Close  Iteration  Predicted Close  Predicted Profit  \\\n",
       "0        0.20674      96.94          0        95.444633         -1.339019   \n",
       "1        0.20674      96.94          1        82.609009        -14.607185   \n",
       "2        0.20674      96.94          2        87.471794         -9.580531   \n",
       "3        0.20674      96.94          3        94.318314         -2.503294   \n",
       "4        0.20674      96.94          4        78.312904        -19.048062   \n",
       "5        0.20674      96.94          5        93.001678         -3.864298   \n",
       "6        0.20674      96.94          6        86.849220        -10.224085   \n",
       "7        0.20674      96.94          7        96.656815         -0.085989   \n",
       "8        0.20674      96.94          8        87.342468         -9.714215   \n",
       "9        0.20674      96.94          9        88.176918         -8.851646   \n",
       "\n",
       "   Start Close Stock  \n",
       "0        96.74   WMT  \n",
       "1        96.74   WMT  \n",
       "2        96.74   WMT  \n",
       "3        96.74   WMT  \n",
       "4        96.74   WMT  \n",
       "5        96.74   WMT  \n",
       "6        96.74   WMT  \n",
       "7        96.74   WMT  \n",
       "8        96.74   WMT  \n",
       "9        96.74   WMT  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do function 10 times appending to list\n",
    "dicts = []\n",
    "for i in range(0, 10):\n",
    "    print(f\"Iteration {i}\")\n",
    "    dictionary = predicted_profit(filepath, 'WMT', 30, 5)\n",
    "    dictionary['Iteration'] = i\n",
    "    dicts.append(dictionary)\n",
    "    \n",
    "#create dataframe and display\n",
    "variation_df = pd.DataFrame(dicts)\n",
    "\n",
    "variation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean     89.018375\n",
       "std       5.867988\n",
       "min      78.312904\n",
       "25%      86.972532\n",
       "50%      87.824356\n",
       "75%      93.989155\n",
       "max      96.656815\n",
       "Name: Predicted Close, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe predicted close\n",
    "variation_df['Predicted Close'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is variation in the results.  We get a mean of $89 per share with a range between $78.31 to $96.66 per share.  This is for only 10 trials, but could easily predict either a loss or a profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "While the LSTM performs reasonably well for short time points, and seems to take advantage of the time series feature of the data, there is variation from run to run.  Further hyperparameter tuning could increase performance, but the real issue is that the stock market is simply hard to measure.  For example, this process did better than all the other methods tried in this repository.\n",
    "\n",
    "The difficulty of no excellent known solution, however, make intuitive sense.  If someone does figure out how to predict the stock market, that person will keep the knowledge secret and make a fortune on speculation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
