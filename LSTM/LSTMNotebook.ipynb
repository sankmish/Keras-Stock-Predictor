{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "\n",
    "This notebook is used to develop an LSTM model for predicting Dow Jones stocks.  \n",
    "\n",
    "We will begin with the Walmart stock data as a beginning test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "First, we load important packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some useful packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Now, we can load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "      <td>9105139</td>\n",
       "      <td>9105139</td>\n",
       "      <td>-0.235889</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>64.7739</td>\n",
       "      <td>Jan 27, 14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "      <td>6035231</td>\n",
       "      <td>6035231</td>\n",
       "      <td>0.454305</td>\n",
       "      <td>0.701</td>\n",
       "      <td>65.3045</td>\n",
       "      <td>Jan 28, 14</td>\n",
       "      <td>0.007013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>8440854</td>\n",
       "      <td>8440854</td>\n",
       "      <td>-0.497990</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>61.0517</td>\n",
       "      <td>Jan 29, 14</td>\n",
       "      <td>-0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "      <td>6742046</td>\n",
       "      <td>6742046</td>\n",
       "      <td>0.567883</td>\n",
       "      <td>0.877</td>\n",
       "      <td>65.2975</td>\n",
       "      <td>Jan 30, 14</td>\n",
       "      <td>0.008092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "      <td>10665285</td>\n",
       "      <td>10665285</td>\n",
       "      <td>-0.061155</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>65.3223</td>\n",
       "      <td>Jan 31, 14</td>\n",
       "      <td>0.007147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open     high      low    close    volume  unadjustedVolume  \\\n",
       "0  2014-01-27  64.7650  64.9747  64.5029  64.7825   9105139           9105139   \n",
       "1  2014-01-28  64.8786  65.8746  64.7388  65.2368   6035231           6035231   \n",
       "2  2014-01-29  65.7785  65.8484  64.7126  64.7388   8440854           8440854   \n",
       "3  2014-01-30  65.1232  65.6037  64.9660  65.3067   6742046           6742046   \n",
       "4  2014-01-31  64.5816  65.6911  64.3369  65.2455  10665285          10665285   \n",
       "\n",
       "     change  changePercent     vwap       label  changeOverTime  \n",
       "0 -0.235889         -0.363  64.7739  Jan 27, 14        0.000000  \n",
       "1  0.454305          0.701  65.3045  Jan 28, 14        0.007013  \n",
       "2 -0.497990         -0.763  61.0517  Jan 29, 14       -0.000675  \n",
       "3  0.567883          0.877  65.2975  Jan 30, 14        0.008092  \n",
       "4 -0.061155         -0.094  65.3223  Jan 31, 14        0.007147  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Walmart Stock Data\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get rid of columns we do not need and set the index as the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open     high      low    close\n",
       "0  2014-01-27  64.7650  64.9747  64.5029  64.7825\n",
       "1  2014-01-28  64.8786  65.8746  64.7388  65.2368\n",
       "2  2014-01-29  65.7785  65.8484  64.7126  64.7388\n",
       "3  2014-01-30  65.1232  65.6037  64.9660  65.3067\n",
       "4  2014-01-31  64.5816  65.6911  64.3369  65.2455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnessecary columns\n",
    "df.drop(['volume', 'unadjustedVolume', 'change', 'changePercent', 'vwap', 'label', 'changeOverTime'], 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-27</th>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-28</th>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-29</th>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-30</th>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close\n",
       "date                                          \n",
       "2014-01-27  64.7650  64.9747  64.5029  64.7825\n",
       "2014-01-28  64.8786  65.8746  64.7388  65.2368\n",
       "2014-01-29  65.7785  65.8484  64.7126  64.7388\n",
       "2014-01-30  65.1232  65.6037  64.9660  65.3067\n",
       "2014-01-31  64.5816  65.6911  64.3369  65.2455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set index\n",
    "df.set_index('date', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a0bb24668>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot close price\n",
    "df.plot(y='close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Split Data\n",
    "\n",
    "We need to create a train/test split.  To do so, we will assume we feed sequences of some length and predict at some point in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save data as a matrix\n",
    "data = df.values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sequence length and time in the future\n",
    "#we will start with 30 days and 5 days in the future (about 1 month and 1 week)\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224, 30, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get X data (30 day sequences)\n",
    "X = []\n",
    "#get all sequences up to (sequence length + future point) days out of last point (can then predict last point)\n",
    "for index in range(len(data) - seq_length - fut_point):\n",
    "    X.append(data[index: index + seq_length])\n",
    "#get X as a numpy array\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get Y data (close price for all days except first (sequence length + future point) days)\n",
    "y = data[(seq_length + fut_point):, -1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040, 30, 4)\n",
      "(184, 30, 4)\n",
      "(1040,)\n",
      "(184,)\n"
     ]
    }
   ],
   "source": [
    "#train/test split of 0.85/0.15\n",
    "train_split = 0.85\n",
    "last_row = int(train_split * X.shape[0])\n",
    "X_train = X[:last_row]\n",
    "X_test = X[last_row:]\n",
    "y_train = y[:last_row]\n",
    "y_test = y[last_row:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data\n",
    "We scale the data using the MinMaxScaler fit for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scalers\n",
    "X_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range = (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data so it can be fit\n",
    "X_train_reshaped = np.reshape(X_train, (-1, 4))\n",
    "X_test_reshaped = np.reshape(X_test, (-1, 4))\n",
    "y_train_reshaped = np.reshape(y_train, (-1, 1))\n",
    "y_test_reshaped = np.reshape(y_test, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(-1, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit scalers\n",
    "X_scaler.fit(X_train_reshaped)\n",
    "y_scaler.fit(y_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 30, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform and rescale\n",
    "X_train_scaled = np.reshape(X_scaler.transform(X_train_reshaped), X_train.shape)\n",
    "X_test_scaled = np.reshape(X_scaler.transform(X_test_reshaped), X_test.shape)\n",
    "y_train_scaled = np.reshape(y_scaler.transform(y_train_reshaped), y_train.shape[0])\n",
    "y_test_scaled = np.reshape(y_scaler.transform(y_test_reshaped), y_test.shape[0])\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model\n",
    "Now, we build a basic LSTM network model.\n",
    "\n",
    "We build several LSTM layers together, adding Dropout layers and a few dense layers to summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import layers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 30, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create an LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "#add first LSTM layer and dropout layer\n",
    "model.add(LSTM(256, return_sequences = True, input_shape = (seq_length, features)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#add second LSTM layer and dropout layer\n",
    "model.add(LSTM(256, return_sequences = False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#add an reLU layer\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "#add a final layer\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0414 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1195 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1158 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1006 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1492 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1585 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1257 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1759 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1639 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1575 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1970 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1993 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2106 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2743 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3165 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3284 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2847 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2807 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2751 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3121 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3393 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3016 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3178 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3454 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2965 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2698 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2687 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2809 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2962 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2996 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2953 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3403 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3739 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3225 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2832 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3172 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2520 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2757 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2118 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2121 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1783 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1917 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2183 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1880 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2428 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2015 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1670 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0753 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0431 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0064\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0064\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0064\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0667 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0939 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1705 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0935 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0704 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1804 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0395 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2283 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1566 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2052 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.3024 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0827 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0442 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1895 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1653 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0832 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1042 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1650 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1021 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1816 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1134 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0473 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0992 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0419 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1026 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1041 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0489 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0729 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1664 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0852 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0485 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0942 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0519 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0450 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0529 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0518 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0441 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1042 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1534 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1656 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1421 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0939 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0746 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2634 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1803 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1030 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1715 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1012 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1021 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2188 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.3478 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1879 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.5154 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.7714 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2814 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.4096 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.5145 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 1.1115 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 1.1323 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 1.1300 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.8911 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 1.0515 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2283 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1000 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0064\n",
      "Epoch 300/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1371 - val_acc: 0.0064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2861e6d8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "model.fit(X_train_scaled, y_train_scaled, epochs = 300, batch_size = 64, validation_split = 0.15, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Make Predictions\n",
    "\n",
    "We load the model from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 30, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('first_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the scores and root mean square errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set- Score: 0.02296979169343383, RMSE: 0.15155788232036574\n",
      "Test Set- Score: 0.11483484830545343, RMSE: 0.3388729087806422\n"
     ]
    }
   ],
   "source": [
    "#score models\n",
    "import math\n",
    "train_score = model.evaluate(X_train_scaled, y_train_scaled, verbose = 0)\n",
    "test_score = model.evaluate(X_test_scaled, y_test_scaled, verbose = 0)\n",
    "train_rmse = math.sqrt(train_score[0])\n",
    "test_rmse = math.sqrt(test_score[0])\n",
    "print(f\"Training Set- Score: {train_score[0]}, RMSE: {train_rmse}\")\n",
    "print(f\"Test Set- Score: {test_score[0]}, RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model on training set and test set\n",
    "y_train_preds_scaled = model.predict(X_train_scaled)\n",
    "y_test_preds_scaled = model.predict(X_test_scaled)\n",
    "y_train_preds_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results\n",
    "We now wish to visualize our results.\n",
    "\n",
    "First, we need to denormalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale results\n",
    "y_train_preds_denormed = y_scaler.inverse_transform(y_train_preds_scaled)\n",
    "y_test_preds_denormed = y_scaler.inverse_transform(y_test_preds_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can reshape to the same shape as the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape results for plotting\n",
    "y_train_preds = np.reshape(y_train_preds_denormed, y_train.shape[0])\n",
    "y_test_preds = np.reshape(y_test_preds_denormed, y_test.shape[0])\n",
    "y_train_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create x arrays (just day indices)\n",
    "days1 = np.arange(len(y_train))\n",
    "days2 = np.arange(len(y_train), len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4FNXawH9nk5BOAgkQOgiIQEhCDF1RFAQVFAsCgmIDsVzBDjaKjfvZkateRUVFQa4ooIgFUMACCEjvNQYCKaT3cr4/puxudjd90zi/59lnd2bOzLw7yc47bznvK6SUKBQKhUJREkttC6BQKBSKuolSEAqFQqFwilIQCoVCoXCKUhAKhUKhcIpSEAqFQqFwilIQCoVCoXCKUhCKGkMIMUsIsai25ahphBCXCyHialsOACHEQiHEC/rnS4UQByt5nPeEEM9Wr3SKuoZSEAqXCCFmCCG+L7HusIt1Y2tWurIRQpwQQgwpY8xTQojjQohMIUScEOJLm22/CiHucb+kdvLcIYQo0uVJF0LsEEKMcMe5pJQbpZRdyynTbyX2nSKlfN4dcinqDkpBKEpjAzBQCOEBIIQIA7yA6BLrOutj6wRCCM9yjpsI3AYMkVIGADHAWnfKVk7+1OUJBj4ElgohmpYcVN7vqVBUFqUgFKXxF5pCiNKXBwG/AAdLrDsqpTwNIIR4Swjxj/70u00IcamzAwshOgghpBDiTn18ihBiihCitxBilxAiVQgx32Z8JyHEOiFEshAiSQjxuRAi2Gb7CSHEk0KIXUCWEGIx0A74Vn8af8KJGL2BH6WURwGklGeklO/rx3sRuBSYr+8/X18/QAjxlxAiTX8fYCNDUyHEx0KI0/r3We7iuz8khNgnhGhT2sWXUhYDHwG+wAWGq0r/nmeAj/XjjdAtjVQhxB9CiAibc/USQmwXQmTo1pGPzTY715cQoq0Q4mshRKJ+necLIboB7wH99euQqo81XVX68iQhxBEhxDkhxEohRCubbVL/2x7Wr8t/hBBC39ZZCLFev55JthacovZRCkLhEillPrAZTQmgv28EfiuxztZ6+AtNeTQFvgD+J4TwwTV9gS7AGOBN4GlgCNADuEUIcZk+TgAvA62AbkBbYFaJY40DrgWCpZTjgFhgpJQyQEr5f07OvQm4XQjxuBAixrCK9O/+tP5dH9T3f1B/il8FzANCgNeBVUKIEH23zwA/XfbmwBslT6j77e8ALpNSlhqX0C2Ee4BM4LC+Ogzt2rYHJgshotGUyL26TP8FVgohvIUQjYDlulxNgf8BN7k4lwfwHXAS6AC0BpZIKfcDU9CtGillsJN9r0D729wCtNSPsaTEsBFoCjlSHzdMX/888BPQBGgDvF3aNVHULEpBKMpiPVZlcCnaTXNjiXXrjcFSykVSymQpZaGU8jXAGyjNz/28lDJXSvkTkAUsllImSClP6efppR/3iJTyZyllnpQyEe3mfFmJY82TUv4jpcwpzxeTUi4C/oV2s1oPJAghppeyy7XAYSnlZ/r3WwwcAEYKIVoCVwNTpJQpUsoCKeV6m32FEOJ1/VyD9e/gin76k/oZNKV3g5QyTd9WDMzUr0MOMAn4r5Rys5SySEr5CZAH9NNfXsCbujxfoSlwZ/RBU76PSymz9L/Jby7GlmQ88JGUcruUMg+YgWZxdLAZM1dKmSqljEWzQg0LtABN2bWq4DkVNYBSEIqy2ABcIoRoAjSTUh4G/gAG6OvCsbEghBCPCiH26y6DVCAICC3l+GdtPuc4WQ7Qj9tcCLFECHFKCJEOLHJy3H8q+uWklJ9LKYeg+funAHOEEMNcDG+F9nRsy0m0p+22wDkpZYqLfYOBycDLNjd7V2ySUgZLKUOllP2klGtstiVKKXNtltsDj+rupVT9mrfVZW0FnJL2FTlLym/QFjgppSwsQzZn2F0XKWUmkIx2XQzO2HzORv+7Ak+gWYdbhBB7hRB3VeL8CjehFISiLP5Eu8lPBn4HkFKmA6f1daellMdBS5sEnkRzITTR3RFpaDeAqvIyIIEIKWVjYIKT45YsTVzuUsX6E/b/gF1oSs/Z/qfRbsi2tANOoSmnprZxkRKkoLlZPhZCDCyvXM5ELbH8D/CirlCMl59u3cQDrQ1/v428zvgHaCecB77Luo5210UI4Y/m7jpVxn5G3GeSlLIVmpvsHSFE57L2U9QMSkEoSkV3Y2wFHkFz+Rj8pq+zjT8EAoVAIuAphHgOaFxNogSi+eJThRCtgcfLsc9Z4AJXG4WWvnmtECJQCGERQlyNFj/Y7GL/74ELhRC3CiE8hRBjgO7Ad1LKeGA12g2uiRDCSwgxyPZ8Uspf0dwx3wgh+pbnS5eDD4ApQoi+QsPf+E5oyr0QeEiX90Y0V5IztqAplLn6MXxsFNlZoI0e03DGF8CdQogoIYQ38BKwWUp5oizhhRCjbYL1KWjKqKjsr62oCZSCUJSH9WhBV1v/8EZ9na2C+BHtJnkIzeWQSyXcPi6YDUSjWSSrgK/Lsc/LwDO66+UxJ9vTgafQgtmpwP8B99n4wd8CbtYzb+ZJKZPRrIBH0VwoTwAjpJRJ+vjb0HzqB4AEYFrJE0opfwbuRAskX1yO71AqUsqtaHGI+Wg32CNoQXAjyeBGfTkFLRHA6XWTUhYBI9FSlmOBOH08wDpgL3BGCJHkZN+1wLPAMjQl0wko77yY3sBmIUQmsBKYalikitpHqIZBCoVCoXCGsiAUCoVC4RSlIBQKhULhFKUgFAqFQuEUpSAUCoVC4ZR6XewrNDRUdujQobbFUCgUinrFtm3bkqSUzcoaV68VRIcOHdi6dWtti6FQKBT1CiGEqxn1digXk0KhUCic4jYFIYT4SAiRIITYY7NutF5vpVgIEVNi/Ay9XPDBUmrhKBQKhaKGcKcFsRAYXmLdHrSZnXbNZYQQ3dFmXvbQ93nHtvSyQqFQKGoet8UgpJQbSpT7Ra8tj33tMACuR6s9nwccF0IcQasZ82dFz1tQUEBcXBy5ubllD1YoKomPjw9t2rTBy8urtkVRKNxGXQlSt0Zr3mIQh32pYBMhxGS0KqK0a+dYmDIuLo7AwEA6dOjgTBEpFFVGSklycjJxcXF07NixtsVRKNxGXQlSO7uTOy0SJaV8X0oZI6WMadbMMUsrNzeXkJAQpRwUbkMIQUhIiLJSFQ2euqIg4tAalhi0QasxXymUclC4G/U/pjgfqCsKYiUwVu+j2xGtR/GWWpZJoVDUJ1atghMnaluKBoU701wXowWZuwoh4oQQdwshbhBCxAH90Zq9/wggpdwLLAX2AT8AD+j16esdycnJREVFERUVRVhYGK1btzaX8/Pzy3WMO++8k4MHD5Y65j//+Q+ff/55dYjMihUriIqKIjIyku7du7NgwYJSx69bt45NmzaVOubaa6/l0ksvLfPc586d47333quQvCWZMGECy5cvr9IxFPWcoiIYMQIGVqVZn6Ik7sxiGudi0zcuxr8IvOgueWqKkJAQduzYAcCsWbMICAjgscfse9VIKZFSYrE4188ff/xxmed54IEHqi4skJeXx3333cfWrVtp1aoVeXl5nDxZ+iTLdevWERoaSr9+/ZxuT05OZvfu3fj4+BAbG+s0mcDAUBBTpkyp0vdQnOfEx2vvpyvtmVY4oa64mBo8R44cITw8nClTphAdHU18fDyTJ08mJiaGHj16MGfOHHPsJZdcwo4dOygsLCQ4OJjp06cTGRlJ//79SUhIAOCZZ57hzTffNMdPnz6dPn360LVrV/744w8AsrKyuOmmm4iMjGTcuHHExMSYyssgLS0NKSVNmzYFwNvbmwsvvBCAs2fPcuONNxITE0OfPn3YtGkTR48eZcGCBbzyyitERUWZ57Llq6++YtSoUYwZM4Yvv/zSXH/mzBmuv/56IiIiiIyMZPPmzUyfPp2DBw8SFRXF9OnTWbNmDaNGjTL3mTJlCosWLQJg5syZ9O7d27yOqtmVwsRQEP7+tStHA6OupLm6hWnToMT9sMpERYF+X64w+/bt4+OPPzZdKnPnzqVp06YUFhYyePBgbr75Zrp37263T1paGpdddhlz587lkUce4aOPPmL69OkOx5ZSsmXLFlauXMmcOXP44YcfePvttwkLC2PZsmXs3LmT6Ohoh/2aN2/OsGHDaN++PVdeeSUjR45kzJgxWCwWHnroIZ544gn69evHiRMnGDFiBHv27OGee+4hNDSUadMcOmoCsHjxYl5++WWCgoKYMGECjz+utY9+4IEHGDp0KA8++CCFhYVkZ2czd+5cjhw5YiquNWvWuLx+U6dOZfbs2UgpufXWW/nhhx+4+uqry3fxFQ2b7OzalqBBoiyIGqRTp0707t3bXF68eDHR0dFER0ezf/9+9u3b57CPr6+veRO8+OKLOeEiCHfjjTc6jPntt98YO1ZrDRwZGUmPHj2c7rtw4UJ+/vlnYmJimDt3LpMnTwa0m/WUKVOIiopi1KhRpKSkkJOTU+p3PHXqFLGxsfTr14/u3btTVFTEgQMHAPj111+59957AfD09KRx48alHqska9eupU+fPkRGRrJ+/Xr27t1bof0VDRjj/7K4uHblaGA0aAuisk/67sLfxvw9fPgwb731Flu2bCE4OJgJEyY4zatv1KiR+dnDw4PCwkKnx/b29nYYUxEXTEREBBEREdx6661069aNBQsWmFaJrQxl8eWXX5KcnGxOIEtLS2PJkiXMmjULKDs91NPTk2KbH7lxTbKzs3nwwQfZvn07rVu35plnnlHzEBSsXg0XXQQdlYJwC8qCqCXS09MJDAykcePGxMfH8+OPP1b7OS655BKWLl0KwO7du51aKOnp6WzYYC2NtWPHDtq3bw/AkCFD+M9//mO3DSAwMJCMjAyn51y8eDFr1qzhxIkTnDhxgi1btrB48WIABg8ebLrXioqKzGtge6z27duzd+9e8vPzSUlJYd26dQDk5ORgsVgIDQ0lIyODZcuWVfq6KBoO11wD4eEoC8JNKAVRS0RHR9O9e3fCw8OZNGkSA92Qnvevf/2LU6dOERERwWuvvUZ4eDhBQUF2Y6SUvPzyy3Tt2pWoqCheeOEFPvroI0BLpf3999+JiIige/fufPDBBwBcf/31LF26lF69etkFqY8ePcqZM2eIibEW6u3SpQve3t5s27aN+fPn8+OPP9KzZ09iYmI4cOAALVq0ICYmhp49ezJ9+nQ6duzIqFGj6NmzJ7fffrsZNwkJCWHixImEh4dzww030Ldv32q/Xor6haELsrOxxiCUgqhWRH3OBImJiZElGwbt37+fbt261ZJEdYvCwkIKCwvx8fHh8OHDXHXVVRw+fBhPzwbtWawx1P9a7ZKRAUYYS857Gx56CIRQSqIcCCG2SSljyhqn7hQNmMzMTK688koKCwuRUvLf//5XKQdFg8HOy5mVZf08Y4amKF56qcZlamiou0UDJjg4mG3bttW2GAqFW7BTECkp2ruUMHeu9lkpiCqjYhAKhaJeYqcgUlNrTY6GjFIQCoWiXtJQFMS5c+f47LPPalsMpygFoVAo6iVOXUz1kDFjxnD77beXWQOtNlAKQqFQ1EsaigWxa9cuQGuXXNdQCqKaOd/LfS9YsIBmzZoRFRVFt27dzDkVlcW2lHdZ16WkXNV5jRR1D1sFUZySCk2a2A8o5++ttknVlVuWbSZWHUFlMVUzqtw3jB8/njfffJMzZ84QHh7OddddR2hoqLm9sLCwUum2ZV2XknJV1zVS1E3sjIaUFGjTxt7VVFAAFSgTU1sYD451UUEoC6KGOJ/KfRuEhYXRoUMHYmNjeeaZZ7j33nsZOnQod955J4WFhTzyyCP06dOHiIgI02opLi7m/vvvp3v37owcOZKkpCSH6wKwatUqoqOjiYyM5KqrrnIql+012r59O3379iUiIoKbbrqJtLS0Uq/d7t276d27N1FRUURERHDs2LHK/NkVbsRaq1Ei0lKhTx/7AfVsEnBmZmZti+BAw7Yg6li97/Ol3LfBkSNHOHnyJBdccAEAf//9Nxs2bMDHx4d33nmH5s2bs2XLFvLy8ujXrx9XXXUVmzZt4vjx4+zZs4fTp0/TvXt3h2ZCZ86c4b777mPjxo20b9+ec+fO0bRpUwe5vv/+e3OfCRMm8P7773PJJZfw1FNP8fzzz/Pqq6+6vHbvvPMOjz32GGPGjCEvL0/1nqhjSAl6mxD8yEYUFkLXrtrv/aWXYOnSeqcg6qIF0bAVRB3DWbnvDz/8kMLCQk6fPs2+ffscFETJct8bN250emxX5b6ffPJJoOxy37t27WLNmjXMnTuXtWvXsmDBAtasWWPn8y9PuW+Azz//nPXr19OoUSMWLFhAcHAwoNVw8vHxAeCnn35i//79LFmyBNAU4eHDh9mwYQPjxo3DYrHQpk0bLr/8cofj//nnnwwePNgsKmhYP65ITk4mNzeXSy65BICJEydy2223mdudXbsBAwbwwgsvcPLkSW688UY6d+5c5vdW1Bxnzlg/N0F3KwUHQ2Qk9O2rKYh6UHIj26aPRVpaGgVFBUgkjTzqhmusYSuIOlbv+3wo9w3WGERJbL+/lJJ33nmHK6+80m7MN998U2ZJcCllmWNKji8NZ9futttuo3///qxatYqhQ4fyySefMGjQoHKfU+FejLYob74JH0zTgxH6gwhGbK8eWBBnz541PyclJdF1fleCfIL4+96/a1EqKyoGUUs01HLf5WXYsGG888475g354MGD5OTkMGjQIJYsWUJxcTGnTp1i/fr1DvsOHDiQdevWmcH0c+fOlSpXaGgovr6+Znzhs88+47LLLitVvmPHjtG5c2emTp3Ktddea6YiKuoGeiiObt2sFkSWVzDr16PVYYJ6YUEcOnTI/JyUlMTx1OPsOFPNbvEqoBRELdEQy31XhHvvvZcuXboQFRVFeHg49913H4WFhdx88820a9eO8PBwHnzwQadP7S1atODdd9/l+uuvJzIykvHjx5cp12effcbDDz9MREQE+/bt45lnnilVvi+++IIePXoQFRXFsWPHmDBhQqW+p8I9GA/eF14IwWgWxOMvNeHyyyEnv/5YEEePHjU/p9TFyX5GymV9fF188cWyJPv27XNYd75SUFAgc3JypJRSHjp0SHbo0EEWFBTUslQNB/W/Vnvcd5+UgYFSFhRIOcnnUylBhvscliBl9v+9LSVImZBQ22KWyuHDhyUgARkWFibHjR8nmYVkFm4/N7BVluMe27BjEOc5qty3oqESGwtduoCnJ4RYtCfv+Fw9BmG4mOq4BWH0iwdt/lRGTtXctu5A3S0aMKrct6Khkp0NRs5DM5FEMYIUtJnUxUJ3MdXxGIS0UWABAQF1UkGoGIRCoah3ZGXZKAiZQKZPKMV4ACBl/bAgbDPx/P39ycy1TpRLyErg812f1/r8G7cpCCHER0KIBCHEHpt1TYUQPwshDuvvTfT1QggxTwhxRAixSwjhOKNLoVAodLKzwc9P+xxKIuk+zc1tUtSPILVtqR1/f3+y8qwT5WasmcGEbyawMdb5vKeawp0WxEJgeIl104G1UsouwFp9GeBqoIv+mgy860a5FApFPcfWggjKTeBQqo2CoH6kuTooiHyrgkjK0UrMnEg9UdNi2eE2BSGl3ACcK7H6euAT/fMnwCib9Z/qAfZNQLAQoqW7ZFMoFPUbWwsipDiBRJqZ2+qLBWG4mHx9ffH39yenwFql4GSqNsdHUP4Joe6gpmMQLaSU8QD6u6H2WwP/2IyL09c5IISYLITYKoTYmpiY6FZhK0N1lPsG+OijjzhjW0/Aht9//52+ffuaJbWff/75Uo+1fft2fvjhh1LHPPDAA7Rr165Mn2dxcTFzjZ6/lcS2iJ5CURmysqwKohmJdgqiuJ5YEEVFRQA0a9bMQUHsSdjjarcapa4EqZ2pSad3Kinl+1LKGCllTLNmzZwNqVWMct87duxgypQpPPzww+ZyRUpWlKYgJk6cyIcffsiOHTvYs2cPN910U6nHKktBFBUVsXLlSlq2bMnvv/9e6rGqQ0EoFFVBSpssJikJIo1Ugq3bqR8WhFFDbNasWZqCKLQqiCKpKY/CYueldWqKmlYQZw3Xkf6uT5gnDmhrM64NcLqGZXM7n3zyCX369CEqKor777+f4uJiCgsLue222+jZsyfh4eHMmzePL7/8kh07djBmzBinlkdiYiJhYWGAVj/IKPCXmZnJHXfcQZ8+fejVqxfffvstOTk5zJkzh88//5yoqCi++uorB7nWrFlDr169mDx5MosXLzbXZ2RkMHHiRHr27ElERATLly9n+vTpZGRkEBUVxe23386RI0eIiooy95k7dy4vvPACAO+99x69e/cmMjKS0aNHl6vQn0JRGocOwf33a8aBnx+QnY0HxaTT2BxTX2IQISEhtG3bljvvvBN/f3+KLY7yFhTXbpe5mp4HsRKYCMzV31fYrH9QCLEE6AukGa6oqjBt2jSH/gdVJSoqqlLukT179vDNN9/wxx9/4OnpyeTJk1myZAmdOnUiKSmJ3bt3A1p3qeDgYN5++23mz59vd/M1mDZtGl26dGHw4MFcffXV3H777Xh7ezNnzhyGDx/OwoULSUlJoW/fvuzatYvnnnuOPXv2uJR78eLFjBs3jquvvpqZM2fy1ltv4enpyaxZs2jWrBm7d+9GSklqaiojRoxgwYIF5nU9cuSIy+88evRos1T39OnTWbhwIffdd1+Fr51CYTB2LPyt17Hz98dsK5dBoDnGVBB13IJIT083rQh/f3+nd+MGa0EIIRYDfwJdhRBxQoi70RTDUCHEYWCovgzwPXAMOAJ8ANzvLrlqizVr1vDXX38RExNDVFQU69ev5+jRo3Tu3JmDBw8ydepUfvzxR4daSc6YPXs2f/31F0OGDOHTTz/l2muvBbQS2i+++CJRUVEMHjyY3NxcYmNjSz1WXl4eP/30E9dddx3BwcFER0ezdu1aU2ajK5sQgiYlWzqWwa5du7j00kvp2bMnS5YsYa+1w4tCUSls7/l+fkB6OoCdBVFcD4LUxcXFfPfdd2Ymk7+/P3g5jisocrQgNm7cyKhRo1xWdq5O3GZBSCnHudh0ZckVem2Qau8PWZcCoVJK7rrrLqcB5V27drF69WrmzZvHsmXLeP/998s8XufOnencuTOTJk0iJCTE7Ay3fPlyOnXqZDfWtlprSVatWkVaWprZKyIrK4umTZsybNiwcpXV9vT0pNjGlM/NzTXLedx+++2sXr2a8PBwFixY4LKPtUJRXvTK7AAkJeHcgpB138W0c+dOQGuiBeDn52fejVv4t+BsllaN0JkFcffdd3P48GH27dtHRESEW+WsK0HqBs+QIUNYunSp2UIzOTmZ2NhYEhMTkVIyevRoZs+ezfbt24HSS2qvWrXKzDY6dOgQ3t7eBAYGMmzYMObNm2eOM/75SjvW4sWLWbhwISdOnODEiRMcO3aM1atXk5uby1VXXcX8+fMBTcGlpKSYN3/j6SUsLIzTp0+TkpJCbm4uq1atMo+dlZVFWFgYBQUFfPHFF5W+dgqFgW2ex/XXU2csiH/++Ye77rrLaU8XZxhxxUceeQSwVxBpcWnmOGcxCCM5x2hu5U6UgqghevbsycyZMxkyZAgRERFcddVVnD17ln/++YdBgwYRFRXFpEmTeOmllwC48847ueeee5wGqRcuXGiW577jjjv44osvsFgszJw5k+zsbHr27EmPHj2YNWsWAFdccQU7d+6kV69edkHqzMxM1q5da3asA02Z9O3bl1WrVjFz5kzOnj1LeHg4UVFRZje7u+++m4iICG6//XZ8fHx46qmn6N27N9ddd51dR7w5c+bQp08fhg4d6tApT6GoDLYWRLdumBaEXZC6FiyIp556io8//phly5aVa7zRXvS6664DdAWhu5hyE6xKxpkFYZSyr2pPlnJRnpKvdfWlyn0rahP1v1bzDBqkVfLGqIj92WdSguzMIXN93Otfah/27q0xuf71r39JQL7xxhvlGr9ixQoJyK1bt0oppdywYYPkCqRllkVyHWbZ7+fWPWe3X3FxsVki/N133620vJSz3LeyIBQKRb3gxAlrBpMZZnPmYqqFNFfD7VPeybtvvPEGYG3Da7iYGlkagU02eEkLwtZqqAkLQikIhUJR54mLg44dNY/SQw+BWcVev0kGtXYSpK7BGERAQAAA2dnZ5Rr/66+/AppL13z3AlEkwCaMUTIGkZycbH5WCkKhUJz3FBeD/sANwOjRYGaDp6eDhwfrt/jy6qv6eGq+H4S3HhwpK0i9du1ac8KoEILWrbWKQqGhoeAJOek56B1UAcc0V1sLpWVL95erUwpCoVDUGdauhYMH7dctWgSvv25dtquwk5EBgYG0bCW44AJtlayFjnJGdl9eXh6gTSC99dZbzWA0aFmFQ4YMYcSIEYCW7GEQHBysBakLgaNotSWAYmmv5IwJqgcOHKiRSaeqo5xCoagzDBmivdve27dssX7u3h3atbPZIT0dGmvxB6N6dm3UYpL6uXJzc8nPz6dLly4ADBo0yKwmkJKitUZdt24dALfeequ5v8ViwcvPi4KCAsgGFkCTuU2QJUrSrVy5klatWtG5c2d3fyVAKQiFQlHH0YueAuAwGV+3IMCqIIprIc3VmCyam5trNz8hISHB/FyyH7xRZsPA4mXRLAgdIYSDBZGcnEyPHj3w8PCoJslLR7mYqpn6Vu57zZo1BAUFmcd68cUXyy2jM2xLeT/99NP88ssv5Zbrm2++4ZVXXqnS+RUNi8OH4b33tM8rVjgZ4MSCKK4FC8JQEN988w1du3Y11ycnJ7Np0yby8vIcqhI0b97cbll4CTsFYcHiUH4/PT2dxo0bU1MoC6KaMcp9g1bGNyAggMcee6zCx/noo4+Ijo42q7baMnHiRJYvX054eDhFRUUcLOm0LcH27dvZs2cPw4eXbPCnMXjwYJYvX05mZiYRERGMGDGCyMhIc3thYaHD0095KEvZlJTrhhtuqPA5FA2be+7R3r29QZ9TZk9GBgRrpb7N0EMtpLkW2Zo5NixYsIB58+bx1ltv2U0Wvfzyyx2DzF5AicQkWwti1qxZ7Nu3j759+1aX2GWiLIgapK5MrcCQAAAgAElEQVSW+zYICAggOjqao0ePsmDBAsaOHcuIESPMmdZz586lT58+REREMGfOHHO/OXPm0LVrV4YOHcrhw4fN9RMmTGD58uUAbN68mf79+xMZGUnfvn3JyspykGvBggVMmzYNgOPHjzN48GAiIiIYOnQocXFx5jGnTp3KgAEDuOCCC/jmm28AOHXqFJdccglRUVGEh4ebs00V9RvDkxIa6mJAerqDi6k2OsoVu1BGRtrr2bNnzQA24LyygCd2FoQslmYMoqioiNmzZwNUqK9MVWnQFsS0H6ax40w1l/sOi+LN4Q2r3LdBYmIiW7Zs4cUXX2Tjxo38+eef7NixgyZNmvD9998TGxvL5s2bkVJyzTXXmN9l2bJl7Nixg/z8fKKioujfv7/dcXNzcxk7dizLli0jOjqatLQ0fHx8HORasGCBuc/999/PPffcw/jx43n//feZNm2aqdwSEhL4/fff2b17N7fccgs33HADixYtYuTIkTz55JMUFRWp3hMNgO+/B8ND+fTTLgY5czHVYgzClmuuuYbvv/8egJdeesmcFAf6xLgSSE9ppyCKi4pNC+LcOWv35ltuuaW6xC4TZUHUEHW13DfAL7/8Qq9evRg+fDjPPvus6UO96qqrzBLfP/30E6tXr6ZXr15ER0dz5MgRDh06xIYNG7jpppvw9fUlKCiIkSNHOhx///79tGvXjujoaACCgoLKDLJt3ryZsWPHAlpVWKMOFMCoUaMQQhAREcGpU6cA6N27NwsWLGD27Nns2bPHnLikqJ98/DHo/9YAuMzoLC1IXYsWhJSSC4y8Wx3blFcfHx+HY+QX54PNtAej3AVY5z8sXryYK664orrELpMGbUFU5knfXcg6Wu4brDGIktg+8UgpeeaZZ+xytwFeffXVMkuCy3KUDa8I3jYV24wf0BVXXMGvv/7KqlWrGD9+PDNmzGD8+PHVdk5FzXLXXdbPK1e6GCSlpiB0C8L4F6uNILWrGIQr9u/f77BOemgWxNKlS7nlllsoyC8wLQhDQdR0m2VlQdQQdbXcd3kZNmwYH374ofkUFBcXR1JSEoMGDeLrr78mNzeX9PR0vvvuO4d9e/TowcmTJ83vlp6eTlFRUaly9evXj6VLlwKwaNEiBg0aVKp8J0+eJCwsjMmTJ3PHHXeY311Rv5k0CZwYpRpZWZoSKBmDqIUgtWFBLFy40ExKmTFjBk899RQrnKRflUz6kFKCN5CHOcchKzOLgkLNpKgtBdGgLYi6hG257+LiYry8vHjvvffw8PDg7rvvNp+y//3vfwPWct++vr5s2bLFLjC1cOFCHn74Yfz8/PDy8rIr9z1t2jR69uxJcXExnTt3ZsWKFVxxxRW88sor9OrVi6effpqbb765wvJfc801HDhwgH79+gGa0vniiy/o06cPN9xwA5GRkXTo0MHpjdzb25vFixdz3333kZubi6+vL+vWrXOQy5b58+dz99138/LLL9OiRQs+/vjjUuVbu3Ytr7/+Ol5eXgQEBLBo0aIKf0dF3cLfH2bOLGWAXqivLqW53nrrrXh5aXW7W7VqxYsvvsjJkycdxpdMPMktzAUP7BQEEjKzMgFrie+aVhC1XrK7Ki9V7ltRm6j/terHKNkNUsbFlTH4wAFt4OefSyml3LBBW9z26jrtwy+/uF1egzlz5khAFhYWOt3eu3dvs0w3IF944QW77fEZ8ZJZyNc3vi6llNq4qchh7w6Tqamp5n75+fnVIi/lLPetLAiFQlFnaNQI8vPhu+9Ar2PnGmMiqZ4DWxcsCKPHdEm2bNlixuH27t1rN5kOID1Ps4aaN9Ymzz344IPMZz5nEs6wZ88ec5xhndQUKgahUCjqDFLCjBn2GUwuOXRIe7/wQsAmSF0Laa5GkLq0ZIyxY8cSEhJC9+7dHbL4ErK0khyhfpqye/vtt/GweJCZmWmmuF5brotSvTRIBSFr8MlBcX6i/sfcQ3Gx1RIok/h47V03NRyC1DVsQZSVur148WIzSaUk8Rnad2kZaJ1d7WHxIC8/z1QQRgLKa3+8hpgtyC8qf+meytLgFISPjw/JycnqB6xwG1JKkpOTneayK6pGhRREUpLWGEJ3uzi4mGo4i8mVe6k8xGdqCqJVYCtznYfFg/z8fFOphISEAPD8Bi1VPis/C3fT4GIQbdq0IS4urtyt/xSKyuDj40ObNm1qW4wGhRGerpCCsKnBYTzAFxbVjgVRFQVxOuM0XhYvQnxDzHUWDwt5BXmcOHGCoKAgs0ifUX6jZKVXd9DgFISXlxcdO3asbTEUCkUFMe7nlVUQxvzJ/MLaCVKXpiD+jv+biBYReFicu6HiM+MJCwizi2F4WjwpKCjgxJkTtG/f3txmeEeUi0mhUJw3GB6hqiqIvPzaCVK7UhCHkw8T/X4009dMd7n/oeRDdGxi/2DrYfEgOyeb+Ph4070EVgtCKQiFQnHeUF0KYuac2rEgXAWpE7M1d/fKQ65qhmgKonuofYXXzAxtkty2bdu0lqQlyCvKc1hX3dSKghBCTBVC7BFC7BVCTNPXNRVC/CyEOKy/N6kN2RQKRe1QVQVh5AzUVqkNVxZEUrYWZDZSWUtSUFTAuZxzhAXY934JDQ3F+Cq2RTwbtItJCBEOTAL6AJHACCFEF2A6sFZK2QVYqy8rFIrzhAopiOxsyMlxakHUxkS5efPmkZqa6nSbkcJqTIYrSXJOMgDN/O3LaDQLbYanlxYmtu0i19BdTN2ATVLKbCllIbAeuAG4HvhEH/MJMKoWZFMoFLWEoSDKVfjXmE/gREHUhgVRGnsTtUbaAY2cl6BPzNIL8fnZKwghBBYP7RbtrIJxQ1UQe4BBQogQIYQfcA3QFmghpYwH0N+bO9tZCDFZCLFVCLFVpbIqFA2HCmUxlUdB1JAF4ap3vMHKg1rsITM/0+n8LCNGUdKCsAiL6bayrf7aoC0IKeV+4N/Az8APwE7s+iiVuf/7UsoYKWVMjVc2VCgUbqNCLiYnCqK2+kHMmDHDbllKSWqu5m7KK8wjNi0WPy8/imUx2QXZDvsbMQqjzIaBQCAs2pdy1hO+QSoIACnlh1LKaCnlIOAccBg4K4RoCaC/O4/oKBSKBklVFQTAAw/UvIvJaMjVu3dvABbvWUyTfzdh19ldnEw7iUQS2SISgLS8NIf9XbmYLMLiVEEYVkhBUQHupraymJrr7+2AG4HFwEpgoj5kIuDYZUOhUDQ8vvkGsrIcFcSnn8LQobB1K6xYAR06gN5ilmQtsFtSQcyfD81b1JwFUVhYyLFjxwD48ssvAVh9ZDUA60+s53jKcQDCm4cDkFPg2CvdcDGF+IXYrRdCmFlMtgrCmEFdJCvWxa4ylDmTWgjRAngJaCWlvFoI0R3oL6X8sArnXSaECEHrwPqAlDJFCDEXWCqEuBuIBUZX4fgKhaI+sHMn3Hgj3HUXxXO1W4qpIN55BzZvBj8/OHlSe61bB7fdplkQQkATx2x4P/+asyBsOzgaFRwM109mfibHUzUF0S20G6A3BipBYlYiTX2b4mmxvx1bhMWpgjAUQ1FxHVAQwELgY8Bo+XUI+BKotIKQUl7qZF0ycGVlj6lQKOohx7UbKDt3OloQmdpEMfbsgUI9TJmSor0nJUHTptYCTDb4+NWMBZGQkMCjjz4KYLYZBasSSMlN4VzOORp5NDJnSTtVENmJDu4l0GIQpVkQNVGLqTwuplAp5VKgGEBPTXW/6lIoFA0fI5ZQXMzs2dpHs015XJz2npJiXblzp3W/Eu4lA8OCSE507w100qRJ5udXXnnF/JySk2K+/3j0R3o274mflx/gfPZzYnaiQ4Aa9BiEcB2krgkXU3kURJbuDpIAQoh+gGOkRaFQKCpKju6Tz87m3Xe1j6dPoymEtDStxVxKChiT0D76CM6dK11BBGi3teeelfzxB/z6q3tEP3LkCIBD2XcjgyklN4WErASiW0bj7aHl4DqzIJKykxxSXMF1DMKgJlxM5VEQj6AFkDsJIX4HPgX+5VapFArF+YGuIIozrb0NMjKwthPtpvnu7dxFsbGlKggfX+2ump5WzMCBMHgwfP019O1bPV6ngoICCgoK2LdvH2A/yxmsM6ZTclPILsjG38sfH09NieQV2lsQ2QXZnEw9SZi/fZkN0GMQOs5ajdYJC0JKuR24DBgA3Av0kFLucrdgCoXiPEBXEAWpJRSEEX9o18469v77tffTpyEx0aWC8PDUFITAqg1uvhm2bIG8Eh4e4zQVYcCAATRq1Mhcvvvuu+225xRq3yklJ4Wcwhz8vPzw9tQsiGu+uIbvDn1njl26dykZ+RmMjxjvcB6BwMPLdZe6OmFBCCEeAAKklHullHuAACHE/W6XTKFQNHx0BeGVlYpFD20WFwNZusLQ24kCEK6linLttVq70c6dnR7S11+7rdkqCMNyKLCZOrB2LQQGwvr15Rc3OzubrVu3msszZszghRdesP9KeiprQlYChcWF+Hr5mhYEwOj/WRM09yfup5FHIwa0HeBwLouwEBgYCEBamqNXv64EqSdJKc0qVFLKFLRiewqFQlE1srWZxRYkTUjhySe1uQzGejsF0aOH/b6XOiRDAnDzaKEf0/EGWlCgWRHbt2tZtFAxBfHdd9/ZLb/00ksOVVwNC+JUhjZnw8/LzwxSgxaHSM9LJzErkWOpx+gQ3MHOnWRgW4spO9txBnadmAcBWIQQQurT94QQHkCjMvZRKBSKssmxThxrRiJz5+puoz+dWBA2Ja8BiIlxesjIXo4WhEG7dnDddbB4sXVdeadLFBcXM2bMGAB+//13unbt6jCmsLiQwmL7ykF+Xn4OWUpBc4O4KPQivCxeXBhyodPz2dZicqog6oKLCfgRbQLblUKIK9BmPf/gXrEUCsV5gY2CCCHZut5wMUVHW9d16mT9/Mgj1up8JRGuLYisLFiyxHbN38yeLcyAszOklDz33HP8apMOFRERYdflzcDIUmoV2MpcF+wTbGdBGBxIOsDuhN10DXFUNGBfi8lQELZupToRpAaeBNYB9wEPoPVqeMKdQikUiobPtm2w7HN7C8LEeGIODYWiIi2IEGBTLvu111wf2GK1IG65xXHzADt3/+eAo+vIliNHjvD8888zdOhQc52/v7/TsUb8wVZBdAzu6HSsgSsFYREWAgK173z55ZcD9vWX6sRMaillMfCu/lIoFIpq4bnn4EGyiSeMlpzhveeTrBsNC8Lf37563+rV1hRYV+gWxF0Ti+m/EJYutd+sl07S0W64tllJJTEUQ7GNL0q4aFphxB9aB7ZmK1ow2+gUl/BYAv6N/PF/yV65dA11YUEIga+fL2lpaWYqrW0F11q1IIQQS/X33UKIXSVfbpdMoVA0aCwW8CWHf2gLQAsPFwrCluHD4Y47Sj+wfvPu38/5pIf4eNslTUH8+eefCCHYvn27w/iTJ0/aLa9Zs8blqZ1ZEEajoGb+zfDz8sPX09duH6NOU0kswoJE2s2zKCi2WhA1kcVUmgUxVX8f4XYpFArFeUeHDpqCOEdTsvDDP8lGQWRng6cnOJkgViaW8tdiEiIfKWH1aq0C67p164i2jXsA4eHh7Nmzx1xu2rSpy+MZFkTLgJbmupLxh4MPHuRczjme+eUZNsVtcjqLGrQYREklYGdB1GaQWkoZr2csfSilPFny5XbJFApFgyYnR1MQOfiSRKi1LhNoFoQLP3+ZCPtqrqX1lxg4UDtHUZH1Zpuens4TTzxBbq4WcO5kGxzHcea0Lc4sCNs5EABtg9oSGRbJ8jHLOfXIKZfHsgiLQwe6OuNiApBSFgHZQoig0sYpFApFRUlJsSqIFI9qVBAlLAgnZYyYMQP+/hu+/VarEGibRvrqq6/yyiuv8N///lcXJctuX2PymjMMC8JWQbiKV3hYPGjk4Tr2YREWByVQZywIG3KB3UKID4UQ84yXuwVTKBQNl4ICredPoEc22fjh26aEgsjO1vpAVIYSFkRwsHVT377ae9OmEBUFfk7OYRTGmzZtGlJKBwVRHguiqa9rN1R58bB4lO5iqiMT5VbpL4VCoagWjKQhf68cbhrrS3BxKGw+Yh1QjRbE+vWwciWMH6/1F3r5ZWtZp5LZS0uWLGHixInmcmpqKkm2igvwdjX/AqsF4evl63JMefEQHg6T7mwVRG0HqRFC9AKygL1Syv1ul0ahUDR4bAvmeRfnENjKF/LcF4O46CLtZfD88/bDR44cybfffgvAtm3bGDVqlLlt+fLlxMbGIoQw4wGuXEZgtSB8PX15+tKnuSj0Ipdjy8LD4uHgRqppF5NLBSGEeA6YAGwD/k8I8bKU8gO3S6RQKBo0Bw9q74JiGhXlgq+vVjUvPR3y8zXzIju72iyIsihpETz77LOA5mq66667AAgKCiItLc2uxaiBlJLknGRC/ULtLIgXrnjBYWxF8BAepccgajlIPQaIklKOA3oDk90ujUKhaPAYCsIHvXmOr6+1dHeyXm6jGi2IsnDlMnriCWvBiLfeeotp06Zxzz33OIz7377/0eyVZvx16i87C6KqeFo8a92CKE1B5Eops8HsF12egLZCoVCUitFW+ucVepkNPz+rgjDcTNWhICppQRjYKojBgwfzxhtv4OvreOPfFLcJgD4L+jDtx2mA+2MQA9sOZGC7gVU+R1mUFoPoJIRYqX8WJZaRUl7nVskUCkWDxGjS07OzriBsLQhDQVQli6mCLiYjS2ncuHEstinzaput1M62cVHJ/fOzHNaVnPtQGTwsrl1Mbw1/i4tbXVzlc5RFaQri+hLLr7pTEIVCcX5gKAg/4UJB/POPVg+jhlxMRpbS1VdfbacghBCEhYXRtm1bp/vtT9zPnSvuZPOpzfh7+fP4gMeZtX4WgNP+DhXFQ1iD1LmFuUgpTQVR2vyJ6sSlgpBSVqCNhkKhUJSPzEzw8QHPAhcKwnhar6EgtZGd1L17d0JCQkhOtpYdP3XK9Uznn47+xOZTmwEYddEonr3sWVNBVAeeFk/Tgug0rxPpeem8P+J9oA4oCIVCoXAHmZn6vd+YvezrC0ZvBdtU12qaKFcWr776Kt999x3R0dFMeWwKL257kfujtYkSJbvFGeQV5vH6ptfN5cEdBleL1WCLh8UagzidcRqgxi0IFXiu58THw4QJ1uKXCkVdJ1fPbDWbBfn5aamtjRvbK4gasiB69erFs88+S1J2EsGDgiEcNodsdjr20R8fpfHLjVl+YDmxabEARLeMZmTXkZWTtRRsXUwGdcbF5E6EEA8D9wAS2A3cCbQElgBNge3AbVLKfJcHUQDw7LPw+efQpQvMnFnb0igUZVNQoBdpzbFxMYFmRfxg06zSScZQuaigBQGam6nTvE5k5GcAcDz1uNNxhtWwMXYjAK8MfYXHBjxWOTnLwAhS2yqJOmdBCCG+FUKsLPH6TAgxVQhR4VC9EKI18BAQI6UMBzyAscC/gTeklF2AFODuih77fMSoFDBrVq2KoVCUm4IC/f+2pII4fhwOHbIOLKWJT6mUJ831zz8hNdVc/Cf9H1M5AJzLOWfOaXDG1/u/xtvDm0f7P2q3/r8j/ssP46unI7OnxZPC4kJz8h3UQQUBHAMygQ/0VzpwFrhQX64MnoCvEMIT8APigSuAr/TtnwCjXOyrsMGn6tl0CkWNkp+vWxC2MQiAPn3sB4aFVe4EZVkQqala39HrrYmaexKs/R76t+kPQEJWgt1uKTkp5uf4zHhaBrZ0KLsx+eLJDOs8rHJyl8BwMdkqqrwirU6Jl0cl+mRUgvK4mHpJKQfZLH8rhNggpRwkhNhb0RNKKU8JIV4FYoEc4Ce0ch6pUkpjVkgc0Lqixz4fqaybVqGoLVy6mNats+87rfdhrjBlWRC79IaYGzYAmrVw5JxWKPDggwc5mHSQ65ZcR0JWAu2D25u7/d/v/2d3GNumQO7Aw+KBRJJVYA0wpuelA9Uzz6I8lEdBNBNCtJNSxgIIIdoBek4aFY4RCCGaoM2x6AikAv8DrnYy1OlfVwgxGb3sR2mTV84XjIZbXl7a70HK0hukKBS1jYOLychW8veHtm21eRB//VX5GARoPwJXCiI93fy45dQW+i7oay63DmxNaq7mejqbddZut7iMOEJ8Q2jk0Yj4zHi7ng/uwNOi3Z4z8zPNdcnZyXh7eFd7xpQrynOWR4HfhBC/CCF+BTYCjwsh/NFcQRVlCHBcSpkopSwAvgYGAMG6ywmgDXDa2c5SyvellDFSyphmzZy36juf0H5jkqIiuPVW6NixtiVSKErHpQUB8P33MG4c9OxZtZMI4drFlGm94a769Bm7Tf6N/Gnu3xywupiM96TsJDo26UiQj9Y/rXPTzlWTsQw8hIcmro2COJd7rlrKeJSXMhWElPJ7oAswTX91lVKuklJmSSnfrMQ5Y4F+Qgg/oTnwrgT2Ab8AN+tjJgIrKnHs8w6RlIjEwrjiRSxZArGxUOT+Gl4KhR1FRfDTT+XLLDVjEIaCsA2khYfDF19AKT0XykVpFoSNgpj91M/8dljzoA/vPBzATkH8dPQnWrzagu8Pf09SdhKhfqFmaY3uzbpXTcYy8LBoCiIjzxo8T85OrjH3EpR/HsTFQA8gArhFCHF7ZU8opdyMFozejpbiagHeB54EHhFCHAFCgA8re47zibbHNT/q/bxjrjt2rLakUZyv/PvfMGwY/Pxz2WNNF1N2tqYcSumvUGnKaUEADIy+ngMPHGDZLcsArRKrp8WT9Lx0dp7ZCcCyfctIzk4mxDeE2yJuA7TJce7EqQWRc65aKsWWlzJjEEKIz4BOwA7AeDaVwKeVPamUciZQMmv/GNDHyXBFKfimnQFAYv2RXXhhuecIKRTVwubN1vfLLivdALBzMVUlzlAaFotrBVFyVukll9A1tKu5KISgsXdj0vPSzZnMZ7POmhbEc5c9xyP9HyHEL8Q9susYmUppeWnmunM55whoFOBql2qnPBZEDDBQSnm/lPJf+ushdwumsCc5GQoLHdf7ZWiBNF9y2EJvhvIToD1AOSldr1C4hX/+0d6fe046dGwriakgqlKxtSy8vJz/YECbym2xwO23Q8uW0KuXw5Ag7yDS8tLM1Nbt8dvJyM8g1C8Ub09vtysHAG8PTcum5VoVRHJOct2KQQB7gEomJCuqg9xcrZbZQzZq+dQprel63knNgojmb3qzlZ+w5mB/qJx0ihpASij6eyeZ+PMO93PmjP322FjtYeWI3nLajEEkJ1trMFU3np6aJnKG0bVu4UI4edKaCmiDYUGk52sZT/GZ8QCE+LpfMRgYk+FsLYjsguwadTGVR0GEAvuEED/azqZ2t2AKK9nZ4E8mny60msxt2sDOndA017HaZGvialI8xXnOp59IvuJm/MnmLj4yjYLUVPjuO2jfXntYuU1z3ZOToxsOSUnWKq7VjZdX6QrCy0szs50oB4AgnyDS89Ltnt4BQv3cJK8TvD01C8JIuzWoySB1eeZBzHK3EIrSyT+dRCbNeCL3/4DHzeSPJpyjLf84jO/Pn6zjCpqTwNSp3XjrrZqVV9EwSE/X7qGBgaWPWzFzOxPRzANv8vnf2/EEBLTkt99g40b744EWIw4IQLMgIiPdI3xpLibDgiiFxt6NOZV+Ch9PH7PkBVAjriUDw4JIyU2xW1+nXExSyvXOXjUhnELDslZLDRkrtWYmX30FnTnMOUKIYLd1YOfO5AhfBvI7C7mD/XRnybyzzg6pUJRJUBA0b172uAGJKyjEg+SF3wLQl828/DJkbtzOF4yjGdo8AiNZKSNDVxBJSbXrYiqFIG/NgsgqyKJHsx7m+mZ+NTf3yohBJGQlIBCEBWie/jrhYhJC/Ka/Zwgh0m1eGUKIdFf7Kaofj7//AiCDQIqKtNjaGL40t5/y76J9GDKEQ5ZuDOcHRvIdAAP4o8blVdR/jDp2ubnajf2995yPW78emuScIicojJBbriSNxtzAN3TvDjN4mXEs4Un+zQ03wN69WnmlggJITymCc+fc62JyZUGYebauMWIQeYV5XNDkAnN92yDn3eXcgWFBnMk8Q7BPMIGNNFOuTsyDkFJeor8HSikb27wCpZSNXe2nqH4a7dkOQHtOYjS7uhSr7e713FPw+OMwZw5xRWFcxEFzWx+xtUZlVTQMfvrJfvmll5yP+9//oCnn8G3dFHx9yet7GRezjUaNoAuHAXiU13mk+BWuYwVeZzWX6Kk9KVp0210KoooWRGCjQNLz0sktzLVLKw3yDqpOKUvFiEGcyTxDE98m+DfSCq/VCQvCQAjRSQjhrX++XAjxkBAi2P2iKQzyj2pB57b8Q2JcHl7k058/KQgNg5tvpvlDY+H//g+aNeOMnnAmw8M50yKCXnKbmlmtqDCNkk6zmuH01y3QCy90Pi4hAdr4nsOzWVMAmg/uQVdxiD07CujIcdZwJQCXrHiCFYziDwYAktcmHdAOcMEFzg9cVcoTpC4F/0b+5BXlkV2QjY+nDy9e8SLzr57vUL3VndhaEE19m5qKqk7FIIBlQJEQojPa7OaOwBdulUphkpoK3qlnSCQUD4r5+5sTPNrzZxqTgddH72uPcDalCgbfq/2SRatWJLWKpCe7WbiwloRX1Ev274emG1cwnB/5ipvxJtflxLeEBGjOWTDqovXogZcsIIatBJFO5qVXI2+6yRzfljj+8+hxOuXv11ZUteaSKzw9qxSk9vfSntZTclPw9vDmqUuf4oE+D1S3lKVixCCKZTFNfJrg56Wlh9W1iXLFehnuG4A3pZQPo3V/U9QAt96YSwBZbKIfAOs+OEpgmp7GevHFDuMv+NcIra7+7NkktYqgNad58p4kh3EKhTM2bIDu3WHvyqMAtCKeXHwJSdjvdHzL3T/SPuegVoUVtJ2B2/gMAI8LOiBGjwYgJaANABcW7IX339cP4KZbSWkWRDliEMbNuLC40HT11DRGUBqgiW8Ts/SG7Xp3Ux4FUSCEGIdWQKRpFcgAACAASURBVO87fV3NdKtQcGCn1iCEHlomRcDZI+THxlOMsD612dKjh1bvoF8/DnhHANCT3ebvsbBQm1eRr5q5KpyQmKi9+2bbP1S0Td/jMDYjA/59bpK2EB2tvXfrBsD9vAtA/7HtYfRo2LSJ/M07ALi8xX7YqsfGKts1riyqmOZq+PvB+iRf07QMbGmW9W7q09Scg2EUE6wJyqMg7gT6Ay9KKY8LIToCi9wrlsJgUD/tTn71PW3I9QqgE0e5mG3EeXUs04+6xyMKgP8xmqfvTWTLFm0Xf3948EG3i66ohxhlipqRyN5GvbSG50BItuPky8z0YlpwltgeV8P48dpKX1/o188cEzqwq1bWom9fWnQPgbAwPDes0zYOH+6+L1LFILVhQUDNZg3ZYhEWbou4DQ/hwciuI3mo70OM7j6aYZ2qp2NduWQoa4CUch/wGLBbCBEOxEkp57pdMgUAWSmagvD09ya/fRcuZSNXs5o1fteXsSeEX9GcY3QklGSe5Xn66n1RxvEFUR/cD5s2QV6eO8VX1DOM9NaL2yfRqV8zGDeOPIsPIXmOM/az487hTT5new23r8hq2yC95Cy7iy6CH3/UPk+dWr3C21LVILWXjQVRSy4mgA+v+5BTj5zimi7XENMqhqWjl5r9KGqC8mQxXQ4cBv4DvAMcEkIMKnUnRbVQWAgHdum+oEaNyL9uNNH8jSdF/OXRr/SdgXvvBb8N2o/xFpbSGK1swEfcpbkA+veHjz92m/yK+kd2UjYLmUjYyS34tAkFITjn24ZmeY4WRP5pzQ0lmpVIVb3oIu29RQvHE9gGpd3ZEdLb2/XDTwUtiNpyMYHWE6JFgJPrWEOUx8X0GnCVlPIyvTf1MOAN94qlAK2OWH6WVUEE3Xqtue366d3K3F8ICLtUm0QXxlle4Bm8yKeRTafYvMOx1Su0ol5z8frXmWhU8tdjXMn+7Widd9xhbH68NinH0qzEbOh27WD+fPjzT8cTDB1qP85dBAQ49H0wKUeQ2jYGUVsuprpAeRSEl5TSnHklpTyEClLXCIsWYb2ZN2qEV3hXaNIEZsxg+OPlTw8sDtKmrUxgEfl4Y7Fp952VmF2tMivqL39uKGDohmetK/RJbPFNuhOZtwUWL7Zue+IJIh+4BADPliWSJYSABx5w3v/2iiusnwPcmK5ZmoKoqAVRiy6m2qY8CmKrEOJDfZLc5UKID4Bt7hZMof1/2yoIvL218gSuprW6wLJvLyeeeIcmpDpsk2dVrSaF5o1ZdlmJqo765If97fSg6K238t71q7UZ0K+8Yg5rHFWByW7+/lqK67JlVRW5dAIDS1cQFYlB1KKLqbYpj4K4D9gLPARMResfPcWdQik08vMhwlcvol+VdMBWrQh4/D67VaNZyi56Is6ecbGT4nzi+KECHuA/ABxDf/LXywbvv+BattAbgCkrryH7q+/t9m3RtYKFFSZNghtvrJrAZWFYEM5aK1Y0zVVZEK6RUuZJKV+XUt4opbxBSvmGlFKlvtQABQXwcc5YbaGMJ56yaNoU8tB+FFnLfiB+4GgOcSFNd/7KF28lVlVURT0nPuIqOnKC13iE8WiprQwZAoBXI8HDNmHHpF2n7fZ1V9fQKhEcrLUcTbPp57B5s5Y5VU/SXOsCLvtBCCF2Ay47G0spI9wikcLEbjKb0QSiklgs0JkjhHGGv27szecXw9oOWs3F9tNGwdTfHfZJTITQVZ8gzsTD9OlVOr+i7pKbWchgfiWVIB7jVUBAUZH2T4P2dhxrPOGvFafB0p52xSfZ+eQXuKmjQ9UwajwdOQIxMdrn/v01i8LHp0wFYVsQ73x2MZXWMGhEjUmhcEpBAeTjRSMK4Kqrqny8Jb+1pXlzrSRC+/aQOWAY/PExkewkNVV76DLYvl2r5CG5Q1uhFESD5dTmODoBj4vXQOrzGSxW58LKlXCGMBYxngl8TvzuRIJI4feLH2Lg3HG1I3RZdNFL4B8+bFUQhrspL69MBWFblE+5mJzjBbSRUp60fQHtKF8nOkUVKcwt1JTDrFlVdjEBDBxo/d0APPTbLSQPGUMmAXz9Nfz6q3Vu0S+/VPl0inrAyZPw/+2dd3gV1da435VAGqH3XgNYqUqzKwpcC1e8v09FRex67Q39WRD99NoviooFFRWQq6IiKsWL5YoFgYuI1FACCAldSCC0ZH1/7Dkl4SSknZyTZL3Pc57Zs/eembVn5uw1u601auhKAO4e67668zsJeuYZUGK4nAmsj+/AzbxMbXZzqH75mXwoNu3bu9lUK1YcnqZarP9TVe5iKkxBjAYyQ8Rne2lGmInfs8MFwuV1S4S6p3ehCZv58O0sTj8dRoxwSYvn72eT2WSs9Dz2GLTf/AO5CCkXdeWnn+DHfD6mhgxxXgwBGtYKDD/uOqpPOUpaTBITXZN41KjQs5lq1Dg8rgDqJFRd7waFKYg2qvpb/khVnQ+0CZtEhp/EPZ7BtHA5VQFiuroe5ENz3KKmd99Rpk87xI7JM2mKzXCqzKQu3kfbNx9gCFPY1r4XMfXr0ru3+/jOz5AhsHIlJH7i1kJ8zens7XV6OUtcTK66ym2//vrwtLp1i3yaqqwgCusqKqxdFY3zFiodiXs993HhakGAG7gDJnEpu6jNqh0dGHD+TAaG74pGlDD/0S95AG9NzWlXHzF/SgqQ0g9BAWV63fJznlMi7r0XnnvO9aPlp169Ip+mPL3IRRuFtSDmici1+SNF5GpsoVzYUYW9y7wXu3nz8F2obl0OxsbTkG10YDUDmJkneXPzbpCUVMDBRkUmd3PQ9ObWrYt5tBTnIzwyNGzoZiyFUhBFEP5vRzs/FtVjq67hiMIUxO3AcBH5VkSe837fAdfgFsyVCBHpJCK/Bv12i8jtIlJPRL4SkVRvG+2vX1iZMgUaZ6aSQwx06BDWa3196qOkcvg13uVyVqcMMOcRlZSYTUEG+PKPTBeB4AkPUYmIc2Q0derhaUVQEO8PeZ+s+wtYjV1FKFBBqOpmVe0LjALSvN8oVe2jqiXunFbVFaraVVW7Aj2AvcAnwH3AbFVNAWZ7++WOKmzfDpq1By66CObNi4QYrFrlnMH/SZ3wOVXx+OKYezmOxYfFj+ApDhLnzMrm5oZVBqN8yc2FAxs2szuhobOxdPWRu5jyU4xemsjRqZP7My1cmDe+CAoiNiY2z4rqqkhRVlJ/o6pjvF+I0Z5ScSaw2ps+ewHwjhf/DjC4jK9VJKZNc2PCd6V8BlOmsOkvh/WylQu5uVCbXdRqUSvs1+rYEfaHGHLaKo054K2+LtC2vnEYqvD74Q7YogZVZ6qo7oEMDjVqBhdf7BzsFJEvvoBZs8IoYFky2ptw+ckneeOjvn8sOiiKLaZwcjHgMxHZWFXTAbxtyDaviFwnIvNFZP7WrWVvIsI3bfqUjH8B8OfWA2H3qTN8OAwalNdszKZNUL/abqrXC7+CuOkm2LgRcl99nUMtWrtFUj17Uj0+hv3qKQjrZioS+/bBuHHO7cH06ZGWJjTr1zu3s43ZTGLr4vsaGDQor9XuqKZ9e/cF9NhjeeNrV92B5+IQMQUhInHA+cCHxTlOVV9X1Z6q2rNhKJ/MpSTTW/nRBzft82iWsWPCl4UcUTr27YPx42H6dGXF0Ef9TeH0dGgQtxtqhV9BxMRAs2YQc/21VNuQ5vxOfvcdcXEEWhDmea5IdOoE110HQi5db+gVXreaJWTaNLftXCeDxLZNIitMeRCqLyw2tvzlqIBEsgUxEPivqvrsTW8WkaYA3nZLJITasQOqcZDGbGE+PQCo/2DZGK/dsAHW5vO74msEdWQlnd8fCd27k3NImTMHWmua32lLuZKQAElJxMXB8nRPQWWGWjNZdUlNda6Xl09fQ07qGn/8+vXQiM1k0ISm638JuNeMIrZsAUGplb05tNe3yoZPSfc+shdGIy+RVBCXEOheAvgMGOaFhwEhph6Eh82bYdEiF160CE5q5mrxV7mBV7iRuIwN8EfQjA9VV9sXk1atAjbEfIwcCaAs4Rh/XOrifbTaMo8m2WvLxMRGSdm2DX5Z6S0SCraKWcXJzXW9Fovn7qHzoPbEdmzPz9KbS2USD/IYcziJRkSnhdxff3Xd8s2TdyH790OTKtCCePBB9zLffnukJalwRERBiEgS0B/4OCj6SaC/iKR6aU+WlzwXXABdu8LOJZtY8csu7uj4BQDfcDov83eX6a232L8fdu30aodWreD774t9rVasg3r1ePi8hYh4Cok5VCPHn2f90iz685XbKcHskrLimmtws6gg4M3eYIvXtn2IQL92b+YyiaE8xsOksCpP/hjJZe6MnTx8R2a59dQ9+GDoMZBu3VxjsEGW15StCgoiNtYtNrVupeKjqhX216NHDy0tubmqoDqW613A+21vebz+859ud3ejdqqXXKLnnafai58C+Z54QlVVL71UdexY91u9JFs1KyvktUD1Wl7zH38pE/Jcc07Klaqgt1+wRufQV/d1Pr7U5SsN27apHstvTr5HHomoLNHES89m67H8plkkqYJ+feEYXU7HPM9yAd384Y4s143STLdSX6c9s0w1LS3sMoJqHPtUv//eveQeQo5Cro7h76qxsarLloVdlqjh448Dz6iKA8zXItSxEa/kS/MrCwUxcaJqNxbk+XMrqE6ZokuXuuBeElRBT+FbHclIFxkTo3rVVZqd7XbbslpXkKIKmhsTo3rwYJ7r7N/v8t3DU4dfy/s92/sDVdBzmK4Kuu/hx0tdvtKQk+MqlJ85UbOato+oLNHElwzwP7Oce0aoqtsVcvR/r16jumCBnnGG6mBchXQjLx/2rDMzNU/FXRjbtqn27686uOV8XXD2CNV+/VQzMgrMv2aNu8wI/uECM2ao7typuQnuPX6C+3SPJKkOH14Wt6PiMHWqKQgPUxBHIDdXdeZM1QEDVJ/gPs1BNJ3G7pYMGaKqqvv2+e6Qe6le41rdSn1Na3yiarduqoMG6ZIlqpCrH3Fh3krgzjvzXG/sWE/v8FfdSv08ede0PEWP7pzjVwxPc7dTNPPml7h8ZQWoPsU9mk28pm8qWoVWqfE1OX2/XbtU1b0raWnuQ0DVJVVnv+4jThdxXIEfBTpjRujr5OSo/uMfqps26bhxed9D1+QdW6CIbdvmyz9mjDtX/mt/913Z3pto5/PPTUF4FFVBRHodRMSYPh3OOQeSZ3zI/TzJXHpxLL+z857H4V9uDUR8PNx6K2SI66e9jjdowHbeqn8PNG2KbkonNRWmcR5D+JjtSS1px2p3ge++A5xjrqZN4f0bv+N3juFCPuFzzmUwn3ApE/nxmGtoPu9T4hJiyCIZgLvPdkZ0pUMIs5rlzMSJkEoKCexH7roTli8vOGPr1m7ebiXm00fzGTj2piHHx7vi+xa9jx4NB4njd47l+BCr1P2cd17o+Dlz4P774dZbyc6Gmzx/0X527y7wlFlZkBxsqf+WW/hhYhoAL3BrIP644wqWqzJiYxDFpyhaJFp/pWlBvHnvcm3KRv2R3qqg5/KZhjrd44+rNmSzXlVjsv/royXr9A2u1o001W+73e6PP7Tod01MVJ3d9U7V+HjVffv0J2/IYhXt/Plm3T1T+/dXPfPMwHV691btwsLAF06HDiUuW1nyxx+qtdmZ98sziC1bVFOXHgi0hsbN1oceUs095xzVV16JkNRhICtLt67N1IcYpQr6y5n3qb7+eoHZN2xwt+QNrs5z76bUvCLvvYyJyXPcBG9Y6uVe76iC7o2vHbrlcc89BV67f/987xLoTmrrpsR2ehnvVt2v6Fmzqm7Z84F1MR3xDrlKnRhddelDum1b6LHl8eMD79SnF7+vv5z3qILqYzyQ9w/r9QkPGKB6TZNp6usGeOMN1d786P7sp5ytunZtSHFOO021PamB802eXPKylTFpaZq3rLNmqarq//yP2+3H9/60j2pcoYnsqVx/xO3bVePi9M+2XXQFKbqZhvrB5EOFHuLrnryZF1VBN9FEFy5UXbxYtQFb9GreCNyjAwf8x4FqAntDKwXQi+OmqLZooXr55QVe+6STVE/mO1XQi/jAf+x4rtB2rHL7hRxfaZk9u3K9l6XAFERh7Mz7RbxvwgcFZj0Q+DjWtWtV58514Zt4yZ/w/eBn/flHj1aN4ZDuaXO0bmjdV+c0GRI4wZ9/FnidU09VbUx6IO+2bSUrWxjIzHQDntkJQV+zW7b4g1cwPs/9TGFFYP/ll4s8GButzD7qpjzle7bRU0WaiDR3ruqKmWt1BmdrCis0MzMwgAyqn5/1vAvs3Ok/BlSP59eQyuGZu9IVVHMHDlJt1SqPYgmmRw/VG1p9oQp6Ij/rWlqrgh7FEvePX7hQdceOsrk5FYlvvzUF4VFUBVE1xyB+y9uPHN+uRYFZq1d3SwD27YM2beCEE1x8BoH54+2uPdMf7tABcollclovWqz7kX4ZU1zChRcWav/lwAH8YxBAeJ0EFZMaNeD56vdxyjE72F/PK3dqKgDVOcDDPMpBqvH7sRcD0JufAwf//e8lWi8SDfz0EyTJXroue59ZBIwP3fVG5yK5TzjxROh4dhsGMJNUOpKU5JbPXHmlS9/je94+l5iZmQznLTrkW0dxPa9SnQP+NQv7hgx1S7Z//plQ7N0LHZu6MYgskvnonl9Y8dV6NtU+moEDcYt+qqKxujBbRa6MVE0FsXcva2OCljR36lRo9tq13SAkOBPz69bBU28HTBQ06x9YBd2ypdumB/lzvmnoLufgoRCys2EvSeyv29hVqlGEiDPmOm9BDMfv+NZF9uvHmfybk5hDe9Ywn54M+/1uILCAzO/TOr+T4wpC375uEWM9dvICtzGRS11Cv37FOs9gzy5xTIwbJ337bWcxOEs9U9JZWaxaBVuuuIu3uJqRjMpz/CK68MPc6n43yv+7YKB7KF9/7Wy37NmTJ392NtQUp3SSGtXkjIsb0emslqSnw+efF+8eVCoSCnOSaYSiSiqISTsG0C53NQ/3+QqefLLYhu1btYIOFx4Pp5zi/EUEmcPwnWoRXfxxfc45ssG9hg1BiWHbok3w0kvFkqc88JmESgtyR/5v+vM1rvV0Be+S1cR5kElhFT/Ti+ZsQhMTnYONCoZvklBn3KyttPo9SX/8bVi9utituw8+gJ0788YlJsL2WHdTczZt5qSUDOp/+iYAx7OYQ8QyNu421lTvyG8czwkn+L3D8sTYuuxp2QkeecTZbklOhjUBe1B790LDQ+kAzFtVl+7dA9eMqZL/eA9TEMWmSr4ubdu67YK6Z8GIESU7Sa1abiprz555on0t9w/5G8u6D2XX5X/nssuOfLrx453jq+Yto/OR/PCD2x4gnpE8wjTODSSKcM7w5qzMCCjCi/jIBWrUOOwLNyrJyXG90x5fegZ87xq0HK1ThyVbG3H3/4873JhWEaheHerk83ufkAB/VHfnWjptNUOZSCy5rKMVANXI4emm/yR53VLmL0lCxPUMvfqqO37B+nxGHG+5hc8/95TAlnS6bPs3HHWUc/xgOExBFJvorI3CTK9e8PDD4flQD7hvFn64cQK1330JKYJv92bN4Pzzy16esiIlBa6/3oVfazyS85nGJUxyESefTINWef1Wb8SN62hScqCPPVpRdf37MTFw7LGQnc0ll7ikBtuXI507U6SHWAxq1IC03FYQG8ufU2bzHK577kR+YUeL4xjEF9SpKzRqGsvRRweO841fXMM49sYHjSPs3s2IEW6sLJ1mtEn7Dk4+uUxlrvAkJkZaggpHlVQQMTEwalSgJVGWiMAZZwSuU5kYPdqN7//yi9v/gr9wcOgwGD/eP0Zz/+BlXNdnMd26uf3cxChuQbzyCogw9aqpztonwJIlMHeul0FJTFvmvsTLmObNYX16dXbVbc3JGyb540+5qDE/vPIb0xnkv6fBxMe7hZepdKTG/h180O8Fl5CRgYgzVe8ngoYeoxJrQRSbSlaFRQdffQUffUSRupYqEgkJbvFtK9cLQia1qD5hPLRt62/9XDCiM6//eCy33OL2cxKiVEGo+icDXDD+r3nTMjKIi4NhJywjZnNGYOpaGdKqFaSlwcJtLQORu3fz4YduABsK9vIaPCnsf364hUNXXuMUBEoDPEXXsmVY5K7QmIIoNqYgwkBMDAwZUrVm1R1zjKtzfT5ZfP/FQ0m1os6XhCqk/2P8YfEP9vJMrH/7LT8d7MF1h15x++eee1je0tKypZs+vQ43X/aVLq/5xwuOP941Wp5/PvSx7dvD5Mm+PWFTk+6QlcXph76iGZtc9Isvlnm3WIUnVJPMKJSieyo3jCCWL3ezZQrCpyAO1G5IjdS15SNUEXn6oUxGPH4VAFtpQEO2cT2vsnhPL5fhtdfoDmze4DlvCIPXNV8r7DZeYEvfwVz+0WB/Wo0asHRp4cf/5S+B8MQf23I/8OKKc3gRr+nWPvJ2vKIOU5jFxloQRono1An/OEMofOOB+2o1CvhVjQYmT2bE44HZVu9yBQCfMpg/D9bIkzVx3w4XCINXP5+C2EUd7vnhrzRpWrzKKzloTeXj/znJH76VMS6QklJaEQ3DFIQRHnwtiMxG7d2iglWrCj+gHNBcxT89CbiQKbzY7CnasJYtNGbDxhhygv4StbLS3cq2MHx5+hREabrFTzvNbfeQzLuXzggkjBtn/e1GmWAKwggLvgWDfzT1BkpXroycMNu3M3OG0jZ2nT/qrQb38gkXsjOzGv9Z14ahQ91s3Ge96aZ+qoWnF7ZVK+cW9KefSn6Ob74JhP93kpuS90vXa232klFmmIIwwoKv2z5jvzdXPwID1ZmZsO2nVGjQgLW3jSYNV4mexjcc98WT/jytWgVmDj3CIzzKQ4GThKF7CVyj5LHH3OK30uAbq0ilI+1ZxYo7Xiu9cIbhYQrCCAv167uP70XrvCXEf/5Z7jIceyxc1XcZADesvBOA8QxjXtJp9OiZt9vIN3V0H4mM5FEW4NmniPJFfsFLNAbc1J5LLrWBWKPsMAVhhIVq1ZxNu5+WehZsy0FBzJgBi4Oct61fD7XJ23K5hTH8+qubivz8885xG7iWRDDB1norCi+/HLYeMaOKYq+TETbq1YPU7QluoLccFssNHOi2PpNKLdjAcN72p++S2uyVmv4JPnfcETj2hBP8FswBuJRJ7CKfAaUoZepUZ9TVKAK1akFubqSlqDCYgjDCRnKypxcSEsrNV/Ux/M6umudQOzmXDWTkSautu8guQIzXXnMLq5s0cUsIdlOw745oI5pteEUd0TTlugJgXUxG2PAbcj2SgsjKgueeC9jYLgG+0w/mU2pnbYKMgHJ4Fc/KYGxsgavbk5Od/4diWn43KhpxcVXLxEEpMQVhhI0aNbwx3vh410G+YEGe5v3GjW42z6cnPgF33w1jx5b4Wj5/C3XZeVjaGtqx9PFP4Ndfj3iepKQjZjGMKkNEFISI1BGRj0RkuYgsE5E+IlJPRL4SkVRvWwV9IlYukpOdOQ7NyXERPXu68Qhv8v/HH7voLsved4GCrNMVAd8QR5N83UrgBpzrDh/spjUdgTDNajWMCkmkWhAvADNUtTPQBVgG3AfMVtUUYLa3b1RgfC4yc3fnmyr6xReA++pPYg9tSXPxBw6U+Fo+u1ApjXbzX7qRQmBh3qMv1qVp0wIOzIeZ6zGMAOWuIESkFnAK8CaAqh5Q1T+BC4B3vGzvAINDn8GoKPgURGx2vhlMXm0+ciS8xM2B+FIoiOxst21bfxe7qcUqUngJZ867zamti3Wue+912/du+MHZbjeMKkokWhDtgK3A2yKyUETGiUgNoLGqpgN420YRkM0oQ4INyuVh717/mEHHoC/94nYxvflmoP52OkdpuOx7mtV3Vljv4RkOfvmVs59dDHxWoVc37gtnnVWsYw2jMhEJBVEN6A6MVdVuwB6K0Z0kIteJyHwRmb/VpqxFNb4WxFAmsIQgv5nffEP6xlx6MJ9+/Mg+4tF69YrdgrjmGjj7bBfOzoauuEHojvHrAbcquvrA4lfwPgVRigaNYVQKIqEg/gD+UFWfX8ePcApjs4g0BfC2W0IdrKqvq2pPVe3ZsGHDUFmMKMGnICYxlJ7MDySsXEmbvk15E2dUbi9JbnS4BDXyX/gcRGg5+Rl6sMBFfvBBqeT2KYj9+0t1GsOo8JS7glDVDGCDiHTyos4ElgKfAcO8uGHA1PKWzShbgruY9pFIDbJIpQMASZlb6MJvABzHYrR6XLEUhG+19GVMcOd47156sICc5FrQp0+p5DYFYRiOSM1iugWYKCK/AV2BJ4Angf4ikgr09/aNCkyNvP532EsNOpLKV93u9cd9esHbbKI5VI8r1hiEb2HcBgI+nW/kVWJ6doeYGMaMgVmzSib35Ze7rqv77y/Z8YZRWYiIqQ1V/RXoGSLpzPKWxQgfBQ1Sf3nMPXRcOJmbeYkzTj0PpoIWs4vJt+g6zyA3IN2dFdabb85/RNGpUwdmziz58YZRWbCV1EbYyN+COO44tx09oQFtWEePkef5rY8Wt4tp40a39Q1MH3YRwzBKjSkII2wEK4g1a2DRosB+cjJcdplbWA2egihGp39amts2IYN/cnsgoU7FsMBqGBUBUxBG2PApiHr1oG1bt0r5iSdg1Cjnf6FDh4CCyE1KLpZJ8B07YBKXEM8BskjmY/7qEsyYkmGUGWbu2wgb1ao5M9qnnRaIyz/wG1AQNWHbhiKfOzMTrmEyAFtpyC2M4S9/b0v8GWeUUmrDMHyYgjDCynXXFZ7uVxA1asLazMIz++a2ipDyb2f59R2u4DWu5wDxxI15DsyWkmGUGdbFZEQUn4LISap5uN9PcEph9WoXvvFGiI3ljyfeocOXL5BNAjtGPM0B3MIFM7RnGGWLKQgjovgUxKE6DdzAQn4l8fbbbrCidm3XX6VKiweupDMrmMBl3PFk4/IX2jCqCKYgjIjiUxCZfc6GQ4fgppsCXUkAsJuy+AAAClxJREFUkya5bQhvc/0ublUOEhpG1cUUhBFRfAoiq0s/F5gwAf7zH8DTE+vXQ+fOIY89+qKAAcCTTw6nlIZRNTEFYUQU/xgEsc5+N8CaNezfDzExkJWRyd7uJ/ErXQBoQjqdWcb8U++CQYMAZ6Hjm28iIb1hVG5MQRgRxa8gcoArroBateDHH/Fbcs/MZDc1GcAMGrKFzTRhBZ1pMuFZSEwE3HRa33kMwyg7bJqrEVHyKIhq1aB3b/jvf8nccZBx3EAye3hnVi020yTPcU2aHH4uwzDKFlMQRkSJi3Nbn3VWjjsOnnuOo7rEcZQXtWZbzcOOq2ZvrmGEHetiMiJKS89a97p1XsRNNx2WZ4t5nzWMiGAKwogoPhtNvrVwtGvnT8vArXHYQT0A3norcIxhGOHHFIQRURISoEULGDkSvvjCxW1471vmDnmay3kPgIV0A2D4cJgzB6ZPj5S0hlG1sJ5cI+IMHgxjxsC558LKldDx8lOBUwGY/qWSPsilAfTrFzk5DaOqYS0II+I891wg7GtF+Dj9dMjNhWnTylcmwzBMQRhRQPXq8MILLnzHHXnT4uPNCJ9hRApTEEZU0Lt3IOyb+gqmHAwjkpiCMKKCjh0D4b59IyeHYRgBTEEYUUGdOjB6tAvfemtkZTEMw2EKwogabrvNDUgPHBhpSQzDAFMQRpQh4tZGGIYReWwdhBGVTJgA9etHWgrDqNqYgjCikqFDIy2BYRgRURAikgZkAjnAIVXtKSL1gH8BbYA04P+p6s5IyGcYhmFEdgzidFXtqqo9vf37gNmqmgLM9vYNwzCMCBFNg9QXAO944XeAwRGUxTAMo8oTKQWhwCwRWSAi13lxjVU1HcDbhnQCICLXich8EZm/1e+X0jAMwyhrIjVI3U9VN4lII+ArEVle1ANV9XXgdYCePXtquAQ0DMOo6kSkBaGqm7ztFuAT4ERgs4g0BfC2WyIhm2EYhuEodwUhIjVEpKYvDJwN/A58Bgzzsg0Dppa3bIZhGEaASHQxNQY+EWemsxowSVVniMg84AMRuRpYD/wtArIZhmEYHqJacbvxRWQrsO6IGUPTANhWhuJECitHdGHliB4qQxkgPOVoraoNj5SpQiuI0iAi84PWYFRYrBzRhZUjeqgMZYDIliOa1kEYhmEYUYQpCMMwDCMkVVlBvB5pAcoIK0d0YeWIHipDGSCC5aiyYxCGYRhG4VTlFoRhGIZRCKYgDMMwjJBUSQUhIgNEZIWIrBKRqDYrLiItReQbEVkmIktE5DYvvp6IfCUiqd62rhcvIvKiV7bfRKR7ZEsQQERiRWShiHzu7bcVkbleGf4lInFefLy3v8pLbxNJuYMRkToi8pGILPeeSZ8K+izu8N6n30XkfRFJqAjPQ0TeEpEtIvJ7UFyx77+IDPPyp4rIsFDXikA5nvHeq99E5BMRqROUdr9XjhUick5QfHjrMlWtUj8gFlgNtAPigEXA0ZGWqxB5mwLdvXBNYCVwNPA0cJ8Xfx/wlBceBEwHBOgNzI10GYLKcicwCfjc2/8AuNgLvwrc6IVvAl71whcD/4q07EFleAe4xgvHAXUq2rMAmgNrgcSg53BlRXgewClAd+D3oLhi3X+gHrDG29b1wnWjoBxnA9W88FNB5Tjaq6figbZe/RVbHnVZxF/WCLxgfYCZQfv3A/dHWq5iyD8V6A+sAJp6cU2BFV74NeCSoPz+fBGWuwXOEdQZwOfen3Zb0B/C/1yAmUAfL1zNyydRUIZaXsUq+eIr2rNoDmzwKshq3vM4p6I8D5zXyeCKtVj3H7gEeC0oPk++SJUjX9pfgYleOE8d5Xse5VGXVcUuJt+fw8cfXlzU4zXtuwFzKdh/RrSWbzRwL5Dr7dcH/lTVQ95+sJz+Mnjpu7z8kaYdsBV42+sqG+cZnKxQz0JVNwLP4myepePu7wIq3vPwUdz7H5XPJR9X4Vo/EMFyVEUFISHion6ur4gkA1OA21V1d2FZQ8RFtHwici6wRVUXBEeHyKpFSIsk1XDdAmNVtRuwh8Jd40ZlObw++gtw3RXNgBrAwBBZo/15HImC5I7q8ojIA8AhYKIvKkS2cilHVVQQfwAtg/ZbAJsiJEuREJHqOOUwUVU/9qIL8p8RjeXrB5wvImnAZFw302igjoj4LAoHy+kvg5deG9hRngIXwB/AH6o619v/CKcwKtKzADgLWKuqW1X1IPAx0JeK9zx8FPf+R+tzwRswPxcYql6/EREsR1VUEPOAFG/GRhxu0O2zCMtUICIiwJvAMlV9PiipIP8ZnwFXeDM4egO7fM3vSKGq96tqC1Vtg7vfX6vqUOAb4CIvW/4y+Mp2kZc/4l94qpoBbBCRTl7UmcBSKtCz8FgP9BaRJO/98pWjQj2PIIp7/2cCZ4tIXa81dbYXF1FEZAAwAjhfVfcGJX0GXOzNJmsLpAC/UB51WXkPzETDDze7YSVuBsADkZbnCLKehGs2/gb86v0G4fqAZwOp3rael1+Al72yLQZ6RroM+cpzGoFZTO28F30V8CEQ78UnePurvPR2kZY7SP6uwHzveXyKmwVT4Z4FMApYjnPW9R5uhkzUPw/gfdy4yUHcF/TVJbn/uD7+Vd5veJSUYxVuTMH3P381KP8DXjlWAAOD4sNal5mpDcMwDCMkVbGLyTAMwygCpiAMwzCMkJiCMAzDMEJiCsIwDMMIiSkIwzAMIySmIIwqiYjkiMivnkXTRSJyp4iU+v8gIm2CLXQW8ZgrReSl0l7bMMqaakfOYhiVkmxV7QogIo1wVmZrAyMjKpVhRBHWgjCqPKq6BbgOuNlbddtGRL4Xkf96v74AIvKeiFzgO05EJorI+QWd12sZfCwiMzy/A08HpQ0XkZUi8h3OFIkvvqGITBGRed6vnxf/oog87IXPEZH/lEWLxzAKw1oQhgGo6hqvwm2Es+XTX1X3iUgKbtVrT2AccAcwVURq4+wXHcnZTFecBd79wAoRGYMzxDYK6IGzjPoNsNDL/wLwT1WdIyKtcCYgjsIZBZwnIt8DLwKDVDUXwwgjpiAMI4DPOmZ14CUR6QrkAB0BVPU7EXnZ65K6EJiiAfPYBTFbVXcBiMhSoDXQAPhWVbd68f/yXQNnSO9oZyIJgFoiUlNVM0XkWuA/wB2quroMymsYhWIKwjAAEWmHUwZbcOMQm4EuuG7YfUFZ3wOG4gyjXVWEU+8PCucQ+M8VZOMmBuecJztE2nHAdpyJbsMIO9aHaVR5RKQhzsXmS+qMk9UG0r0unMtxrh19jAduB1DVJSW85FzgNBGp75ly/1tQ2izg5iDZfAPprYG7cN1VA0WkVwmvbRhFxhSEUVVJ9E1zBf6Nq5hHeWmvAMNE5Gdc188e30GquhlYBrxd0gurMzn9CPCTd+3/BiXfCvQU57h+KXBDkMn3u1V1E87y5zgRSSipDIZRFMyaq2EUAxFJwpmO7u4bWzCMyoq1IAyjiIjIWTgfCmNMORhVAWtBGIZhGCGxFoRhGIYRElMQhmEYRkhMQRiGYRghMQVhGIZhhMQUhGEYhhGS/wNloehjikQwRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(days1, y_train, 'b', label = 'Training Set Actual')\n",
    "ax.plot(days1, y_train_preds, 'r', label = 'Training Set Predictions')\n",
    "ax.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "ax.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "ax.legend()\n",
    "ax.set_title('Walmart Stock Predictions')\n",
    "ax.set_xlabel('Day Index')\n",
    "ax.set_ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot only the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot test set only\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "ax2.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "ax2.legend()\n",
    "ax2.set_title('Walmart Test Set Predictions')\n",
    "ax2.set_xlabel('Day Index')\n",
    "ax2.set_ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Arbitrary Size, Number of Neurons, and Future Time Point\n",
    "We wish to create functions that allow for some more arbitrary settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create training and test data from a dataframe\n",
    "def train_test_splitter(df, seq_length, fut_point, train_split):\n",
    "    #save data as a matrix\n",
    "    data = df.values\n",
    "    \n",
    "    #save number of features\n",
    "    features = data.shape[1]\n",
    "    \n",
    "    #get X data (30 day sequences)\n",
    "    X = []\n",
    "    #get all sequences up to (sequence length + future point) days out of last point (can then predict last point)\n",
    "    for index in range(len(data) - seq_length - fut_point):\n",
    "        X.append(data[index: index + seq_length])\n",
    "    #get X as a numpy array\n",
    "    X = np.array(X)\n",
    "    \n",
    "    #get Y data (close price for all days except first (sequence length + future point) days)\n",
    "    y = data[(seq_length + fut_point):, -1]\n",
    "    \n",
    "    #create train/test splits using chosing training split (between 0 and 1)\n",
    "    last_row = int(train_split * X.shape[0])\n",
    "    X_train = X[:last_row]\n",
    "    X_test = X[last_row:]\n",
    "    y_train = y[:last_row]\n",
    "    y_test = y[last_row:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function with 180 days sequence and 80 days future point\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_splitter(df, 180, 80, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create scaled data and scalers\n",
    "def create_scalers_and_normalize(X_train, X_test, y_train, y_test):\n",
    "    #instantiate scalers\n",
    "    X_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #reshape data so it can be fit\n",
    "    X_train_reshaped = np.reshape(X_train, (-1, features))\n",
    "    X_test_reshaped = np.reshape(X_test, (-1, features))\n",
    "    y_train_reshaped = np.reshape(y_train, (-1, 1))\n",
    "    y_test_reshaped = np.reshape(y_test, (-1, 1))\n",
    "    \n",
    "    #fit scalers\n",
    "    X_scaler.fit(X_train_reshaped)\n",
    "    y_scaler.fit(y_train_reshaped)\n",
    "    \n",
    "    #transform and rescale\n",
    "    X_train_scaled = np.reshape(X_scaler.transform(X_train_reshaped), X_train.shape)\n",
    "    X_test_scaled = np.reshape(X_scaler.transform(X_test_reshaped), X_test.shape)\n",
    "    y_train_scaled = np.reshape(y_scaler.transform(y_train_reshaped), y_train.shape[0])\n",
    "    y_test_scaled = np.reshape(y_scaler.transform(y_test_reshaped), y_test.shape[0])\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled2, X_test_scaled2, y_train_scaled2, y_test_scaled2, X_scaler2, y_scaler2 = create_scalers_and_normalize(\n",
    "    X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an LSTM model with different neuron sizes\n",
    "def create_generic_LSTM_model(neurons, dropout, seq_length, features):\n",
    "    #create an LSTM model\n",
    "    model = Sequential()\n",
    "\n",
    "    #add first LSTM layer and dropout layer\n",
    "    model.add(LSTM(neurons[0], return_sequences = True, input_shape = (seq_length, features)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #add second LSTM layer and dropout layer\n",
    "    model.add(LSTM(neurons[1], return_sequences = False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #add an reLU layer\n",
    "    model.add(Dense(neurons[2], activation = 'relu'))\n",
    "\n",
    "    #add a final layer\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    #compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "new_model = create_generic_LSTM_model([256, 256, 32], 0.2, 180, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "new_model.save('second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "new_model = load_model('second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate score and return predictions for a given model path\n",
    "import math\n",
    "def make_preds(model_path, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, y_scaler):\n",
    "    #load model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    #score models\n",
    "    train_score = model.evaluate(X_train_scaled, y_train_scaled, verbose = 0)\n",
    "    test_score = model.evaluate(X_test_scaled, y_test_scaled, verbose = 0)\n",
    "    train_rmse = math.sqrt(train_score[0])\n",
    "    test_rmse = math.sqrt(test_score[0])\n",
    "    print(f\"Training Set- Score: {train_score[0]}, RMSE: {train_rmse}\")\n",
    "    print(f\"Test Set- Score: {test_score[0]}, RMSE: {test_rmse}\")\n",
    "    \n",
    "    #evaluate model on training set and test set\n",
    "    y_train_preds_scaled = model.predict(X_train_scaled)\n",
    "    y_test_preds_scaled = model.predict(X_test_scaled)\n",
    "    \n",
    "    #rescale results\n",
    "    y_train_preds_denormed = y_scaler.inverse_transform(y_train_preds_scaled)\n",
    "    y_test_preds_denormed = y_scaler.inverse_transform(y_test_preds_scaled)\n",
    "    \n",
    "    #reshape results for plotting\n",
    "    y_train_preds = np.reshape(y_train_preds_denormed, len(y_train_scaled))\n",
    "    y_test_preds = np.reshape(y_test_preds_denormed, len(y_test_scaled))\n",
    "    \n",
    "    return y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set- Score: 0.02296979169343383, RMSE: 0.15155788232036574\n",
      "Test Set- Score: 0.11483484830545343, RMSE: 0.3388729087806422\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "y_train_preds, y_test_preds, train_score, test_score =  make_preds('first_model.h5', X_train_scaled, \n",
    "                                                                   X_test_scaled, y_train_scaled, y_test_scaled, \n",
    "                                                                   y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create, compile, fit a model, and make predictions\n",
    "def fit_generic_LSTM_model(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, \n",
    "                           validation_split, model_path):\n",
    "    \n",
    "    #get train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_splitter(df, seq_length, fut_point, train_split)\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #get scalers and normalized data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler = create_scalers_and_normalize(\n",
    "        X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #create model\n",
    "    model = create_generic_LSTM_model(neurons, dropout, seq_length, features)\n",
    "    \n",
    "    #fit model\n",
    "    model.fit(X_train_scaled, y_train_scaled, epochs = epochs, \n",
    "              batch_size = batch_size, validation_split = validation_split, verbose = 1)\n",
    "    \n",
    "    #save model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    #evaluate model and get predictions\n",
    "    y_train_preds, y_test_preds, train_score, test_score = make_preds(model_path, \n",
    "                                                                      X_train_scaled, X_test_scaled, \n",
    "                                                                      y_train_scaled, y_test_scaled, y_scaler)\n",
    "    \n",
    "    #return necessary variables to create predictions\n",
    "    return y_train, y_test, y_train_preds, y_test_preds, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 128 samples\n",
      "Epoch 1/300\n",
      "721/721 [==============================] - 13s 18ms/step - loss: 0.1062 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0737 - acc: 0.0000e+00 - val_loss: 0.3066 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0699 - acc: 0.0000e+00 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0704 - acc: 0.0000e+00 - val_loss: 0.3028 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0708 - acc: 0.0000e+00 - val_loss: 0.2989 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0703 - acc: 0.0000e+00 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.2983 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0678 - acc: 0.0000e+00 - val_loss: 0.3113 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.3135 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0717 - acc: 0.0014 - val_loss: 0.2933 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0688 - acc: 0.0014 - val_loss: 0.2803 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0677 - acc: 0.0000e+00 - val_loss: 0.2786 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0676 - acc: 0.0000e+00 - val_loss: 0.2839 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0674 - acc: 0.0014 - val_loss: 0.3007 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0652 - acc: 0.0000e+00 - val_loss: 0.9151 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0636 - acc: 0.0000e+00 - val_loss: 4.7593 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.1447 - acc: 0.0000e+00 - val_loss: 0.4065 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0686 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0679 - acc: 0.0000e+00 - val_loss: 0.2823 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0663 - acc: 0.0000e+00 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 0.2838 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0653 - acc: 0.0000e+00 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.2881 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0657 - acc: 0.0000e+00 - val_loss: 0.2940 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0639 - acc: 0.0000e+00 - val_loss: 0.3290 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.3915 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0610 - acc: 0.0000e+00 - val_loss: 0.8590 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.9307 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0721 - acc: 0.0000e+00 - val_loss: 0.4470 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 0.4549 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0421 - acc: 0.0014 - val_loss: 0.2581 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0386 - acc: 0.0014 - val_loss: 0.4858 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0333 - acc: 0.0014 - val_loss: 0.4760 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0324 - acc: 0.0014 - val_loss: 0.5090 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0304 - acc: 0.0014 - val_loss: 0.5627 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0291 - acc: 0.0014 - val_loss: 0.6472 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0278 - acc: 0.0014 - val_loss: 0.6994 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0339 - acc: 0.0014 - val_loss: 0.4277 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.4038 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.2825 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.2593 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0653 - acc: 0.0000e+00 - val_loss: 0.2636 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0649 - acc: 0.0000e+00 - val_loss: 0.2669 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.2843 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0641 - acc: 0.0000e+00 - val_loss: 0.3122 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.2829 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.7358 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 1.0746 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.9497 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0661 - acc: 0.0000e+00 - val_loss: 1.2637 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0617 - acc: 0.0000e+00 - val_loss: 1.4186 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 1.1666 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0593 - acc: 0.0000e+00 - val_loss: 1.3303 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.8406 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0386 - acc: 0.0014 - val_loss: 0.5413 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0350 - acc: 0.0014 - val_loss: 0.5526 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0328 - acc: 0.0014 - val_loss: 0.5714 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0309 - acc: 0.0014 - val_loss: 0.5161 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0596 - acc: 0.0000e+00 - val_loss: 2.7609 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0692 - acc: 0.0000e+00 - val_loss: 3.8245 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0706 - acc: 0.0000e+00 - val_loss: 3.0924 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0699 - acc: 0.0000e+00 - val_loss: 1.5305 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0661 - acc: 0.0000e+00 - val_loss: 0.8577 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0672 - acc: 0.0000e+00 - val_loss: 0.6036 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.6170 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0644 - acc: 0.0000e+00 - val_loss: 0.6031 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.7469 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.6561 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.3975 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0620 - acc: 0.0000e+00 - val_loss: 0.5290 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0643 - acc: 0.0014 - val_loss: 0.4120 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.3760 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0623 - acc: 0.0000e+00 - val_loss: 0.3025 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0618 - acc: 0.0000e+00 - val_loss: 0.3221 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0617 - acc: 0.0000e+00 - val_loss: 0.3211 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0597 - acc: 0.0000e+00 - val_loss: 0.3443 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0579 - acc: 0.0014 - val_loss: 0.4831 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.6668 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.4014 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 1.8851 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0681 - acc: 0.0000e+00 - val_loss: 3.5749 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0567 - acc: 0.0014 - val_loss: 1.8414 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0366 - acc: 0.0014 - val_loss: 1.9048 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0310 - acc: 0.0014 - val_loss: 3.4883 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0303 - acc: 0.0014 - val_loss: 2.6318 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0282 - acc: 0.0014 - val_loss: 2.3632 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0340 - acc: 0.0014 - val_loss: 0.7314 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0305 - acc: 0.0014 - val_loss: 0.6156 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0282 - acc: 0.0014 - val_loss: 0.5376 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0288 - acc: 0.0014 - val_loss: 1.8888 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 2.1659 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0276 - acc: 0.0014 - val_loss: 0.4858 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0304 - acc: 0.0014 - val_loss: 0.4309 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0236 - acc: 0.0014 - val_loss: 3.4463 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0229 - acc: 0.0014 - val_loss: 3.5607 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0194 - acc: 0.0014 - val_loss: 0.4478 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0172 - acc: 0.0014 - val_loss: 1.1057 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0150 - acc: 0.0014 - val_loss: 0.5913 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0159 - acc: 0.0014 - val_loss: 0.7242 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0155 - acc: 0.0014 - val_loss: 1.0891 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0146 - acc: 0.0014 - val_loss: 1.9457 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0144 - acc: 0.0014 - val_loss: 1.7432 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0195 - acc: 0.0014 - val_loss: 0.6968 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0337 - acc: 0.0014 - val_loss: 0.9751 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0407 - acc: 0.0014 - val_loss: 0.3062 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0648 - acc: 0.0000e+00 - val_loss: 0.3979 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 1.2933 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0645 - acc: 0.0000e+00 - val_loss: 1.8025 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.9559 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0553 - acc: 0.0000e+00 - val_loss: 0.7505 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0484 - acc: 0.0014 - val_loss: 1.2136 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0388 - acc: 0.0014 - val_loss: 1.6171 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0332 - acc: 0.0014 - val_loss: 1.6586 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0291 - acc: 0.0014 - val_loss: 2.0963 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0283 - acc: 0.0014 - val_loss: 2.2332 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0262 - acc: 0.0014 - val_loss: 2.7511 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0217 - acc: 0.0014 - val_loss: 2.3657 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0336 - acc: 0.0014 - val_loss: 1.4498 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0273 - acc: 0.0014 - val_loss: 0.9754 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0228 - acc: 0.0014 - val_loss: 2.1310 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0239 - acc: 0.0014 - val_loss: 2.0108 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.1576 - acc: 0.0014 - val_loss: 1.0154 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.1464 - acc: 0.0014 - val_loss: 0.5773 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.1079 - acc: 0.0014 - val_loss: 0.6549 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.1026 - acc: 0.0000e+00 - val_loss: 0.5807 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0954 - acc: 0.0000e+00 - val_loss: 0.5684 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0907 - acc: 0.0000e+00 - val_loss: 0.6417 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0918 - acc: 0.0000e+00 - val_loss: 0.5325 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0923 - acc: 0.0000e+00 - val_loss: 0.5415 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0927 - acc: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0876 - acc: 0.0000e+00 - val_loss: 0.5992 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0877 - acc: 0.0000e+00 - val_loss: 0.6044 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0851 - acc: 0.0000e+00 - val_loss: 0.5195 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0846 - acc: 0.0000e+00 - val_loss: 0.6129 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0816 - acc: 0.0000e+00 - val_loss: 0.5528 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0745 - acc: 0.0000e+00 - val_loss: 0.4595 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0673 - acc: 0.0014 - val_loss: 0.3360 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0780 - acc: 0.0000e+00 - val_loss: 0.3950 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0788 - acc: 0.0000e+00 - val_loss: 0.4950 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0843 - acc: 0.0000e+00 - val_loss: 0.3467 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0756 - acc: 0.0000e+00 - val_loss: 0.4983 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0696 - acc: 0.0000e+00 - val_loss: 0.4336 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0733 - acc: 0.0000e+00 - val_loss: 0.5222 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0902 - acc: 0.0000e+00 - val_loss: 0.6334 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0894 - acc: 0.0000e+00 - val_loss: 0.5862 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0903 - acc: 0.0000e+00 - val_loss: 0.6680 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0904 - acc: 0.0000e+00 - val_loss: 0.6449 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0884 - acc: 0.0000e+00 - val_loss: 0.5735 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0885 - acc: 0.0000e+00 - val_loss: 0.5837 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0824 - acc: 0.0000e+00 - val_loss: 0.4859 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0804 - acc: 0.0000e+00 - val_loss: 0.4555 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0856 - acc: 0.0000e+00 - val_loss: 0.4751 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "721/721 [==============================] - 10s 15ms/step - loss: 0.0777 - acc: 0.0000e+00 - val_loss: 0.3704 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0767 - acc: 0.0000e+00 - val_loss: 0.3126 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0767 - acc: 0.0000e+00 - val_loss: 0.4492 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0774 - acc: 0.0000e+00 - val_loss: 0.4718 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0771 - acc: 0.0000e+00 - val_loss: 0.3738 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0724 - acc: 0.0000e+00 - val_loss: 0.4012 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0769 - acc: 0.0000e+00 - val_loss: 0.4242 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0726 - acc: 0.0000e+00 - val_loss: 0.3476 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0711 - acc: 0.0000e+00 - val_loss: 0.3436 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0728 - acc: 0.0014 - val_loss: 0.3834 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0734 - acc: 0.0000e+00 - val_loss: 0.3580 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.3397 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0686 - acc: 0.0000e+00 - val_loss: 0.3684 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0692 - acc: 0.0000e+00 - val_loss: 0.3483 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0724 - acc: 0.0014 - val_loss: 0.3519 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0688 - acc: 0.0000e+00 - val_loss: 0.3765 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0692 - acc: 0.0000e+00 - val_loss: 0.3622 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0678 - acc: 0.0000e+00 - val_loss: 0.3693 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0683 - acc: 0.0000e+00 - val_loss: 0.3830 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0698 - acc: 0.0000e+00 - val_loss: 0.3652 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0649 - acc: 0.0000e+00 - val_loss: 0.4082 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0584 - acc: 0.0000e+00 - val_loss: 0.4580 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0542 - acc: 0.0014 - val_loss: 0.3672 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0662 - acc: 0.0014 - val_loss: 0.4534 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0589 - acc: 0.0014 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0610 - acc: 0.0014 - val_loss: 0.3870 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0514 - acc: 0.0014 - val_loss: 0.3329 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0437 - acc: 0.0014 - val_loss: 0.3198 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0404 - acc: 0.0014 - val_loss: 0.3830 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0407 - acc: 0.0014 - val_loss: 0.3568 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0383 - acc: 0.0014 - val_loss: 0.3916 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0352 - acc: 0.0014 - val_loss: 0.4063 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0423 - acc: 0.0014 - val_loss: 0.4629 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0417 - acc: 0.0014 - val_loss: 0.3395 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0487 - acc: 0.0014 - val_loss: 0.3875 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0404 - acc: 0.0014 - val_loss: 0.3128 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.0014 - val_loss: 0.3809 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0347 - acc: 0.0014 - val_loss: 0.4594 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0341 - acc: 0.0014 - val_loss: 0.3439 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0328 - acc: 0.0014 - val_loss: 0.4449 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0358 - acc: 0.0014 - val_loss: 0.3874 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0332 - acc: 0.0014 - val_loss: 0.5034 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0320 - acc: 0.0014 - val_loss: 0.3928 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0312 - acc: 0.0014 - val_loss: 0.4301 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0341 - acc: 0.0014 - val_loss: 0.4765 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0335 - acc: 0.0014 - val_loss: 0.3684 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0313 - acc: 0.0014 - val_loss: 0.3534 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0309 - acc: 0.0014 - val_loss: 0.4338 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0314 - acc: 0.0014 - val_loss: 0.5610 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0297 - acc: 0.0014 - val_loss: 0.3581 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0304 - acc: 0.0014 - val_loss: 0.5068 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0286 - acc: 0.0014 - val_loss: 0.6265 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0293 - acc: 0.0014 - val_loss: 0.6513 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0301 - acc: 0.0014 - val_loss: 0.5640 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0263 - acc: 0.0014 - val_loss: 0.7243 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0254 - acc: 0.0014 - val_loss: 0.6481 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0243 - acc: 0.0014 - val_loss: 0.7119 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.0014 - val_loss: 0.7305 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0547 - acc: 0.0014 - val_loss: 0.3052 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "721/721 [==============================] - 12s 17ms/step - loss: 0.0478 - acc: 0.0014 - val_loss: 0.3399 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "721/721 [==============================] - 11s 16ms/step - loss: 0.0345 - acc: 0.0014 - val_loss: 0.3168 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0325 - acc: 0.0014 - val_loss: 0.3376 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0318 - acc: 0.0014 - val_loss: 0.4294 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0347 - acc: 0.0014 - val_loss: 0.4723 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0303 - acc: 0.0014 - val_loss: 0.4408 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0282 - acc: 0.0014 - val_loss: 0.4595 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0263 - acc: 0.0014 - val_loss: 0.5282 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0256 - acc: 0.0014 - val_loss: 0.5090 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0244 - acc: 0.0014 - val_loss: 0.5439 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0263 - acc: 0.0014 - val_loss: 0.4667 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0255 - acc: 0.0014 - val_loss: 0.5903 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0270 - acc: 0.0014 - val_loss: 0.5210 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0244 - acc: 0.0014 - val_loss: 0.6046 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0254 - acc: 0.0014 - val_loss: 0.5381 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0233 - acc: 0.0014 - val_loss: 0.5788 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0223 - acc: 0.0014 - val_loss: 0.5446 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0261 - acc: 0.0014 - val_loss: 0.6807 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0228 - acc: 0.0014 - val_loss: 0.6310 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0218 - acc: 0.0014 - val_loss: 0.6779 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0238 - acc: 0.0014 - val_loss: 0.6438 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0231 - acc: 0.0014 - val_loss: 0.5744 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0212 - acc: 0.0014 - val_loss: 0.6059 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0222 - acc: 0.0014 - val_loss: 0.6473 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0219 - acc: 0.0014 - val_loss: 0.6115 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0226 - acc: 0.0014 - val_loss: 0.6702 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0212 - acc: 0.0014 - val_loss: 0.6813 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0188 - acc: 0.0014 - val_loss: 0.7475 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0178 - acc: 0.0014 - val_loss: 0.7054 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0216 - acc: 0.0014 - val_loss: 0.5333 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0367 - acc: 0.0014 - val_loss: 0.4468 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0404 - acc: 0.0014 - val_loss: 0.4334 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0246 - acc: 0.0014 - val_loss: 0.6791 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0210 - acc: 0.0014 - val_loss: 0.7543 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0206 - acc: 0.0014 - val_loss: 0.6628 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0258 - acc: 0.0014 - val_loss: 0.7553 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0455 - acc: 0.0014 - val_loss: 0.3399 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0292 - acc: 0.0014 - val_loss: 0.3359 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0237 - acc: 0.0014 - val_loss: 0.4471 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0197 - acc: 0.0014 - val_loss: 0.4288 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0192 - acc: 0.0014 - val_loss: 0.5406 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0187 - acc: 0.0014 - val_loss: 0.5861 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0183 - acc: 0.0014 - val_loss: 0.5984 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0171 - acc: 0.0014 - val_loss: 0.6217 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0266 - acc: 0.0014 - val_loss: 0.6151 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0251 - acc: 0.0014 - val_loss: 0.5343 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0228 - acc: 0.0014 - val_loss: 0.3820 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0208 - acc: 0.0014 - val_loss: 0.6331 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0184 - acc: 0.0014 - val_loss: 0.6488 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0168 - acc: 0.0014 - val_loss: 0.6880 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0170 - acc: 0.0014 - val_loss: 0.6798 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0173 - acc: 0.0014 - val_loss: 0.6203 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0162 - acc: 0.0014 - val_loss: 0.5952 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0176 - acc: 0.0014 - val_loss: 0.6485 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0160 - acc: 0.0014 - val_loss: 0.6832 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0163 - acc: 0.0014 - val_loss: 0.5996 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0158 - acc: 0.0014 - val_loss: 0.5979 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0138 - acc: 0.0014 - val_loss: 0.6107 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0138 - acc: 0.0014 - val_loss: 0.4885 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0165 - acc: 0.0014 - val_loss: 0.5356 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0141 - acc: 0.0014 - val_loss: 0.6439 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0134 - acc: 0.0014 - val_loss: 0.6313 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0171 - acc: 0.0014 - val_loss: 0.6329 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0164 - acc: 0.0014 - val_loss: 0.5478 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0159 - acc: 0.0014 - val_loss: 0.5310 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0175 - acc: 0.0014 - val_loss: 0.6475 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0197 - acc: 0.0014 - val_loss: 0.5265 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0170 - acc: 0.0014 - val_loss: 0.7241 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0156 - acc: 0.0014 - val_loss: 0.5819 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0129 - acc: 0.0014 - val_loss: 0.6491 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0184 - acc: 0.0014 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0200 - acc: 0.0014 - val_loss: 0.4391 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0225 - acc: 0.0014 - val_loss: 0.6162 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0162 - acc: 0.0014 - val_loss: 0.6132 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "721/721 [==============================] - 12s 16ms/step - loss: 0.0150 - acc: 0.0014 - val_loss: 0.5867 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0143 - acc: 0.0014 - val_loss: 0.7379 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0207 - acc: 0.0014 - val_loss: 0.5317 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.0150 - acc: 0.0014 - val_loss: 0.5797 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0168 - acc: 0.0014 - val_loss: 0.5886 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 0.0146 - acc: 0.0014 - val_loss: 0.5194 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0127 - acc: 0.0014 - val_loss: 0.7028 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0101 - acc: 0.0014 - val_loss: 0.5850 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.0082 - acc: 0.0014 - val_loss: 0.5940 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.0087 - acc: 0.0014 - val_loss: 0.6511 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "721/721 [==============================] - 11s 16ms/step - loss: 0.0085 - acc: 0.0014 - val_loss: 0.5939 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.0078 - acc: 0.0014 - val_loss: 0.6630 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.10574903501498265, RMSE: 0.3251907671121409\n",
      "Test Set- Score: 1.2414444414774577, RMSE: 1.1142012571692144\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seq_length = 180\n",
    "fut_point = 80\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'third_model.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot results\n",
    "def make_results_plot(y_train, y_test, y_train_preds, y_test_preds):\n",
    "    #create x arrays (just day indices)\n",
    "    days1 = np.arange(len(y_train))\n",
    "    days2 = np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "    \n",
    "    #plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(days1, y_train, 'b', label = 'Training Set Actual')\n",
    "    ax.plot(days1, y_train_preds, 'r', label = 'Training Set Predictions')\n",
    "    ax.plot(days2, y_test, 'k', label = 'Test Set Actual')\n",
    "    ax.plot(days2, y_test_preds, 'g', label = 'Test Set Predictions')\n",
    "    ax.legend()\n",
    "    ax.set_title('Walmart Stock Predictions')\n",
    "    ax.set_xlabel('Day Index')\n",
    "    ax.set_ylabel('Closing Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set- Score: 0.10574903501498265, RMSE: 0.3251907671121409\n",
      "Test Set- Score: 1.2414444414774577, RMSE: 1.1142012571692144\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test function\n",
    "y_train_preds3, y_test_preds3, train_score3, test_score3 = make_preds('third_model.h5', \n",
    "                                                                                         X_train_scaled2, \n",
    "                                                                                         X_test_scaled2, \n",
    "                                                                                         y_train_scaled2, \n",
    "                                                                                         y_test_scaled2, y_scaler2)\n",
    "make_results_plot(y_train2, y_test2, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Interval Testing\n",
    "\n",
    "One day future point, 20 days past information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 894 samples, validate on 158 samples\n",
      "Epoch 1/300\n",
      "894/894 [==============================] - 5s 5ms/step - loss: 0.0366 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1241 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1724 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1925 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2092 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2094 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2230 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2460 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2418 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2486 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2579 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2699 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2840 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2783 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2780 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2681 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.3025 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.3252 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.3251 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3321 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3182 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.3030 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.3038 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3173 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3104 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2959 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2962 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3047 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2994 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3202 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3209 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3108 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2925 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3000 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2985 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3027 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3226 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3297 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.3209 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3252 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2884 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2703 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2798 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2913 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.3215 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3547 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.3311 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.3010 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2745 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2606 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2634 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3320 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3259 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3127 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2969 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3037 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2806 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2628 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2793 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.2995 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.3007 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2603 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2745 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.3070 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3026 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2892 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2822 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2423 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2232 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2057 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2425 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3564 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.3302 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2935 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2716 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2606 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2679 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2761 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2671 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2638 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2527 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3172 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3108 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2799 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2831 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2383 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2587 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2333 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2525 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2145 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2492 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2650 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2557 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2544 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2554 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.3213 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.3262 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.3056 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.2822 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2754 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2672 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2390 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2461 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2267 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2254 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2665 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2466 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.2186 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1988 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.2025 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1955 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1620 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1831 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2035 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2420 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2490 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1553 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1655 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1754 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1226 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1612 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1569 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1598 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1918 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2061 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2458 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1288 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1771 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1541 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1574 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1388 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1603 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1812 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1794 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0959 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0968 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1888 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1916 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1014 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1012 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1121 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1281 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1176 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1070 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0923 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1398 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0969 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1298 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0990 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1398 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1425 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0887 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1136 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1040 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0799 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0573 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0651 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1354 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "894/894 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1130 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.018251367610925277, RMSE: 0.13509762252136517\n",
      "Test Set- Score: 0.12118753662673376, RMSE: 0.3481200031982273\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seq_length = 20\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'first_one_day_model.h5'\n",
    "y_train5, y_test5, y_train_preds5, y_test_preds5, train_score5, test_score5 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train5, y_test5, y_train_preds5, y_test_preds5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try even lengths:  20 days and 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0563 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0185 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0151 - acc: 0.0011 - val_loss: 0.1187 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.0011 - val_loss: 0.1313 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0130 - acc: 0.0011 - val_loss: 0.1329 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.0011 - val_loss: 0.1557 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.0011 - val_loss: 0.1538 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.1733 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.1863 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.1987 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.0011 - val_loss: 0.2170 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.2518 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.2767 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0130 - acc: 0.0011 - val_loss: 0.2752 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.2944 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.3098 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3502 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.4169 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.4232 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.4427 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3840 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.3788 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.3782 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3828 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.4302 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0132 - acc: 0.0011 - val_loss: 0.3801 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.3353 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.3663 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.4300 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 0.4615 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.5194 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 0.6283 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 0.7072 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.6827 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 0.6740 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 0.7128 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.9465 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.7946 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.6335 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.8144 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.0011 - val_loss: 0.9689 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 1.1514 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 1.0689 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.0288 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.1169 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.1098 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 1.0971 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.5388 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.4372 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.5139 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.6901 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 1.5512 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.4288 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 1.3138 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.0991 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 2.0653 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.0011 - val_loss: 1.2695 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 1.8494 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.3152 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.7054 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.0743 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.0011 - val_loss: 1.5021 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.4398 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.6452 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.5851 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.3124 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 1.5007 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.7726 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.9313 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 2.1830 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.9801 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 2.2262 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.8976 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 2.3025 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 2.0072 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.0011 - val_loss: 1.6428 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.7466 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 2.5954 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.0343 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.4500 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.6938 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.6747 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 0.0011 - val_loss: 1.2102 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.0011 - val_loss: 1.3674 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.8075 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 1.9461 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 0.0011 - val_loss: 1.6211 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 2.1732 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.9146 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.9268 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 1.9754 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0121 - acc: 0.0011 - val_loss: 1.5007 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 1.9965 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.4946 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 2.0592 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.6318 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.1056 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.6440 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 2.2226 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.2494 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.6039 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 1.9905 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.3729 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.5444 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 1.5557 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.0011 - val_loss: 1.4498 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.8040 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 2.2223 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.9444 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.8672 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 1.2102 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.3349 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.7300 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 0.7397 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.0011 - val_loss: 2.0087 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 1.4404 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.6584 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.7111 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.5468 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.4080 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.6662 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 0.8267 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.3064 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.2546 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.0011 - val_loss: 0.4917 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.0011 - val_loss: 0.3408 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.1966 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.0011 - val_loss: 0.2982 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.2846 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.3477 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.0011 - val_loss: 0.3714 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.8127 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.0011 - val_loss: 0.3102 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.4972 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.4913 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.3115 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.3648 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.0011 - val_loss: 0.1922 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.4853 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.0011 - val_loss: 0.4018 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3190 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4081 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.4168 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.3063 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.0011 - val_loss: 0.4388 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.3425 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4327 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4610 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.4550 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3102 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.3929 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3289 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3721 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.3671 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.3279 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.4743 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.6663 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3647 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.3601 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.3413 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.0011 - val_loss: 0.4825 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.0011 - val_loss: 0.4758 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.4932 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.3132 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.4481 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.3750 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3800 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.2610 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.0011 - val_loss: 0.3171 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.2465 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.3696 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.3504 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.4255 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.2336 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.2063 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3565 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.2432 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3979 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.3238 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.5329 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.3794 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.4269 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.3312 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.5068 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3201 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3300 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.5666 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.0011 - val_loss: 0.5148 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.4600 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.6063 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.5378 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.0011 - val_loss: 0.2860 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.2774 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.3522 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.4637 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.3237 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.6189 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.7263 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.6355 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.5242 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.2403 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.2113 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.6915 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.3190 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.2791 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.4405 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.4078 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.7121 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.3357 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.0011 - val_loss: 0.4101 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.0011 - val_loss: 0.4705 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.1404 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3708 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.2763 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.3362 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.3129 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.3919 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.4237 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.3949 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.2450 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.3550 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3028 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.1590 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.3049 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.3395 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.2250 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.2399 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.2128 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.2566 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.1281 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.0011 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.0011 - val_loss: 0.3259 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.2302 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.2362 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.0011 - val_loss: 0.1676 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.1650 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.1543 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.1729 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.2064 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1417 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1098 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1280 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.0011 - val_loss: 0.2600 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.0011 - val_loss: 0.2141 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.0011 - val_loss: 0.1841 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0081 - acc: 0.0011 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.1698 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.1632 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.2681 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.3532 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.2865 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.2543 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.2096 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "880/880 [==============================] - 2s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.2108 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.1862 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.2167 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.2085 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1969 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.2032 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "880/880 [==============================] - 1s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.2742 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.2150 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.2291 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.039451694439621966, RMSE: 0.19862450614066224\n",
      "Test Set- Score: 0.2755998133635912, RMSE: 0.5249760121792149\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seq_length = 20\n",
    "fut_point = 20\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'four_week_model.h5'\n",
    "y_train6, y_test6, y_train_preds6, y_test_preds6, train_score6, test_score6 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train6, y_test6, y_train_preds6, y_test_preds6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 905 samples, validate on 160 samples\n",
      "Epoch 1/300\n",
      "905/905 [==============================] - 3s 4ms/step - loss: 0.0426 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "905/905 [==============================] - 0s 476us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1239 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "905/905 [==============================] - 1s 622us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1176 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "905/905 [==============================] - 0s 516us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "905/905 [==============================] - 1s 598us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1163 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "905/905 [==============================] - 0s 526us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "905/905 [==============================] - 1s 718us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "905/905 [==============================] - 1s 597us/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "905/905 [==============================] - 1s 677us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "905/905 [==============================] - 1s 747us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "905/905 [==============================] - 1s 663us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "905/905 [==============================] - 1s 627us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "905/905 [==============================] - 1s 681us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "905/905 [==============================] - 1s 674us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "905/905 [==============================] - 1s 611us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "905/905 [==============================] - 1s 741us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "905/905 [==============================] - 1s 664us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1733 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "905/905 [==============================] - 1s 588us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1778 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1823 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "905/905 [==============================] - 1s 689us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1830 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "905/905 [==============================] - 1s 731us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1862 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "905/905 [==============================] - 1s 682us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "905/905 [==============================] - 1s 690us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "905/905 [==============================] - 1s 674us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1811 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "905/905 [==============================] - 1s 666us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "905/905 [==============================] - 1s 720us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1749 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1801 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "905/905 [==============================] - 1s 600us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1817 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "905/905 [==============================] - 1s 607us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1785 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "905/905 [==============================] - 1s 586us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1873 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "905/905 [==============================] - 1s 591us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1725 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1735 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1763 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1775 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "905/905 [==============================] - 1s 569us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1734 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1752 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1796 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1804 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1761 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1816 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1828 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1807 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1831 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1742 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1618 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1730 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "905/905 [==============================] - 1s 567us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1683 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1664 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "905/905 [==============================] - 0s 530us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1792 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1617 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "905/905 [==============================] - 0s 533us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1659 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1639 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "905/905 [==============================] - 0s 537us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1611 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "905/905 [==============================] - 0s 533us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1602 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1575 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1615 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "905/905 [==============================] - 0s 527us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1680 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1776 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "905/905 [==============================] - 1s 605us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1680 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "905/905 [==============================] - 0s 533us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1267 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1563 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "905/905 [==============================] - 1s 603us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1506 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1519 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "905/905 [==============================] - 1s 631us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "905/905 [==============================] - 1s 672us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "905/905 [==============================] - 1s 710us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1412 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "905/905 [==============================] - 1s 615us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1588 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1532 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "905/905 [==============================] - 1s 619us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "905/905 [==============================] - 1s 593us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1577 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "905/905 [==============================] - 1s 569us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1732 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "905/905 [==============================] - 1s 583us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1613 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1652 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "905/905 [==============================] - 1s 571us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1218 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "905/905 [==============================] - 1s 567us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1384 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1452 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1233 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 0s 551us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "905/905 [==============================] - 1s 575us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1250 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "905/905 [==============================] - 0s 534us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1546 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "905/905 [==============================] - 0s 539us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1504 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "905/905 [==============================] - 0s 530us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "905/905 [==============================] - 0s 535us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1317 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1607 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1565 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "905/905 [==============================] - 1s 665us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1425 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "905/905 [==============================] - 1s 588us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "905/905 [==============================] - 1s 685us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1437 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "905/905 [==============================] - 1s 698us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1442 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "905/905 [==============================] - 1s 593us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1357 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "905/905 [==============================] - 1s 600us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1534 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "905/905 [==============================] - 1s 624us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1468 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "905/905 [==============================] - 0s 523us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1544 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "905/905 [==============================] - 0s 467us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1407 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "905/905 [==============================] - 1s 644us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1396 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1393 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "905/905 [==============================] - 0s 523us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1109 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "905/905 [==============================] - 0s 519us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "905/905 [==============================] - 0s 519us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "905/905 [==============================] - 1s 607us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1250 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "905/905 [==============================] - 1s 604us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "905/905 [==============================] - 1s 561us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1412 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1369 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "905/905 [==============================] - 1s 613us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1443 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1385 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "905/905 [==============================] - 1s 671us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0986 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "905/905 [==============================] - 0s 518us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "905/905 [==============================] - 0s 450us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "905/905 [==============================] - 0s 510us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "905/905 [==============================] - 0s 471us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1486 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "905/905 [==============================] - 0s 450us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1395 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "905/905 [==============================] - 0s 456us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1601 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "905/905 [==============================] - 0s 500us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1369 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1530 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "905/905 [==============================] - 0s 511us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1589 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "905/905 [==============================] - 0s 464us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "905/905 [==============================] - 0s 510us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1540 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1457 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1572 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1735 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "905/905 [==============================] - 0s 448us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "905/905 [==============================] - 0s 506us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1427 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1552 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1411 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "905/905 [==============================] - 0s 472us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "905/905 [==============================] - 0s 511us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1264 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "905/905 [==============================] - 0s 486us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1579 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "905/905 [==============================] - 0s 527us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1394 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "905/905 [==============================] - 1s 621us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "905/905 [==============================] - 1s 745us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "905/905 [==============================] - 1s 724us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "905/905 [==============================] - 1s 601us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1104 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "905/905 [==============================] - 1s 583us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1368 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "905/905 [==============================] - 0s 492us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1109 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "905/905 [==============================] - 0s 473us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1675 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "905/905 [==============================] - 0s 478us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1420 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "905/905 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "905/905 [==============================] - 0s 459us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1485 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "905/905 [==============================] - 0s 460us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "905/905 [==============================] - 0s 460us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1302 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1616 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "905/905 [==============================] - 0s 486us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "905/905 [==============================] - 0s 495us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "905/905 [==============================] - 1s 680us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "905/905 [==============================] - 1s 847us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1885 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "905/905 [==============================] - 1s 587us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1662 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1501 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "905/905 [==============================] - 0s 471us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1825 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "905/905 [==============================] - 0s 457us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1447 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1359 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1192 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "905/905 [==============================] - 0s 478us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "905/905 [==============================] - 0s 468us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "905/905 [==============================] - 0s 475us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1594 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "905/905 [==============================] - 0s 464us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1218 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "905/905 [==============================] - 0s 472us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1055 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "905/905 [==============================] - 0s 506us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "905/905 [==============================] - 0s 477us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1291 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "905/905 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1241 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "905/905 [==============================] - 0s 467us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "905/905 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "905/905 [==============================] - 0s 516us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "905/905 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "905/905 [==============================] - 0s 481us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "905/905 [==============================] - 0s 484us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "905/905 [==============================] - 0s 507us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "905/905 [==============================] - 0s 487us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "905/905 [==============================] - 0s 462us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "905/905 [==============================] - 0s 515us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "905/905 [==============================] - 0s 480us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "905/905 [==============================] - 0s 477us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "905/905 [==============================] - 0s 469us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "905/905 [==============================] - 0s 468us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "905/905 [==============================] - 0s 465us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1124 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "905/905 [==============================] - 0s 472us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "905/905 [==============================] - 0s 458us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "905/905 [==============================] - 0s 461us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "905/905 [==============================] - 0s 456us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "905/905 [==============================] - 0s 463us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "905/905 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1318 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "905/905 [==============================] - 0s 460us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "905/905 [==============================] - 0s 450us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "905/905 [==============================] - 0s 455us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1104 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "905/905 [==============================] - 0s 453us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "905/905 [==============================] - 0s 470us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "905/905 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.022006138167540792, RMSE: 0.1483446600573839\n",
      "Test Set- Score: 0.15339001949797285, RMSE: 0.39165037916229933\n"
     ]
    }
   ],
   "source": [
    "#predict one day ahead with last week's data\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'one_day_model.h5'\n",
    "y_train4, y_test4, y_train_preds4, y_test_preds4, train_score4, test_score4 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4FMX7wD8TEpJQA4TeBeRnCCGE0JReRUApKij9SxcU7KgoRVAUO4iIgCAgRRBEQ5OOKE16kd4JEEII6e3m98fuXe6Sy+VC7nJJmM/z3LO7szOz720u++7M+877CiklCoVCoVCkxc3VAigUCoUid6IUhEKhUCisohSEQqFQKKyiFIRCoVAorKIUhEKhUCisohSEQqFQKKyiFIQixxBCTBRCLHa1HDmNEKKVEOKaq+UAEEIsEEJM0febCyFOP2A/s4UQ7ztWOkVuQykIRYYIId4RQqxLU3Y2g7LeOStd5gghLgkh2mVS510hxEUhRLQQ4poQYrnZue1CiCHOl9RCnoFCiBRdnvtCiMNCiC7OuJaUcpeUsradMv2Vpu0IKeWHzpBLkXtQCkJhi53AE0KIAgBCiHKABxCUpqymXjdXIIRwt7PeAKAf0E5KWQQIBrY4UzY7+UeXxweYB6wQQpRMW8ne76lQPChKQShssR9NIQTqxy2AbcDpNGXnpZQ3AIQQXwshrupvv/8KIZpb61gIUU0IIYUQg/T6EUKIEUKIhkKIo0KIe0KImWb1awghtgohwoUQd4QQS4QQPmbnLwkh3hZCHAVihBBLgSrA7/rb+FtWxGgIbJRSngeQUt6UUs7R+5sKNAdm6u1n6uWPCyH2CyEi9e3jZjKUFEL8KIS4oX+fNRl891eEECeFEJVs3XwppQGYD3gDjxinqvTveRP4Ue+viz7SuCeE+FsIEWB2rfpCiINCiCh9dORlds5i6ksIUVkI8asQIky/zzOFEI8Bs4Gm+n24p9c1TVXpx0OFEOeEEHeFEGuFEBXMzkn9b3tWvy/fCiGEfq6mEGKHfj/vmI/gFK5HKQhFhkgpE4G9aEoAfbsL+CtNmfnoYT+a8igJ/Az8IoTwImMaA7WAXsBXwHtAO6AO8LwQoqVeTwAfAxWAx4DKwMQ0fb0AdAZ8pJQvAFeArlLKIlLKT61cew/QXwjxphAi2Dgq0r/7e/p3Ha23H62/xYcA3wClgC+AECFEKb3ZIqCQLnsZ4Mu0F9Tn7QcCLaWUNu0S+ghhCBANnNWLy6Hd26rAMCFEEJoSGa7L9D2wVgjhKYQoCKzR5SoJ/AL0zOBaBYA/gMtANaAisExKeQoYgT6qkVL6WGnbBu1v8zxQXu9jWZpqXdAUcj29Xke9/ENgE1ACqATMsHVPFDmLUhCKzNhBqjJojvbQ3JWmbIexspRysZQyXEqZLKX8HPAEbM1zfyiljJdSbgJigKVSyttSyuv6derr/Z6TUv4ppUyQUoahPZxbpunrGynlVSllnD1fTEq5GHgZ7WG1A7gthBhno0ln4KyUcpH+/ZYC/wFdhRDlgU7ACCllhJQySUq5w6ytEEJ8oV+rtf4dMqKJ/qZ+E03pdZdSRurnDMAE/T7EAUOB76WUe6WUKVLKhUAC0ET/eABf6fKsRFPg1miEpnzflFLG6H+TvzKom5Y+wHwp5UEpZQLwDtqIo5pZnWlSyntSyitoo1DjCDQJTdlVyOI1FTmAUhCKzNgJNBNClABKSynPAn8Dj+tl/piNIIQQrwshTulTBveA4oCvjf5vme3HWTkuovdbRgixTAhxXQhxH1hspd+rWf1yUsolUsp2aPP9I4DJQoiOGVSvgPZ2bM5ltLftysBdKWVEBm19gGHAx2YP+4zYI6X0kVL6SimbSCk3m50Lk1LGmx1XBV7Xp5fu6fe8si5rBeC6tIzImVZ+I5WBy1LK5Exks4bFfZFSRgPhaPfFyE2z/Vj0vyvwFtrocJ8Q4oQQ4n8PcH2Fk1AKQpEZ/6A95IcBuwGklPeBG3rZDSnlRdDcJoG30aYQSujTEZFoD4Ds8jEggQApZTGgr5V+04YmtjtUsf6G/QtwFE3pWWt/A+2BbE4V4DqacippbhdJQwTaNMuPQogn7JXLmqhpjq8CU3WFYvwU0kc3oUBF43y/mbzWuApUEdYN35ndR4v7IoQojDbddT2Tdka7z1ApZQW0abJZQoiambVT5AxKQShsok9jHABeQ5vyMfKXXmZufygKJANhgLsQ4gOgmINEKYo2F39PCFEReNOONreARzI6KTT3zc5CiKJCCDchRCc0+8HeDNqvAx4VQrwohHAXQvQC/IA/pJShwHq0B1wJIYSHEKKF+fWklNvRpmNWCyEa2/Ol7eAHYIQQorHQKGz8TmjKPRl4RZe3B9pUkjX2oSmUaXofXmaK7BZQSbdpWONnYJAQIlAI4Ql8BOyVUl7KTHghxHNmxvoINGWUkvnXVuQESkEo7GEHmtHVfH54l15mriA2oj0kz6BNOcTzANM+GTAJCEIbkYQAv9rR5mNgvD718oaV8/eBd9GM2feAT4GRZvPgXwPP6p4330gpw9FGAa+jTaG8BXSRUt7R6/dDm1P/D7gNjE17QSnln8AgNENyAzu+g02klAfQ7BAz0R6w59CM4EYngx76cQSaI4DV+yalTAG6orksXwGu6fUBtgIngJtCiDtW2m4B3gdWoSmZGoC962IaAnuFENHAWmCMcUSqcD1CJQxSKBQKhTXUCEKhUCgUVlEKQqFQKBRWUQpCoVAoFFZRCkKhUCgUVsnTwb58fX1ltWrVXC2GQqFQ5Cn+/fffO1LK0pnVy9MKolq1ahw4cMDVYigUCkWeQgiR0Yp6C9QUk0KhUCisohSEQqFQKKyiFIRCoVAorJKnbRDWSEpK4tq1a8THx2deWaF4QLy8vKhUqRIeHh6uFkWhcBr5TkFcu3aNokWLUq1aNSyDWCoUjkFKSXh4ONeuXaN69equFkehcBr5boopPj6eUqVKKeWgcBpCCEqVKqVGqYp8T75TEIBSDgqno35jioeBfKkgFArFw8Pp07Btm6ulyJ8oBeFgwsPDCQwMJDAwkHLlylGxYkXTcWJiol19DBo0iNOnT9us8+2337JkyRJHiMxvv/1GYGAg9erVw8/Pj7lz59qsv3XrVvbs2WOzTufOnWnevHmm17579y6zZ8/Okrxp6du3L2vWrMlWH4q8y//9H7Rp42op8if5zkjtakqVKsXhw4cBmDhxIkWKFOGNNyxz1UgpkVLi5mZdP//444+ZXmfUqFHZFxZISEhg5MiRHDhwgAoVKpCQkMDly7YXWW7duhVfX1+aNGli9Xx4eDjHjh3Dy8uLK1euUKVKRlkuUxXEiBEjsvU9FAqF41EjiBzi3Llz+Pv7M2LECIKCgggNDWXYsGEEBwdTp04dJk+ebKrbrFkzDh8+THJyMj4+PowbN4569erRtGlTbt++DcD48eP56quvTPXHjRtHo0aNqF27Nn///TcAMTEx9OzZk3r16vHCCy8QHBxsUl5GIiMjkVJSsmRJADw9PXn00UcBuHXrFj169CA4OJhGjRqxZ88ezp8/z9y5c5k+fTqBgYGma5mzcuVKunXrRq9evVi+fLmp/ObNmzzzzDMEBARQr1499u7dy7hx4zh9+jSBgYGMGzeOzZs3061bN1ObESNGsHjxYgAmTJhAw4YNTfdRJbtSmKN+Do4nX48gxo6FNM/DbBMYCPpzOcucPHmSH3/80TSlMm3aNEqWLElycjKtW7fm2Wefxc/Pz6JNZGQkLVu2ZNq0abz22mvMnz+fcePGpetbSsm+fftYu3YtkydPZsOGDcyYMYNy5cqxatUqjhw5QlBQULp2ZcqUoWPHjlStWpW2bdvStWtXevXqhZubG6+88gpvvfUWTZo04dKlS3Tp0oXjx48zZMgQfH19GTs2XUZNAJYuXcrHH39M8eLF6du3L2++qaWPHjVqFO3bt2f06NEkJycTGxvLtGnTOHfunElxbd68OcP7N2bMGCZNmoSUkhdffJENGzbQqVMn+26+It+TmAienq6WIn+hRhA5SI0aNWjYsKHpeOnSpQQFBREUFMSpU6c4efJkujbe3t6mh2CDBg24dOmS1b579OiRrs5ff/1F795aauB69epRp04dq20XLFjAn3/+SXBwMNOmTWPYsGGA9rAeMWIEgYGBdOvWjYiICOLi4mx+x+vXr3PlyhWaNGmCn58fKSkp/PfffwBs376d4cOHA+Du7k6xYsVs9pWWLVu20KhRI+rVq8eOHTs4ceJEltor8jfR0a6WIP+Rr0cQD/qm7ywKFy5s2j979ixff/01+/btw8fHh759+1r1qy9YsKBpv0CBAiQnJ1vt21N/dTKvk5UpmICAAAICAnjxxRd57LHHmDt3rmlUYi5DZixfvpzw8HDTArLIyEiWLVvGxIkTgczdQ93d3TEYDKZj4z2JjY1l9OjRHDx4kIoVKzJ+/Hi1DkFhQVQUlCrlainyF2oE4SLu379P0aJFKVasGKGhoWzcuNHh12jWrBkrVqwA4NixY1ZHKPfv32fnzp2m48OHD1O1alUA2rVrx7fffmtxDqBo0aJERUVZvebSpUvZvHkzly5d4tKlS+zbt4+lS5cC0Lp1a9P0WkpKiukemPdVtWpVTpw4QWJiIhEREWzduhWAuLg43Nzc8PX1JSoqilWrVj3wfVHkT/LyCOLIkSOuFsEqSkG4iKCgIPz8/PD392fo0KE88cQTDr/Gyy+/zPXr1wkICODzzz/H39+f4sWLW9SRUvLxxx9Tu3ZtAgMDmTJlCvPnzwc0V9rdu3cTEBCAn58fP/zwAwDPPPMMK1asoH79+hZG6vPnz3Pz5k2Cg4NNZbVq1cLT05N///2XmTNnsnHjRurWrUtwcDD//fcfZcuWJTg4mLp16zJu3DiqV69Ot27dqFu3Lv379zfZTUqVKsWAAQPw9/ene/fuNG7c2OH3S5G3yasKYvny5QQGBrJ69WpXi5Ieo8tlXvw0aNBApuXkyZPpyh5WkpKSZFxcnJRSyjNnzshq1arJpKQkF0uVf1C/NdeTkCCl5r8k5Z9/ulqaB2Ps2LESkJ999lmOXRM4IO14xuZrG8TDTnR0NG3btiU5ORkpJd9//z3u7upPrsg/xMSk7ufVEUS0Lri5jTK3oJ4W+RgfHx/+/fdfV4uhUDiN+/et7+clYmNjgaw5leQUygahUCjyLGFhqfv37rlOjuxgVBD3c6GGUwpCoVDkWcyc7PKsgjB68WXkGehKlIJQKBR5lpUrU/cjIlwnR3Ywhs/JjSMIZYNQKBR5lkqVtGiuBw/mXQVx69YtQI0gHgoe9nDfc+fOpXTp0gQGBvLYY4+Z1lQ8KOahvDO7L2nlcuQ9UuRObt2CihXBxydvKoj4+HjCdEOKGkE8BKhw39CnTx+++uorbt68ib+/P08//TS+vr6m88nJyQ/kbpvZfUkrl6PukSJ3kpSkKQVfXyhRQtu/fFkLqLlnD9Su7WoJM+fs2bMm76XcqCDUCCKHeJjCfRspV64c1apV48qVK4wfP57hw4fTvn17Bg0aRHJyMq+99hqNGjUiICDANGoxGAy89NJL+Pn50bVrV+7cuZPuvgCEhIQQFBREvXr16NChg1W5zO/RwYMHady4MQEBAfTs2ZPIyEib9+7YsWM0bNiQwMBAAgICuHDhwoP82RVO5MYNbVuuXKqCWLJEM1YvWOBS0ezm7NmzgBZDzejNlJvI3yOIXBbv+2EJ923k3LlzXL58mUceeQSAQ4cOsXPnTry8vJg1axZlypRh3759JCQk0KRJEzp06MCePXu4ePEix48f58aNG/j5+aVLJnTz5k1GjhzJrl27qFq1Knfv3qVkyZLp5Fq3bp2pTd++fZkzZw7NmjXj3Xff5cMPP+Szzz7L8N7NmjWLN954g169epGQkJArfdQfdg4d0rZBQbBrF8THg/EZW6iQ6+Syl3///ZeePXsC2v+hUhAPOdbCfc+bN4/k5GRu3LjByZMn0ymItOG+d+3aZbXvjMJ9v/3220Dm4b6PHj3K5s2bmTZtGlu2bGHu3Lls3rzZYs7fnnDfAEuWLGHHjh0ULFiQuXPn4uPjA2gxnLy8vADYtGkTp06dYtmyZYCmCM+ePcvOnTt54YUXcHNzo1KlSrRq1Spd///88w+tW7c2BRU0jn4yIjw8nPj4eJo1awbAgAED6Nevn+m8tXv3+OOPM2XKFC5fvkyPHj2oWbNmpt9bkbPog0B8fcHdHZKT85aCMA/QV7p0aWLMl4XnEvK3gshl8b4fhnDfkGqDSIv595dSMmvWLNq2bWtRZ/Xq1ZmGBJdSZlonbX1bWLt3/fr1o2nTpoSEhNC+fXsWLlxIixYt7L6mwvmYK4O8qCDMf8NlypTh1KlTLpTGOsoG4SLya7hve+nYsSOzZs0yPZBPnz5NXFwcLVq0YNmyZRgMBq5fv86OHTvStX3iiSfYunWryZh+9+5dm3L5+vri7e1tsi8sWrSIli1b2pTvwoUL1KxZkzFjxtC5c2eOHj2are+rcDzGwWx+URC5cYrJaQpCCDFfCHFbCHHcrKykEOJPIcRZfVtCLxdCiG+EEOeEEEeFEOkny/MZ+THcd1YYPnw4tWrVIjAwEH9/f0aOHElycjLPPvssVapUwd/fn9GjR1t9ay9btizfffcdzzzzDPXq1aNPnz6ZyrVo0SJeffVVAgICOHnyJOPHj7cp388//0ydOnUIDAzkwoUL9O3b94G+p8J5GJ+n3t6agrhzJ3U1tbe36+SyF3MvxtyqIJwWihtoAQQBx83KPgXG6fvjgE/0/aeA9YAAmgB77bmGCvdtGxXu27mo35preecdKT08tP1XXkkN+w1SrlrlWtnsYdGiRRKQgJw0aZIEZHJyco5cG1eH+5ZS7hRCVEtT/AzQSt9fCGwH3tbLf9IF3yOE8BFClJdShjpLvocBFe5bkZ+JjU0dKaT9Wec1pzOjfS42NpaiRYu6WJpUcvppUdb40JdShgohyujlFYGrZvWu6WXpFIQQYhgwDKBKlSrOlTaPo8J9K/IzsbGptoYCBSzPmaU1z7WYO5wU0r9IblMQucVIbc0lxeo7gJRyjpQyWEoZXLp0aSeLpVAocivmCiIlxfJcXlAQCQkJAEyaNMmkIHKbq2tOK4hbQojyAPr2tl5+DahsVq8ScCOHZVMoFHmAlBRo3BiWLUtVEElJlnXywhSTUUGMGjXKYoopN5HTCmItMEDfHwD8ZlbeX/dmagJEKvuDQqGwxv37sG+fpigyUhB5YQRxT3e5Klas2MM3ghBCLAX+AWoLIa4JIQYD04D2QoizQHv9GGAdcAE4B/wAvOQsuRQKRd7G/BlqNE7nRQUxYcIEADw8PEwKwp5IBTNmzLAaNscZOE1BSClfkFKWl1J6SCkrSSnnSSnDpZRtpZS19O1dva6UUo6SUtaQUtaVUh5wllzOxhHhvgHmz5/PzZs3rZ7bvXs3jRs3NoXU/vDDD232dfDgQTZs2GCzzqhRo6hSpUqmq44NBgPTpk2zWSczzIPoKRRZJTo6dd+43CVtEIK8oCDM8dbdseLi4khMTLS5EPWVV17h0KFDhIeHO12u3GKkzjcYw30fPnyYESNG8Oqrr5qOsxKywpaCGDBgAPPmzePw4cMcP37cFPArIzJTECkpKaxdu5by5cuze/dum305QkEoFNnBXEG0bq1t0+aCcIUN4pNPPmHhwoV21TW+iNWoUQOw9GJq3bo1xYoVy7SPq1evZlonuygFkYMsXLiQRo0aERgYyEsvvYTBYCA5OZl+/fpRt25d/P39+eabb1i+fDmHDx+mV69eVkceYWFhlCtXDtDiBxkD/EVHRzNw4EAaNWpE/fr1+f3334mLi2Py5MksWbKEwMBAVprnaNTZvHkz9evXZ9iwYSxdutRUHhUVxYABA6hbty4BAQGsWbOGcePGERUVRWBgIP379+fcuXMEBgaa2kybNo0pU6YAMHv2bBo2bEi9evV47rnn7Bo+KxSZYa4g9FiUpH2ZdsUIYty4cQwcONCuukYD9eDBgwHLEYS90QmizW+Ek8jXq6bGjh2bLv9BdgkMDHyg6ZHjx4+zevVq/v77b9zd3Rk2bBjLli2jRo0a3Llzh2PHjgGa4crHx4cZM2Ywc+ZMi4evkbFjx1KrVi1at25Np06d6N+/P56enkyePJknn3ySBQsWEBERQePGjTl69CgffPABx48fz1DupUuX8sILL9CpUycmTJjA119/jbu7OxMnTqR06dIcO3YMKSX37t2jS5cuzJ0713Rfz507l+F3fu6550yhuseNG8eCBQsYOXJklu+dQmGOnqET0HJBAEybljqagNw/xWQ0Rhu9l8xHELYwn1bKCQWhRhA5xObNm9m/fz/BwcEEBgayY8cOzp8/T82aNTl9+jRjxoxh48aN6WIlWWPSpEns37+fdu3a8dNPP9G5c2dAC6E9depUAgMDad26NfHx8Vy5csVmXwkJCWzatImnn34aHx8fgoKC2LJli0lmY1Y2IQQlSpTI0nc+evQozZs3p27duixbtowTJ05kqb1CkZaUFPjrr9Tjxx7Ttq1aaR8jud3N1TiVW0Bf4Wc+grCFeQItNYLIJrnJECql5H//+59Vg/LRo0dZv34933zzDatWrWLOnDmZ9lezZk1q1qzJ0KFDKVWqlCkz3Jo1a0zzmkbMo7WmJSQkhMjISFOuiJiYGEqWLEnHjh3tCqvt7u6Owex1LT4+3hTOo3///qxfvx5/f3/mzp2bYR5rhcJeunSBDRu0HNQ7doC5Wc/fH7Zv1/Zz+wjigw8+ADBliDSOJDJL92uMXAxkO6KyPagRRA7Rrl07VqxYYXoDCA8P58qVK4SFhSGl5LnnnmPSpEkcPHgQsB1SOyQkxGTkOnPmDJ6enhQtWpSOHTvyzTffmOod0lNu2epr6dKlLFiwgEuXLnHp0iUuXLjA+vXriY+Pp0OHDsycORPQFFxERITp4W8ME1CuXDlu3LhBREQE8fHxhISEmPqOiYmhXLlyJCUl8fPPPz/wvVMoQAvnbfS1qFMHAgIsz0+dqqUchdyrIG7dukVkZCQp+tLvN998E9DyvhQpUoQvv/zSVDcl7fJwLKeYjHlMnIlSEDlE3bp1mTBhAu3atSMgIIAOHTpw69Ytrl69SosWLQgMDGTo0KF89NFHAAwaNIghQ4ZYNVIvWLDAFJ574MCB/Pzzz7i5uTFhwgRiY2OpW7cuderUYeLEiQC0adOGI0eOUL9+fQsjdXR0NFu2bDFlrANNmTRu3JiQkBAmTJjArVu38Pf3JzAw0JTNbvDgwQQEBNC/f3+8vLx49913adiwIU8//bRFRrzJkyfTqFEj2rdvny5TnkKREVLCP/+kL69UKXX//v3054sVA2P+KVdOMRkf7LNnzza98BkpV64cjzzyCOfOncPT05MiRYqYzpUqVcqirjW3eGOGx9u3b/Piiy86WvT02BPyNbd+VLhvhStRvzXnMHOmFrL7jz9Sy+LjLcN5T59uve3t29r5mTNzRlZz0EN3R0VFyc2bN5uOrdUB5Lvvvmtxrn79+hbn7927l+4aLVq0kDVq1HCErHaF+1YjCIVCkas4c8ZyCxAWlrq/ciW8/rr1tkaTmSunmGJjY2nXrl2m9S5cuGBx7J0my5G1EcTNmzcJDg7OnoBZQCkIhUKRqzBOrZs/H81NWO3bpyqCtBiTtLlyiqlRo0YWxykpKVYjFJQvX97iOK1NwZqCiIqKsmsRnaNQCkKhUOQqjM9JfS0ZkLogbudOzdaQEUYF4coRRFpPpDJlyvD000+nq2dcUGokrYJIML8BaG7soaGhOZovQikIhUKRqzC6rhpfoM2deTJLAePKKaa0RmYjd+/e5Y8//rAoq1GjhmlxnJG0oXjCzObV4uPj6dixI4BSEAqF4uHFfAQhJWzenHouzaxMOlw5xWTNLdUc83hoae0NkH4EYW6jMF8gV6tWrQcVMcsoBaFQKHIVxhfp+Hj48kt48kntuHt3yCzQgCunmMwXjPbr1y9dTCVzd3JraxjS2hwizCIQGtc/vPvuuznj3qqjFISDyWvhvjdv3kzx4sVNfU2dOtVuGa1hHsr7vffeY9u2bXbLtXr1aqZPn56t6yvyPl5e2nbmTEtvpVmzMm/ryikmg8GAly68h4eHzbU/1nLFGxMI9ejRA7BMHmQcQXTs2DHT6AaORCkIB5MXw323bt2aw4cPs3//fubNm8eRI0cszpsnV88KU6dOpbV5BLVM5OrevbtpZani4cXaFHt4eGpgPlu4corJYDDQSg8IFRQUZMoU93pGPrlpMMZWMkaEfeutt0zTVkYF4evr61ihM0EpiBwkt4b7NlKkSBGCgoI4f/48c+fOpXfv3nTp0sU0NJ42bRqNGjUiICCAyZMnm9pNnjyZ2rVr0759e86ePWsq79u3L2vWrAFg7969NG3alHr16tG4cWNiYmLSyTV37lzGjh0LwMWLF2ndujUBAQG0b9+ea9eumfocM2YMjz/+OI888girV68G4Pr16zRr1ozAwED8/f3tDpmsyH1Ye/svWdK+tq6eYgoICODq1auMHDkSIQQxMTF89tlndrUvW7YsoHk9GTFGS3aVgsjXwfrGbhjL4ZsODvddLpCvnsxf4b6NhIWFsW/fPqZOncquXbv4559/OHz4MCVKlGDdunVcuXKFvXv3IqXkqaeeMn2XVatWcfjwYRITEwkMDKRp06YW/cbHx9O7d29WrVpFUFAQkZGReHl5pZNr7ty5pjYvvfQSQ4YMoU+fPsyZM4exY8ealNvt27fZvXs3x44d4/nnn6d79+4sXryYrl278vbbb5OSkqJyT+RhzN/+69SBNNEqbOLqKSY3NzcqmccE0SlRooSFTcEa06dPp2nTphbpRG/dukWtWrUYPXo0ACXt1ZQOIl8riNyEebhv0ML6Vq5cmY4dO5rCfT/11FN06NAh074mTZpEv3792LRpEz/99BPLly9n8+bNbNq0ifXr15syvtkT7htg27Zt1K9fHzc3N95//31q167Nrl276NChgynEt7Hv+vXrA9po5cyZM9y5c4eePXvi7e2Nt7c3Xbt2Tdf/qVOnqFIdP0CwAAAgAElEQVSliumHb09I871795pcA/v378/7779vOtetWzeEEAQEBHD9+nUAGjZsyPDhw4mPj6dbt27Uq1cv02socifmD/cPPrCM2JoZrp5icnOzPilz7NgxatWqZXpxMY58zfHz80tntzh//ryFW6sxWGZOka8VxIO86TsLmUvDfYNmgzBOBZljDEFslH/8+PGmDFhGPvvss0yNZtKOsOFZwdwDxLhCtU2bNmzfvp2QkBD69OnDO++8Q58+fRx2TUXOYVQQf/8NaQajmeLqKaaMFETFihXp378/33//Pb///jtdunSx2Vd4eDiVK1dm9+7dpqknV6BsEDlEbg33bS8dO3Zk3rx5Js+Ka9eucefOHVq0aMGvv/5KfHw89+/fT7cgCKBOnTpcvnzZ9N3u379PSkqKTbmaNGnCihUrAFi8eDEtWrSwKd/ly5cpV64cw4YNY+DAgabvrsh7GB/ulStnvW1umGLKiOnTpzN9+nSeeuqpTPsqWbIk1atXJyIiwjQ1tW7dOofJai/5egSRmzAP920wGPDw8GD27NkUKFCAwYMHm96yP/nkEyA13Le3tzf79u2z8IBasGABr776KoUKFcLDw8Mi3PfYsWOpW7cuBoOBmjVr8ttvv9GmTRumT59O/fr1ee+993j22WezLP9TTz3Ff//9R5MmTQBN6fz88880atSI7t27U69ePapVq2b1Qe7p6cnSpUsZOXIk8fHxeHt7s3Xr1nRymTNz5kwGDx7Mxx9/TNmyZfnxxx9tyrdlyxa++OILPDw8KFKkCIsXL87yd1TkDowPdxvPWpsIkfNTTMYXNlsKomjRorzxxht29+nj48O9e/dMSYJyMkifCXtCvubWjwr3rXAl6rfmHL77TgvZHRr6YO0LFJAyTSRtp5OcnCwBOXnyZIf12blzZxkUFCTHjx8v3dzcZFJSksP6RoX7VigUeZHsjiDc3bXsczmJcRW1rRFEVjGOIC5evEjlypVz3EANygahUChyGUYF8aB+DZ6elpFgcwLjgjZnKIjQ0FAqVKjgsH6zQr5UENKVweAVDwXqN+Y8jLf2QZ+1np6wZ4/1tKTOwhkjiAIFCnD37l2OHj2Kj4+Pw/rNCvlOQXh5eREeHq7+gRVOQ0pJeHi4Ke6OwrFkd4opMhL27gV9bVmOYFQQBQoUcFifW7ZsAbRV1PasHXIGLvFiEkKMAYYCAvhBSvmVEKIksByoBlwCnpdS2l56aIVKlSpx7do1i1jqCoWj8fLysrpiVpF9sqsgjJFp9ACoOYIzppgWLFhAw4YNAfsWlzqDHFcQQgh/NOXQCEgENgghQvSyLVLKaUKIccA44O2s9u/h4UH16tUdKbJCochBsqsgjFStmn1Z7OWnn34CcOj6m+DgYHx9fblz5w5FihRxWL9ZwRVTTI8Be6SUsVLKZGAH0B14Blio11kIdHOBbAqFwsU4SkHowVFzhB07dgBw4MABh/ZrXP+UlUjQjsQVCuI40EIIUUoIUQh4CqgMlJVShgLo2zLWGgshhgkhDgghDqhpJIUi/+EoBWGWTsHprFq1CsAUZdlReHh4AI61bWSFHFcQUspTwCfAn8AG4Ahgt9eylHKOlDJYShlcOrMEtQqFIs+RXTdXIzk5gjCybNkyh/ZnXPvgijUQ4CIvJinlPCllkJSyBXAXOAvcEkKUB9C3t10hm0KhcC3ZdXNdvlzb5tQIwjy0vKMD6xmN3g+VghBClNG3VYAewFJgLTBArzIA+M0VsikUCteS3Smm55+Hp5/OuRHE+PHjnda3qxWEq4L1rRJClAKSgFFSygghxDRghRBiMHAFeM5FsikUChfiCBtE4cI5M4JISUnhiy++ALQQ/I7GGCb/oVIQUsrmVsrCgbYuEEehUOQiHGGDKFIkZ0YQ8+fPN+0vWbLE4f0bRxAPjZFaoVAoMiIxESZN0vazqyBu3oQzZxwjV0YMGzYM0IzTjRo1cnj/rh5BKAWhUChyDVu3OqYfY5bO2rXh0iXYvdsx/ZqTaFyyDTjLozLXKwghRFkhxDwhxHr92E+3EygUCoVDOXfOMf2UKpW6X706NGsGp07B8OGgR8XINrdvpzpaVqlSxTGdpsHVRmp7RhALgI2AMd7sGWCsswRSKBQPLxs3OqYfX9/0Zd26wZw5cPZs9vq+desWnp6eVDbLieosBeHt7Q04NsZTVrDnqr5SyhWAAUAPj+EgHaxQKBQaBgOcP++YvqwtR4iP17aenqlle/bsQQjBlStX7O57y5YtFtNL27Ztc1ooDKNd4969e07pPzPsURAxukuqBBBCNAEinSqVQqF46HjrLW0aSAh4gLTpFgQGpi8z6gCjlxTAp5/OBmDz5s129z3JaEUH2rZtS6tWrR5ERLswBumLjY112jVsYY+CeA1tEVsNIcRu4CfgZadKpVAoHjq+/lrbdu8Ov/ySvb5KlYIePayfe/117VpCwOrV2iPQYK41bHD37l3O6K5RM2bMYN26ddkTNBOMU0zmq7VzkkwVhJTyINASeBwYDtSRUh51tmAKheLhwmg8dlQ+6YoVrZf/9huMNVlRNS+hESNGWEwbpSUpKYk///yTESNGAFpQvtGjRzs9ymqhQoWAXKwghBCjgCJSyhNSyuNAESHES84XTaFQPAz884/mXWSMwVSihGP6NdocrJE6BaUpiJSUFDZs2JBh/Q8++IAOHTrw+++/A9hUJo6kqp7UokwZq8GtnY49U0xDpZQmC4me5W2o80RSKBQPE48/rnkXGZk+PYsdREdDp05w4oRF8dtvQ6NGEBaW3midmimgtanM1mrladOmAamZ45o3TxcMwin07NmTlStX8sYbb+TI9dJij4JwEyJ1TaMQogDgmuwVCoUiXzN0KGR5zdm2bbBhA4wZY1Fco4aWm9rXF4oVs2xy/bpxr49Z2XVeeeUVkxKwRoUKmrf/rFmzsijkgyGEoGfPnrk6FtNGtCB6s9E8mUag5XFQKBQKh/JA+XauXdO2xjkqKxQunHk3w4cPB6Bfv36mXNBpuXLlCpUrVzYpCkfx0a6PKOxRmDFNxmReOQexZwTxNrAVGAmMArYAbzlTKIVC8fBg/qwtX/4BOti+XdtGZux9n9V1ZklJSdy6dStduZSSosY4Hg4iLCaM97a+x9iNuW/9sT1eTAYp5XdSymellD2llN9LKdVCOYVC4RCiolL3szyC+P57WLFC2//vP22Rw5075kYGwLqCaNNGm5Xas2ePRbnBYGD06NGUK1eOuLg4pJQWK5kdrSBWnVpl2o9Ncs16h4zIUEEIIVbo22NCiKNpPzknokKhyK8kJ1sqiFq1stjB1KnadsoULQHEkSOaESPNUMSagmjSBL76Kr2HUGxsLGvXrgVg5cqVJCYmWqyTcKSCeGPTG4wMGWk6Phl20mF9OwJbIwjjZFgXoKuVj0KhUDwwBgMYk7ENGAAjR4KfXxY6SEmBGzfg3XfhOT2/2Lffpp4zo3dvbduzJ+jPftq107Zp04TGxsZSvHhxAPr370+UuQYDCttj0LCTz//5HICAsgEAHLt1zGF9O4IMFYSUMlT3WJonpbyc9pODMioUinzI5s3wySfafqtWMGtWFmwF//0HH32kKYKqVVMXT8ybZ7X62LHaSGXlSujaVVsj0Vr3cC1UqBANGjQw1e3SpQvVqlUzHd+4ccOir4SEBKvX+OfqP4hJglNhp+z6CtLMqN79/7rj7e7Nsdv2KYiTYSdJMTh/pt/mn0O3NcQKIYo7XRKFQvFQYXQ+AqhXL4uNn30WPvhA269fH4rbfkQJoSURMmIesA9ItyJ6o1lY2TfffNPi3AfG66Zh43mtzfxD862eT8uOyzsA8C/jz1tPvIVfaT+O3T5GdGI0fX/tm6GiOX/3PHVm1eHrvV/bdZ3sYI++jgeO6TkhvjF+nC2YQqHI31y4kLpvLbheOsLC4IsvtGBN5ovigoMhbciLLIbf9kyrMXTc3d3ZtGkTkJoUqGnTplbrli2sTVXdjbub4XUSUxLZeXknKYYUvvjnCwp7FGbXoF0U8ihEQNkAjt06xud/f86SY0uYfWC21T5eXq+FwmtWpZl9Xy4b2KMgQoD3gZ3Av2YfhUKheGCuXtW2U6daSS/63nupuUeNfPSRFmlvzZrUsv79Uxubx+jIYlagpKQkq+Uffvihaf/MmTNcMx/2pCHZoAWRuhN3h91XduP3rR9ikuDYrWNExmsuuN/t/46WC1pS9OOi/H7md0Y3Go2Plw8AdcvU5VbMLWbsm6F9BSvOovuu72P9ufVULV6VRhUdn+I0LTYXygkh6gMxwAkppX0TawqFQmEH0dFQp45mY07HRx9p28GDteXQgwenrnMoXx4++wzatgVzD6TQUM0tadUquHgxS7LExMRYLW/btq1p38fHBx8fnwz7SEjRbBNrT69l7em1pvKA2ZoB+oMWH/BvqPZuHZccR3CFYD5u+7Gp3v/5/h8A4XHhAFy6d8mi/+/2f8dL67QweH8P/tuu75VdbLm5fgAsB3oCIUIIFX9JoVA4jJgYO1Y4V66s2RuMymHLFrh8GV58UQuwZD708PTUAjA9/jhkMZje3bvatJBxNbURo4eTPTmnE5Itjdflilgu6pi8czIhZ0NMxx+3/RizKEZUKGq5OjvkbAirTmprJM7fPW9SDpWKVUpX11nYmmLqBQRKKV8AGgLDckQihULxUBAdbWk4tkDPg2Digw/g9m1tdZuHh+2OPT0hA0+jjLhz5w6gBcczp1KlSgwaNIiQkBBrzSwwjiA29t3IL8/9Qujroax6fhXNqzTnx2d+TFe/Tuk6ltcqVgkAHy8fRjTQwoo/+8uzxCbFUnNGTQD6BvTl/CsOSrtnB7ammOKllLEAUspwIYRrkqIqFIp8SUwMlCyZwUnj0GLWLG2RRDojhQ0KFtQUxJ492mo4O/D392ffvn0WMZi8vb1xc3Nj/nz7vJISkhPwLOBJhxodTGU9HutBj8e0zEVtqrfhqz1f8ZjvY3R+tDPli1ou5itVqBQb+mygVqlaeLl7cfT2Uf6++jeLjiwCoGXVlvz4zI+4u+Vc4D5bV6ohhDBOpIk0x0gpn3aqZAqFIl9jc4opIUFLEjFwYNY7Nq50btpUG6bYsbBt5cqVhIaG4uPjww8//MCwYcM4n8UE2ctPLDeNIqxRpXgVvuj4hc0+OtbsaNoPeTGEEp+UYESINpqY2mZqjioHsK0gnklz/JkzBVE4lmnTYMECbT2RQpEbSUhIvx7BvpOZYG64PngQ7MjdULlyZSpXrgzAkCFDGDJkiN2XM0gD3+3/jsuRjl0/7OPlg19pP1P4Db/SWVlm7hgyVBBSyh3OuqgQ4lVgCFr48GPAIKA8sAwoCRwE+kkpcyZtUz7knXe0bXi4lp9XochtJCVlYE5YtUozMj9oOk/zTtes0RRETAwUKqS5vxYokLUpKxucDT/LozMfNR1PbjXZIf0amdpmKt2XdwcwucPmJDluVxBCVAReAYKllP5AAaA38AnwpZSyFhABDM5p2fIjxhA1CkVuw6qC2LlT81oC2LfvwTp+7jn48ktt/4svNF/aIkWgc2ftgiP14HgREWAw8Pnfn7PixIosXWLqzqmIScJCOSztuZT3W77/YDJnQCnv1Lc74SCllhVck6ZIu663ECIJKASEAm2AF/XzC4GJwHcukS4f8a9a0qjIpVgoiL17tbf6li1TKxgVRVYpWFALvvTqq9rxST1C6vr12vb777VpqE8/ZXvLqrzx+BkA2j/SnhLeGSfE3nZxG2WLlGX4H8P568pfFue2D9hOy2otM2j54ASVD3J4n1khxxWElPK6EOIz4AoQB2xCW5l9T0qZrFe7BlS01l4IMQzd5bZKFpfTP4w88oirJVAorGNSEAcOpPc2SkqC7KbZ3LdPS0ptDX2F9ELvM6aiWjNq0eXRLjSv0pzBQZYTGIdvHqbNT20sypb2XEo1n2o0qWSfp9SDULhgYT5p90m6NRY5RaZ/ASHE72i2AnMigQPA91LK+KxcUAhRAs0AXh24B/wCdLJS1Wr+QCnlHGAOQHBwcMY5Bh9yWrXSEm1VrarF3HfgtKtC4RCSksD/cgj0esXyREpK1lPAWaNhQ7h7V9NCBQtaNXq/c6gwpStVZHrpM4THhbPwyEIWHlnI/+r/j4Y/NCQ0OpTtA7bzx5k/LNot6r6I3v69sy+jHbz1hOsSeNqjoi8ApYGl+nEv4BbwKPAD0C+L12wHXJRShgEIIX4FHgd8hBDu+iiiEnDDRh+KTIjVE1NFR2v/H2++CZ9+6lqZFAojUoJbUjwDV3bRCh59FIYOhbp1HaMcjJjHZzpwQDN+Fy+urcxOSODRVq34FIhdN5pv939rqtpgTgMO3TykiWZmZzDS/pH2jpMxFyOkjUTfAEKInVLKFtbKhBAnpJR1MmqbQX+Ngfloq7PjgAVoo5EWwCop5TIhxGzgqJRylq2+goOD5YEDB7Jy+YeGgAA4ZhZa3rh2SKFwJgYD/P03NMsk0GhyMgR4nOQk+uPjyBHtR+sitl/aTuuFrdOVv9vsXT7/53MSUhKY02UOxTyL0bBiQx4pkbfnboUQ/0opgzOrZ4+qLi2EME326/u++mGW3VCllHuBlWiurMd0GeYAbwOvCSHOAaUA65k/FHYRFwed+YPCRAPaS1Mm7wIKRbb59FPNq3RHJk7ySUngwz3tYMMGlyoHgOKeWj6JMoXLMKX1FFP5u83f5eDwg8zpMochQUPo5d8rzyuHrGDPFNPrwF9CiPNoK6qrAy8JIQqjeRtlGSnlBGBCmuILgPPj1z4kFIu6zh96ZliBJCwMFi3SoiMrFM7iL92558wZTVFkNFtkoSBsREjNKWr71uaJyk/waftPaVihIUmGJHo81oPCBQvjV9rPJYvUcgOZKggp5TohRC3g/9AUxH9mhumvnCmc4sEpFHvHtF+ZK1yjEgMGuDFgAFy/DhVyJhik4iEjNFTbDhum2ZpHjLBeL7cpiEIehfjrf6muqxNbTXSdMLkIe61BDYA6QADwvBBCvYfmAkJDNc+k5ctTy06d0gJfFooJM5UtYCBhlMaHCEALw6FQOIPQUChGJN7Ecvy45bnoaJgxQ1MOuU1BKKxjj5vrIqAGcBgwpjiSwE9OlEthB8Y4S999B716aQZCP30k3IvUEUQbtgHQkh38TlcSEwvktKiKh4AdOzQFIfHhHDVYI7YAVUlI0EK+VNRXNrm7Q6dOUEJ/YVEKIvdijw0iGPCTmbk7KXIcT08oTDTe0XFAaVOa3rLcpBHpwxSsQYvpsvH7Dpx+dSO1a+egsIp8z3vvQTdWA1CT87w4synrOt3gk0+0CBoAXsQRfl0QE+OFD/dILuiN+4MG5VM4HXummI4D5TKtpchxhIBD1Gf9v1r0ytWroQ+LuUl5XuPLDNt1ZBP9srp6RfHQMnOmfV5wN28YWE0P03EFQvlt4K/s2xnHWrqyh8bEUYjh3/gRHa1NMSUXUaOH3Iw9CsIXOCmE2CiEWGv8OFswReYkJEAtzmkHUVFMmACD03oH79+P7PQUW7AMExByXIUpUdjHyy9D4/ubmPnBbZYssV7n5k0oc3Gv6fhdpgLwfVhPerKKrvxBY31UWzrqIl9MjsaHe6QUVQoiN2PPFNNEZwuheDDizYOcfPIJBXmf1mzn7qNNKHlmDymVqlAgOBixLoT/xCjastVUvXTcVc1o4chVq4p8h8GgGZ030ZFjU/zZSEd4dmq6sBVz5sBzrMDgURC3sNu0bvEhHNXOBRh3zPh83f9Rievg2BQKCgeT6dNBSrnD2icnhFPY5vx5uI2WTD05RdCWLQD4eMfD4cMU2LHNVPeOcW3j6tXs8Gir7cdnKYyW4iEkOhpe5GcA6nKcN/gc/vwzXb0b1yXPu63E7cmOULw47deMIt5NyytdhxOmeqc3XSYJd005KHI9GSoIIcRf+jZKCHHf7BMlhLifcyIqMuLt0dGUQXNnjTxxDW+hxdJw+/wzqFfPIpTrHPdR/NhqATz9NFsLaQvoDDFxOS6zIm8RGQmPcsay0ErUx7gbEVQ0XNOiRAJUr84Thl0AdGadqV7t9lUYWWBOasOqVR0tssKB2Moo10zfFs05cRT28tFHMJfUtIjxpy9RyuO+FvzESozv60llgAEAhEZqb3YHe31C8FYVwU9hnf79JBW87lKX25YnIiLS1U28rK+QM1uBeYY0Qe5mzwbgaIpZ+LZDhxwiq8I5ZDrFJISoIYTw1PdbCSFeEUIoy5KL+fK9MHqTukKu4pntNEj8WzsoVsxm2zg0BRG8bTopSQanyajI2xgWL2HaXF/66FNMUYX0XM/WFMRZ3ZhQMTWNy3eLUt8t45q2geHDAWjzsj/HqYP86mvLaKuKXIc9FspVQIoQoiZaAL3qoP9iFC6jUZVbpv03mA7AcPShe1Hbgz5PUsO67hk6j127tCyMv7X6guTtf9loqXhYSEiAqmYW5LgWHfjypXOpJ81ITIT/i9dHAoGBpvI+fSBkyiHOfLgc7+3rTeXTvimEX8pxxJg0eSAUuQ57vJgMUspkIUR34Csp5QwhhBoXupgqRfW3uJUrKXu0I0x+M/VkJsneTSEOgCcWDqPvQm8WG9N6tEaFfVVw/z4UJsZ07DViEAVOavlBDQlJFm+WMTHaquikgoXwMHs5EQI6vxcIBJIW5TyXN7Dnz5QkhHgBbQLbmFYpbapxRQ4iJSTe0hVE1aoULFkkS+0bzRvB+sBx/Ek7gFTloFDoREZqCiKxUHFISUG80JsCntr7ZEpiskXdmBgoQjRJnln7HSpyP/YoiEFAU2CqlPKiEKI6sNi5Yilsce0alLxzWjuoWJFHHoGRzGItXVk+bEum7Z//XxE6HfqYKYy3en5/948cKa4iDxIToymIFK/Cptd9d08thpchPild3SJEk+KtFER+w55w3yeFEG8Ajwoh/IHTUkoVD9SF7NwJ9ThCXNmqeJcvT5cukLJ6JGHhI7OU7yEK67aKhmveg6iXM7VlKPIv8fGagjB4FTaVeRQUJOGOIc0IIjpar1tIKYj8hj3RXFuhJQa6hJYPorIQYoCUcqdzRVNkxL598Aw3KFBF8xgRArp1y3o/X/9ZBzJKrRsVpRTEQ8ry5bDms3O8SDQGbzMF4QFJeCATkrh/P9VZ7v59KEoUFC6cQY+KvIo9U0yfAx2klC313NQdwUYkOIXTSY5NpL44TMEa2Yun1LydJx3qZLCiNTo6W30r8i6Tep9k6YFadOUPZKH0CmLP7mQKFC9M9DN9+HOT5I+eP/I4f+NWxtdGr4q8iD0KwkNKedp4IKU8gzJSuxSPqLuUkBHw+OPZ7iva6NsOVOIqR9ByA1/7QzmqPYwkJsJjnDIdF0hKXW3v4aG5SLc9+hWFiaXI2p+ZMewYn0f8j0LEUbCqSlOY37BHQRwQQszTF8m1EkL8APzrbMEUNkhM1LaFCmW7K3ev1FnG09GVGMPXAFR6vTeGmd9mu39F3mLEcMkqnjUdF0i0VBBeWK6BqMxV075ncF3nC6jIUexRECOBE8ArwBjgJJBBpllFTiATdAWRyXoHe3juOWjOTq5sOUvhwlCsQ1Mi0BbKx34zL139HTs0LypF/uT8nxcsjt1SUj2WClhJRPjt5S4A3Os1HF56yamyKXIee6K5Jkgpv5BS9pBSdpdSfimlTMisncJ5yET9n9YBCmL0aFhzpzlV2tQEYM16TwZ0CmM2wyl07gjcvWuqazBA/1aXmVf3q2xfV5E7qeWljQh+5gUA3GRqKBZbLwY+n7xjNYifIm9jK5rrMSHE0Yw+OSmkIg2JjhtBCAGlSqUeu7nB2nXuHAoYiJs0cGjy7/w3dRVIyc2bsI3WTLj3qtV4PIq8S0oKvNg+jHbntYB6/3V9i3V0Iumr1GnGQYMs27yD2XqZ4sVzQkxFDmPLzbVLjkmhyBpGBeHhPF+BQi0bknTUnfpfD9QKGqwn5OqTDOWidpycnGFbRd7j8GHosPlNerOc5EJFmfBrPaJj1uFt9tw3f5G4Evg0CaFVwRgSTLlE50tsTTF5AJWklJfNP0AV7IvhpHASMslxU0wZ4Ve3ANdJjcx56OdTTBlmlv7LqKQUeR4pIThYMpCFABRYuYIC7sL6oGDkSJgyhSqHfiPG4J1abs1Aocjz2FIQXwFRVsrj9HMKFyEcOMWUEdWqwU3KmY7rL3qNy1RLrZCUlK6NIm8SEQE9WQWAHDUa0enJjCvPmgXvvQfA/eTse9Epcje2FEQ1KWU6W4OU8gCYPykUOYnBAP8dc/4UU/HiEImNeWU1gsg33LgBDdkPgPjY/jhcEfHemVdS5GlsKQgvG+ce+JchhKgthDhs9rkvhBgrhCgphPhTCHFW36pMIlb4/nuowA3twIkjiOLFIRYbb4hKQeQbrl6FIA4SVbtBlmwJUXHatFKSb7lMairyKrYUxH4hxNC0hUKIwWRjoZyU8rSUMlBKGQg0AGKB1cA4YIuUshawRT/OVSQmWnh9uoQbN2ABujuJE0cQxYpBd9akK99eQg/6pBREvmHvHkkQB/FsEpSldufQXKPFnDmZ1FTkVWwpiLHAICHEdiHE5/pnBzAEbcGcI2gLnNeN38+AbiXTtg8Qfs65jBsHj5S6xwtNLlK1Kqxbk/MPSQtbYM2aTrtOiRKwih4WZYkBwWwp+6J+oBSEvVy/ruVXyI0sXw5bJ++iFHcpmEUF8ce+svy+VuLevauTpFO4mgy9kaSUt4DHhRCtAX+9OERKudWB1+8NLNX3y0opQ/VrhwohylhrIIQYBgwDqFIle8Hqssrhv6K5RwnYC6f4Px7r/p8e69g5USynT4cLi/9mxm9VcK9WCYDbN5IxIHB7ZxwUcV54ZS8vaH51KQbPKMIv3sc37ioFW7Ygrr6eb0IpCLtISIDBlTbwO13h3p1ct15g3jzYSUvtoEGDLLVt2NAJAilyFfbkg9gGbEu2g5IAACAASURBVHP0hYUQBYGngXey0k5KOQe05MvBwcE5mhuzuluqm+dj/KftXLgAdZ0Tg+attySSJ7Qs4Hoa0LgrYbghoXJlp1zTnDKVCgKlKF26FJoQII12D+XFlCnbtsHQNufYSx88SIYTJxwSYNGRXNtrFs03KGsjCEX+x5WZYTsBB/WRCsAtIUR5AH1722WSZYQ1A8SVK9nuNjExfRiDlBR4kg0W105JgesHb2rH5VxjGHTz1BVEXJztig8ZP/4I06ZZpvPetw/OUYtSuNhwlQGJidDk/kbt4OhRtZZBkQ5XKogXSJ1eAliLlvcafftbjktkhYgIuHdPWzgcezU8fYUoa0tFssaQIdqAIMEswtWKFZpniYn4eC5cgAZhutKo4JrQyociHwHgzKK9Lrl+bmTdOhjzv/v4vjOEUW6zeFaspEQJzWZlQS5bfb5mDdTiLClu7uDvn3kDxUOHSxSEEKIQWi6zX82KpwHthRBn9XO5Iq2pn59msD1+HMrHX0hfQU+sI7Mx2bViuWQDHYlZvJqDB6FWLZj/QwpTzXNGx8dz9iwEcpgU78IQHPzgF8wGg94qzTH8qb7yU2WH0JkyBe5TnCHMYxajWMlzRNwTxONpUS82LAYhtHn/tWvh5k3nyxYbCxMnWr58APz1F/TqJSlBBImFS6hAewqruERBSCljpZSlpJSRZmXhUsq2Uspa+jZXjMsjb8Yyng8Z0TOMrvxOQtVaHC3TznReRscQGak91L/9NMai7YkT8Npr2izU9QwStwEUkVF0ZBMlh/SgVYP7dD/3KdW3WYbaDr2UwIEDUJ2LJDR4wmXTAX36wOpiA/EwJEJYmEtkyG0kR8dbLffEUoHufOUXHuMkl4dMpvczsYx48qLTZfvmG1gz6TBL3z9pUX7jBnzPcEbwPd5R6u+oyAApZZ79NGjQQDqTxYulHMh8KUFuoIOUIA1vvCllYqLs/8w9KbWBgxw/Xsq3mCYTcZeG/QdM7Xv1krIvP8nnWSZ78otc8PU9q9epxWlTX8fxM+1LkEtLvywlyHZskmt4WkqQCb36OfV7Z8bzLJMSZMTzw1wqR27g3Dkp/Tma+jcbNkzu7DzN4m94vvX/pAT5J21NZfsIlhLk8EI/ybhYg93Xi46W8p13pHzlFSn37Mm8/vDhMlUWMz77TMpLVLF6TpH/AQ5IO56xLn/IZ+fjTAURFSVlraoJFv/oEqQ8oCmAxYsMprLCRJn2I8eMN/XxQo/49O1TUiyuk5Qk5bMlt6Svp39mVJ0uJcjNtDGVGZo3d9r3tocn2JWq0Cb+4lJZXM22bVLuoLl2Pw4dktJgkIYUg7zeqJtW9vvvcscOmeHf1/iJC42w63qffSblUL6Xx/GTBz0aaj8gG2D8N0+jBF552SDvUUzGVKktDes3PNiXV+RZ7FUQrjRS51pCQrSIA6UuW1kwrvuK9+mbOmc7zsxcEv93ai7nlLNWbBahoabdrVvB2yOJ3nczTu15tbhmPGxL6vIT4WIH9G/+bWbarzPxORdK4lpSUjRX1vLof9M6dUAIhJugwt7V2mO5Sxf8/OAEfjb78ipvX2SZxESYw3DqcJL6Sfvh/PkM6xoM0JbNpuNL55KZ03IJMZt2E37+HsW5T6GxwxFPdrTr2oqHD6UgrLB2LcxkFP/wOEkFzAyN06db1Huvwo8AtGErCYV8WEwf3E8cJijQwKp59/C4cFqruH0737bV7PHy0GFT+9Edz5JEQXrqtvqD5TpZCnLuHCneZovhfvhBM2ZMc639vm5d+JN2mVfUCQuDQ4cyr5fXmDcPNk/eTTUukdi1Z4ahT3x94Xu/b9KV3/B+xLLg6lWLw3PnoEcPWPbpFc6dSmL7NkmMpZkLLl3KUL64OGhnpiB+nRfBsJ19KdyxGUlndPtHtWoZtlcolIKwQmK8gVHMAiClbAU2TtnP/YlfwOuvW9RL1oOUPc4/JPvX52Lx+pSMvc7BIwXoOaQET8RsRArx/+2deXxU1fXAvyf7vhIgrCH8AMVWgR8otqgoFEQRcMG1CgpabRXFohat4tJfRa3YWqtURVuVRZS1WhekuLWCgorKTkEBwxIQSCALWe7vj/sySzIJGUhmyZzv5zOfee/e+947d97MO3POvfcc6NWLuFHncZgk9s/6J2BnlQypfNN1LnPHnfTZtojigmIKXnoPioqga1ckwUNB9etnp7c2YwymxhAbC//z5TwWMpJqifJaNLdkCXTuDOfLm3wxeS4AZ5wBfftUYaoDuq6x2fnkvcP8mwHEUklsXvsG2369r+605Na/vcG7oKjIa/fySyr5+4JULr+rMxt6jmLgOVFs/r853sc4s+h8UVoKCbgH0F+butm1ff3mO+1GM4ZrUcIfVRA+KP12t2s7ZuAAht7Tl7QpE+tMBcwa4p5qmnDWaezr1Nur/iamUzXgLEhP59yR8bzHYKLffYutW2HpUjsjqSIhBSorkUemQmwsqbkptLt6kCuqZlSKR0TVIC2O80WXU9L4IGW4zVlcUOAqHzIEWm1bxZsMp/fUy2DfPgo2FFFFDOVTnwiixE3HjBkwfz6se+1rV5nkNnxvpsw+gY/ajmZ9N3fcophJE3mD892NyrxnQ+1evZNUrAI4H/vHYhY2FtayHjfaRkdREIm4FzR+gnsV92CckClduzYotxLZRLSCKC/3GhLg/fehfXso32RXR1dPfYSYZ56q9/iJ/9eKZaOfpurU04me8lsSB9SNZRNz5WUAdOgAX8T1J33fVk7NL+Sa8/dyOp8QdWIPO2W1nnnoFYlp7p1WrfzvZDNSnOGE+/BwjaRSxCrcivPA2FtpxV4AzMMPB1S+pqasDK68wtBj/AAuulhYzunuyqPEMRp4tnDGzrn84/rF7sK4OB7HwyqttVihQ8xuahOFtcJiaozIOj4nNzUKYl9aHj9QzxhHkib9UeonohXE2LHQo10RFeXVANx5J3xY0JXndtp/dVHDzrVxr+shLg7OnnsT0Sv+A8nJ3P9EOnNP/h3ruo9wN7rMKggRKMqx/9Y+pw97yeFUPiN6zNUNynjQeFw/xEIhHMp0FMQZZ7BUBlHy5jLO4gOvNhlvzKSt2KgpiYf28vAdIbG8xW+qqqB/4mr+OieNAfzbu/LwYWs6NYLa8RXfPHw2t/ZyPrNaFkTnhLoKooaCLnaiwP61O+ttU1ZmFURsSgL38hAA5oZf8MM+wweXP0PlszPqPVZRIMIVxKI5JRSRzsFfTebQIagoKqUrW2iFE1LDz4B48fFw6ep7OHHDIhuC48gRuwzboTo7x54Wj8BLR5mRtO2H5ovYerwUJrqj6Q7iXyQNPwdx/uEWJ7mD8f4Ytytm8h+yYXf9D75QZcMGeI7xLpePi4UL/foXPm4cTJtUQOlmu3IyKQniUp1xJkdBPPQQ3PKjZXQ4tM7nOUxODlv6X0kJiaQ+PbVeN1ONBWESE7l9401sfHQhMu1xsrLgrNk3EnP9dY2WW4lMIlZBGAMnsQaAVjMe5ZzUT/liQ60fekbGsV8gJaXOYLJk+jhf9+4Nnuauu63VUHVS80SMPR5unJTC1lrZZ8dHvQBA6tefcHenVwC439znfeDnnxNuLFsGR7CBCo88OJX37/sX5tPPYORIv84TFwe3P5ZLYlf3oLUkOskby8ooKYEP71vCn9ecwx+4w+vY5eOeZW23EciyZdx8i3AdLxBjKvlX1+vrxHpZv95Oo06gDElKpGu3KLrfMbLZQtMrLZOIVRCrVsHJuFNuf8ppdRs1cXya6FYefuDFi63P+SjjCoMHA1u2EL38P00qS1MwejTce5V3uIgR1YvszK02bThyxiAAcqkVdGhn/W6RUOXmmw0nsQZz403E3XsXAx84G+nXNPGwopLcCmLRIriWF322639pZ3puXAQnnURqKlz3tnVfnrNnDkdeeNmr7Yknwt13Q1t2Edc2q0nkVCKPyFQQM2bQY2QPRrC4TlVx9z5smbYQtjZ9nJzMHh45kDIyGp9TukuXZk0OdDw8+CC8njeJ5Vf8yVVW2qYLJCdTlt7GVVZFFKU1ac5DOFR4RUXdVBdHjkAntpHBQeSUk5v8mvE5dpypas8+Zj5TxIUscNVtPeMad8PsbK/j+p3q/gMTN34MR274lSuAYg57WMcJ/Ig1xPc7pcllViKDyFQQhw+TWrCR//WRWjt1wyryJ45slgVEE+9JYnHcxXbneNxXIUR+Plyy9TH6z5rANU7G2MQO9kGW09r9APvHgiruGeeMPZT5Dm4XCowaBWNz37Fx3h0KCuAnOBbcCSc0+TXTurdlN6356MkvuOejoSRSxsGZb7D8b+vZ/eBf3Q1ruSMzM2Fy+5dc+3HPPW3DAACjeY0TsAs1pZcqCOXYiEwF4cxM6oB3iNWKocOb9bJJSTCiaKYd2GyB8fd3YdcCSDe7+OqOO2DuZfOoWPgmo0ZBZq61IExJ6FoQ2/75NTP3ncv7WRfy7ZJNgM0TNdtZf0CHDk1+zQ4dhS3kM3Dri5zOcgDST+5M/zE9aJuXwHie46He811rYzy55dOr2YbHZApn2mvNeAkAw2qt0FeURhLRCgJge3Rn13bsW3VdTk1OfLwd2GyB8ffTR53DY4n32RjTWIV46ZyLiB15HgCxSbFUEUXV4dCyIPbuhQkjv+P5yf/lJp4BYCAf0Pa83pSXGaqqPBq3b3jF9LHQsSPsoJbiyc0FrCE7aNZ4frnkQp/HtmsHa99yZzWsmLug9nh1yLonldDnqDmpWyQeCmJB6hgmHHjQ7rTAh3YgeW1BDPBAvfUJiUIZCcQcKg2pL96JHYopLM+j9pBUQuVhOiVuZ8AluVzHIE7rtJPUxMQmv36HDrDCQ0FUzppLjMd4wxVXNHy859BE7D/mU7y3jEysi6xi/X8JbmAWJZyJSAviP9+7rYahSyYx+8lCG/pSaVYSEqCUxJCyIIyBp8vrXw/wItcy/fVsEimlMrV5ZgPl5sI+nKf8I48Qc4V/EXJTU+EdPBbq3XorueykIj6Z2O5dmlBSJdIIpT9yAWNrTDceYz7Tp5XSo28qPfrW9e0qTU9iIhwihfgDRUdv3MxUVsKmTdb70peVXnWvpV6HFB/kEua5wqx3YAfE5Ps61XETG2sVUSb7+fWNN/p9fI8eMP/+N2hzfz96sZrU2c8yESjO6kasWsXKcRCRFsRVV8G8qgtpM/HKYIsSUWRnQwHtqP4++OsgZs2CJ3o+y1edzqcL33rVjf5mCh/3nuBVlkZRs4Y6+eeX7bl8x+MNhnapDxG4e0os1/CSV3lMfGiFZlHCj4i0IACiIlI1BpecHNhGe3pvXW5degG+CTt3wrp10KkT3Ptbw3f8wlVXkZNLbKGjuLKzOVixx+vYTA6wvxkVxClNMBN10ZaTeTf/ZwxhiS2Y1jKi5yrBQx+TSsDo2BE+5EwS9+7wChEeKE47DZ4aNJ97rtzK19vTveqq1m3iYl7n3ylDISmJT7/xMRgdE9r/p/LyIMWJFVU0+WESLzw3uAIpYY8qCCVgtGsHZDuhRRoIU91UvP22zd1QQ8n2vcznYl79LJ80il3l5b+YQEJ2MtcsvJi89W/XP5stJrRdNiIwGzvlKW3C2OAKo7QIVEEoAcUkOcHiGkh001QMGwbjx7snqGVwwKv+3mEr+V3e88Q//nvALk+pWeaQ0OtElnKO9wlDLNy6Lwa+djOrPykJqeRSSvgS2jaz0uJwKYgAWBBJHOYVfs7SlCoGffciWXjnonhowY8g3neinw8/jqK4eCnzPjZcPNr+j4or/N5n21Di4ksEaPq1GkpkogpCCSgm2VnVGwALoi8ruZCFUAqlv76bVrhDc5clZpAQH1/vscnJ9pWa5nY3RZeVNKu8ihJqqItJCSiS0rAF8fjjcJv8kR3D/V8PUBtPi6H4/ZXcwp9d+wmlB3wd0iDRxfuP3khRWhBBsSBEJAN4HvgRYIDrgA3Aq0Ae8C1wqTFGf5EtjOhkd+6DfYXVpMaUEpfpTmIzdVIhhUyEN4GDj0B6uu8TNYI2uKeqtt7+OcOACmKIpbLR5/BMEx19KPgL/BQlkATLgvgT8LYx5gTgFGAd8BtgqTGmG7DU2VdaGHEpNsroof1HmNn6NuKyUuyyZoer2r3vbnyc4xQZ0cV1yipa5bLzjmkwd26jztGrF4zGtpWK8qO0VpSWRcAVhIikAWcCMwCMMUeMMQeAkeAkFLDvowItm9L81ORfTrl1PBNqXD7F9kG+fz9kFKxxN65s/D/92lRXQ2yVDSv+Ele7yqtatSH30Yk2HV4j6NgRlkf9FACpnUlIUVo4wbAg8oFC4EUR+UJEnheRZKCNMWYngPPeuqGTKOFJjYLw4oAdD3j4YbjfMxqsV5zto7NuHcycabfLyiCJEiqj41g7+n5Xm6gs/xM1VcRpHmclMgmGgogB+gDPGGN6A4fxw50kIjeIyEoRWVlYWNhcMirNRHyaDwVx8CDgI22BnxZEz57w85/b7dJSR0HEJTF1bj5jnTzPsVn+xzqqjEvy+xhFaQkEQ0HsAHYYY1Y4+69jFcZuEckFcN73+DrYGPOsMaavMaZvTk5OQARWmo74VB95uL+36ws2fGV9/BvjnWx7fiqIREowCNX3TnFZEFXx9uEejbVGYrP9VxDRCZpRQYlMAq4gjDG7gO0i0sMpGgSsxaZrGeOUjQEWBVo2pflJSvWxGnn4cIpeWcwF8+ztL4yx2dT8dTG1wea8jvrdgxQWwhj+jomxCikNOwNJ0v1XEHFxdvbTwV/d7fexihLOBGuh3C3ATBGJA7YA12KV1VwRGQdsA/zLmqKEBcn1uPOr753C5XwJwJ64Dtbx6KcFUROoDuC529bwFyoo+59uAJx/5iH4kGMKp/3QQxB3bQWHH/X7UEUJa4IyzdUY86XjJjrZGDPKGLPfGLPPGDPIGNPNef/h6GdSwo36FETGt1+6ttcmn2o3/FQQNVYCQJ/1s2zZQ3cCMHjBr+Cyy+D22/06J8DYsTbzXJIORSgRhq6kVgJKdLRdV/AWNhT1y/zcq774pP7sSsizO366mFrHuldHj9ttA/DR2Ukvm5UFc+ZAZuYxya0okYgqCCWgVFfD64xmOG/w9O8PMLjgZaZyl6teZs9yR031w4KoroZu1RvqVnTseLwiK0rEogpCCSjG2PcLRkbzy8npZGfDZKZy3k8OUFZSTcqPu2CinaExPxREURF0qtpStyIhoQmkVpTIRKO5KgFlwABrIEyaZPfj4uw6udTUdFcG0uoo52vph4upuBhSKaacOOI5AkB5ajb1x2tVFOVoqIJQAkrr1nUNgzrx+I7BxVRUZBXERrrzY74BoCKnnSoIRTkO1MWkhB4x/ruYPp6yhItYQCv2chtPALrATVGOF1UQSsjhGoNopIupvBzS5r0AQEb7FFZwGgAx8WogK8rxoApCCT38dDFNf/IIVzAHgKpZrxLj5HuISVAFoSjHgyoIJeQwMY5rqLxx+Rc+unMxAPvy+5FyZh++pBc7aI88/PvmElFRIgJVEErIcSC5vd3Yvt2rfMsWeG/eQSgt5c2X9rGrXR8Q4XUnKsvh1/4JwJJPUnnvxR1w1lkBlVtRWhpqgyshR1l8OkXRGaR9951X+QUXwJq1Np9DHINpyxeuumqETn1aAdC/v30pinJ8qAWhhBzR0fBDdA7s2+dVXrbTnaL8Z7znVedySymK0mSoglBCjuhoOBCVXUdBnJG0qt5jKpJqL6ZQFOV4UQWhhBypqVBosmHJEigpcZV3Td4FwBwuc5WVYkNp7L5yYmCFVJQIQBWEEnLk5cG75c4A8w03uMqjy62yOIyNGV5CIkmU0p0NmLsmB1pMRWnxqIJQQo78fJjBOLszc6Z9f+UVRu2aDsB0bgTgo/Evcc01sInu5OYGQ1JFadmoglBCji5dYD9ZlGPThe6avQyuvpqe5XbW0mpOQTC0m3AJf/sb/PADxGvQJUVpclRBKCFHv372fQx/ByD5yhFe9YOG2hlL3buDiOYAUpTmQtdBKCFHbCzs2gW9254JQKpHrmmAt96WYIilKBGHWhBKSNKmDbTv09a1X6H/ZRQl4KiCUEKWxOQoTmY1B0njIuYHWxxFiThUQSghy+DB8DUnk8FBNvW4INjiKErEoXa7ErJMngwffGDTku7ebd1Mxd37khVswRQlQlAFoYQssbGwdKndHjgQkihh8eNRDAuqVIoSOaiLSQkLunSBSmIpKY8OtiiKEjGoBaGEBdOmQatWNuS3oiiBQRWEEhZkZsJjjwVbCkWJLIKiIETkW6AYqAIqjTF9RSQLeBXIA74FLjXG7K/vHIqiKErzEswxiLONMb2MMX2d/d8AS40x3YClzr6iKIoSJEJpkHokOMF37PuoIMqiKIoS8QRLQRjgXRFZJSI1Af/bGGN2AjjvrX0dKCI3iMhKEVlZWFgYIHEVRVEij2ANUv/UGFMgIq2BJSKyvrEHGmOeBZ4F6Nu3r2kuARVFUSKdoFgQxpgC530PsAA4FdgtIrkAzvueYMimKIqiWAKuIEQkWURSa7aBIcA3wGJgjNNsDLAo0LIpiqIoboLhYmoDLBCRmuvPMsa8LSKfAXNFZBywDRgdBNkURVEUBzEmfN34IlIIfHeMh7cC9jahOMFA+xB8wl1+CP8+hLv8EPg+dDbG5BytUVgriONBRFZ6rMEIS7QPwSfc5Yfw70O4yw+h24dQWgehKIqihBCqIBRFURSfRLKCeDbYAjQB2ofgE+7yQ/j3IdzlhxDtQ8SOQSiKoigNE8kWhKIoitIAqiAURVEUn0SkghCRc0Vkg4hsFpGQDCsuIh1FZJmIrBORNSJyq1OeJSJLRGST857plIuIPOn06SsR6RPcHrgRkWgR+UJE3nD2u4jICqcPr4pInFMe7+xvdurzgim3I1OGiLwuIuude3F6uN0DEZnofIe+EZHZIpIQ6vdARF4QkT0i8o1Hmd+fu4iMcdpvEpExvq4V4D485nyXvhKRBSKS4VE32enDBhEZ6lEevOeVMSaiXkA08F8gH4gDVgM9gy2XDzlzgT7OdiqwEegJPAr8xin/DfCIs30e8BYgQH9gRbD74NGX24FZwBvO/lzgcmd7OnCTs/1LYLqzfTnwagjI/ndgvLMdB2SE0z0A2gNbgUSPz35sqN8D4EygD/CNR5lfnzuQBWxx3jOd7cwg92EIEONsP+LRh57Osyge6OI8o6KD/bwK6pc3SF+804F3PPYnA5ODLVcj5F4E/AzYAOQ6ZbnABmf7r8AVHu1d7YIsdwdsAqhzgDecH/Fejx+J634A7wCnO9sxTjsJouxpzsNVapWHzT1wFMR25yEZ49yDoeFwD7DZJT0frn597sAVwF89yr3aBaMPteouBGY6217PoZr7EOznVSS6mGp+MDXscMpCFsfM7w2soP68GaHarz8CdwLVzn42cMAYU+nse8rp6oNTf9BpHyzygULgRcdF9rwTYDJs7oEx5nvgD9j4Zjuxn+kqwuceeOLv5x5y96MW12EtHwjRPkSighAfZSE711dEUoB5wG3GmKKGmvooC2q/RGQ4sMcYs8qz2EdT04i6YBCDdRE8Y4zpDRym4VS4oSY/jp9+JNZt0Q5IBob5aBqq96Ax1CdzyPZFRO4BKoGZNUU+mgW9D5GoIHYAHT32OwAFQZKlQUQkFqscZhpj5jvF9eXNCMV+/RQYISLfAnOwbqY/AhkiUhNJ2FNOVx+c+nTgh0AKXIsdwA5jzApn/3WswginezAY2GqMKTTGVADzgZ8QPvfAE38/91C8HziD5cOBq4zjNyJE+xCJCuIzoJsziyMOOxC3OMgy1UFEBJgBrDPGTPOoqi9vxmLgGmdGR3/gYI05HiyMMZONMR2MMXnYz/lfxpirgGXAJU6z2n2o6dslTvug/eMzxuwCtotID6doELCWMLoHWNdSfxFJcr5TNX0Ii3tQC38/93eAISKS6VhSQ5yyoCEi5wJ3ASOMMSUeVYuBy51ZZF2AbsCnBPt5FcgBm1B5YWc9bMTODrgn2PLUI+MArCn5FfCl8zoP6w9eCmxy3rOc9gL8xenT10DfYPehVn8G4p7FlI/98m8GXgPinfIEZ3+zU58fAnL3AlY692EhdjZMWN0D4AFgPTYx18vYmTIhfQ+A2dgxkwrsv+hxx/K5Y/38m53XtSHQh83YMYWa3/R0j/b3OH3YAAzzKA/a80pDbSiKoig+iUQXk6IoitIIVEEoiqIoPlEFoSiKovhEFYSiKIriE1UQiqIoik9UQSgRiYhUiciXTpTT1SJyu4gc9+9BRPI8o3c28pixIvLU8V5bUZqamKM3UZQWSakxpheAiLTGRptNB6YEVSpFCSHUglAiHmPMHuAG4GZnNW6eiHwkIp87r58AiMjLIjKy5jgRmSkiI+o7r2MZzBeRt518BI961F0rIhtF5ANsSJKa8hwRmScinzmvnzrlT4rIfc72UBH5sCksHkVpCLUgFAUwxmxxHritsTF+fmaMKRORbtgVsX2B54GJwCIRScfGNDpaEppe2Ei85cAGEfkzNkjbA8D/YqOlLgO+cNr/CXjCGPOxiHTChoY4ERsk8DMR+Qh4EjjPGFONojQjqiAUxU1N5MxY4CkR6QVUAd0BjDEfiMhfHJfURcA84w6ZXR9LjTEHAURkLdAZaAW8b4wpdMpfrbkGNrheTxs2CYA0EUk1xhSLyPXAh8BEY8x/m6C/itIgqiAUBRCRfKwy2IMdh9gNnIJ1w5Z5NH0ZuAobNO26Rpy63GO7Cvdvrr4YN1HYhD2lPup+DOzDhu1WlGZHfZhKxCMiOdi0m08ZG5wsHdjpuHCuxqZ9rOFvwG0Axpg1x3jJFcBAEcl2QrqP9qh7F7jZQ7aagfTOwK+x7qphInLaMV5bURqNKgglUkmsmeYKvId9MD/g1D0NjBGR5VjXz+Gag4wxu4F1wIvHemFjQ1HfD3ziXPtzj+oJQF+x1lzgDAAAAG5JREFUSe3XAjd6hH6fZIwpwEYFfV5EEo5VBkVpDBrNVVH8QESSsCGl+9SMLShKS0UtCEVpJCIyGJtX4c+qHJRIQC0IRVEUxSdqQSiKoig+UQWhKIqi+EQVhKIoiuITVRCKoiiKT1RBKIqiKD75f9GywztF590QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train4, y_test4, y_train_preds4, y_test_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different numbers of features\n",
    "\n",
    "We will read in the dataframe again and consider another couple features (volume traded and vwap).\n",
    "\n",
    "We test compared to the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-27</th>\n",
       "      <td>64.7650</td>\n",
       "      <td>64.9747</td>\n",
       "      <td>64.5029</td>\n",
       "      <td>64.7825</td>\n",
       "      <td>9105139</td>\n",
       "      <td>64.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-28</th>\n",
       "      <td>64.8786</td>\n",
       "      <td>65.8746</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>65.2368</td>\n",
       "      <td>6035231</td>\n",
       "      <td>65.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-29</th>\n",
       "      <td>65.7785</td>\n",
       "      <td>65.8484</td>\n",
       "      <td>64.7126</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>8440854</td>\n",
       "      <td>61.0517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-30</th>\n",
       "      <td>65.1232</td>\n",
       "      <td>65.6037</td>\n",
       "      <td>64.9660</td>\n",
       "      <td>65.3067</td>\n",
       "      <td>6742046</td>\n",
       "      <td>65.2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>64.5816</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>64.3369</td>\n",
       "      <td>65.2455</td>\n",
       "      <td>10665285</td>\n",
       "      <td>65.3223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close    volume     vwap\n",
       "date                                                             \n",
       "2014-01-27  64.7650  64.9747  64.5029  64.7825   9105139  64.7739\n",
       "2014-01-28  64.8786  65.8746  64.7388  65.2368   6035231  65.3045\n",
       "2014-01-29  65.7785  65.8484  64.7126  64.7388   8440854  61.0517\n",
       "2014-01-30  65.1232  65.6037  64.9660  65.3067   6742046  65.2975\n",
       "2014-01-31  64.5816  65.6911  64.3369  65.2455  10665285  65.3223"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Walmart Stock Data\n",
    "filepath = os.path.join('..', 'Resources', 'WMT.csv')\n",
    "new_df = pd.read_csv(filepath)\n",
    "\n",
    "#drop unnessecary columns\n",
    "new_df.drop(['unadjustedVolume', 'change', 'changePercent', 'label', 'changeOverTime'], 1, inplace = True)\n",
    "\n",
    "#set index\n",
    "new_df.set_index('date', inplace = True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first run the functions for 30 days sequence and 5 days of future point for the old number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 7s 8ms/step - loss: 0.0480 - acc: 0.0011 - val_loss: 0.0932 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0094 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1506 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1442 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1476 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1522 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1659 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1577 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1557 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1431 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1854 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1695 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1726 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1762 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1751 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1699 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1855 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2029 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1974 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1859 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2105 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1966 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1703 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1817 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1937 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2169 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2263 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2290 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2126 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1950 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2229 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2306 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2264 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1903 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1958 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2358 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2222 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1892 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2227 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2001 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1926 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1787 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1690 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1801 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1718 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1114 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1013 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1573 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1666 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1748 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1219 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1007 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1002 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1371 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0887 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1131 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0358 - val_acc: 0.0064\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0387 - val_acc: 0.0064\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1275 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0064\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.3289 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0064\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1360 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1143 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0309 - val_acc: 0.0064\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0586 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0247 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0373 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2714 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1890 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1646 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2346 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1945 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1665 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.3358 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.3163 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1645 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.3428 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.4557 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.5764 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.4594 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.3116 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1532 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2850 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.3089 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2244 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1190 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1576 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0584 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1008 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0969 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2044 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1772 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.3098 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1748 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1638 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0458 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0607 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1144 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0266 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0309 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0639 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0286 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0573 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0243 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0794 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0303 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0260 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0588 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0262 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0214 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0204 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0380 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0572 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0304 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0395 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0269 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0212 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0300 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0203 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0271 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0233 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0222 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0210 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0259 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Training Set- Score: 0.006159613274324399, RMSE: 0.07848320377204539\n",
      "Test Set- Score: 0.027706175232711044, RMSE: 0.16645172042580708\n"
     ]
    }
   ],
   "source": [
    "#model for old number of features\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 8s 9ms/step - loss: 0.0548 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0092 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1511 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1673 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1909 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1707 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1888 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1788 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1938 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1661 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1774 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1725 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1673 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1879 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1632 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1726 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1619 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1882 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1698 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1342 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1529 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1614 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1617 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1770 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1755 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1836 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1491 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1228 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1711 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1788 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1876 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1817 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1685 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1886 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2372 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2097 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2018 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1993 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1874 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1801 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1328 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1546 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1142 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0894 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0971 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0834 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1332 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1043 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1368 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1744 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1811 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.2060 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1384 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1494 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1431 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0607 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1088 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0503 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0434 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0647 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.2215 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1293 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0791 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1027 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1969 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0303 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0289 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0776 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1054 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0605 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0442 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0609 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0654 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0525 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0438 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0947 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0452 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0392 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0494 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0358 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0652 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2709 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0949 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0232 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2528 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0249 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2076 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.3134 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0746 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1237 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0872 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2711 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0719 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0733 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0709 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0990 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0452 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0435 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0363 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0373 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0643 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0393 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Training Set- Score: 0.008340317677133358, RMSE: 0.09132533973182556\n",
      "Test Set- Score: 0.04561135691145192, RMSE: 0.2135681551904495\n"
     ]
    }
   ],
   "source": [
    "#model for new number of features\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features_real_long.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(new_df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 905 samples, validate on 160 samples\n",
      "Epoch 1/300\n",
      "905/905 [==============================] - 6s 7ms/step - loss: 0.0509 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "905/905 [==============================] - 1s 581us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "905/905 [==============================] - 1s 746us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1480 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "905/905 [==============================] - 1s 677us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "905/905 [==============================] - 1s 609us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "905/905 [==============================] - 1s 599us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "905/905 [==============================] - 1s 616us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "905/905 [==============================] - 1s 573us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1809 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1793 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1851 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "905/905 [==============================] - 1s 596us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1810 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "905/905 [==============================] - 1s 586us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1768 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "905/905 [==============================] - 1s 580us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1791 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "905/905 [==============================] - 1s 656us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "905/905 [==============================] - 1s 585us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1859 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "905/905 [==============================] - 1s 618us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1891 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "905/905 [==============================] - 1s 584us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2039 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2055 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2178 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "905/905 [==============================] - 1s 584us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2193 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "905/905 [==============================] - 1s 632us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2126 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "905/905 [==============================] - 1s 623us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.2103 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "905/905 [==============================] - 1s 591us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2114 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "905/905 [==============================] - 1s 622us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2130 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2139 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "905/905 [==============================] - 1s 592us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2038 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "905/905 [==============================] - 1s 699us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2270 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "905/905 [==============================] - 1s 726us/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2100 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "905/905 [==============================] - 1s 700us/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2176 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "905/905 [==============================] - 1s 681us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.2170 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "905/905 [==============================] - 1s 590us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2166 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "905/905 [==============================] - 1s 702us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1992 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1952 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "905/905 [==============================] - 1s 593us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1864 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1883 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1860 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1713 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1656 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "905/905 [==============================] - 1s 627us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "905/905 [==============================] - 1s 606us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "905/905 [==============================] - 1s 608us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1534 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "905/905 [==============================] - 1s 720us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1752 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "905/905 [==============================] - 1s 689us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1435 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "905/905 [==============================] - 1s 669us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "905/905 [==============================] - 1s 627us/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "905/905 [==============================] - 1s 607us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1196 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "905/905 [==============================] - 1s 586us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "905/905 [==============================] - 0s 536us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "905/905 [==============================] - 0s 540us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1262 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "905/905 [==============================] - 1s 643us/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "905/905 [==============================] - 1s 623us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "905/905 [==============================] - 1s 578us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "905/905 [==============================] - 0s 539us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "905/905 [==============================] - 1s 633us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1156 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1174 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "905/905 [==============================] - 1s 588us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "905/905 [==============================] - 1s 649us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "905/905 [==============================] - 1s 699us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1127 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1128 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "905/905 [==============================] - 1s 597us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "905/905 [==============================] - 1s 606us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "905/905 [==============================] - 1s 654us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "905/905 [==============================] - 1s 613us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1155 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "905/905 [==============================] - 1s 617us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1192 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "905/905 [==============================] - 1s 587us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "905/905 [==============================] - 1s 631us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1707 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "905/905 [==============================] - 1s 579us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1150 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1170 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "905/905 [==============================] - 1s 597us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1194 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "905/905 [==============================] - 1s 629us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "905/905 [==============================] - 1s 579us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "905/905 [==============================] - 1s 698us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "905/905 [==============================] - 1s 663us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "905/905 [==============================] - 1s 612us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "905/905 [==============================] - 1s 692us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "905/905 [==============================] - 1s 592us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "905/905 [==============================] - 1s 579us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "905/905 [==============================] - 1s 600us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "905/905 [==============================] - 1s 620us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "905/905 [==============================] - 1s 592us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "905/905 [==============================] - 1s 595us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "905/905 [==============================] - 1s 605us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1443 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "905/905 [==============================] - 1s 618us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 1s 629us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "905/905 [==============================] - 1s 583us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "905/905 [==============================] - 1s 594us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "905/905 [==============================] - 1s 584us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "905/905 [==============================] - 1s 595us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "905/905 [==============================] - 1s 602us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1184 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "905/905 [==============================] - 1s 585us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "905/905 [==============================] - 1s 641us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1021 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "905/905 [==============================] - 1s 576us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2146 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "905/905 [==============================] - 1s 611us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.2061 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "905/905 [==============================] - 1s 614us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "905/905 [==============================] - 1s 633us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "905/905 [==============================] - 1s 623us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "905/905 [==============================] - 1s 569us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1271 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "905/905 [==============================] - 1s 574us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1866 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1477 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "905/905 [==============================] - 1s 582us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1866 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "905/905 [==============================] - 1s 606us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1378 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "905/905 [==============================] - 1s 589us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1478 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "905/905 [==============================] - 1s 618us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2210 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "905/905 [==============================] - 1s 591us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "905/905 [==============================] - 1s 619us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1537 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "905/905 [==============================] - 1s 660us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1354 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1723 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1571 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "905/905 [==============================] - 1s 577us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "905/905 [==============================] - 1s 575us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1318 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "905/905 [==============================] - 1s 571us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1503 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "905/905 [==============================] - 1s 565us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1644 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.2020 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1297 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "905/905 [==============================] - 1s 562us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1601 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1617 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "905/905 [==============================] - 1s 575us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1309 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "905/905 [==============================] - 1s 570us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1437 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "905/905 [==============================] - 1s 568us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1181 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1449 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1060 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1226 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "905/905 [==============================] - 1s 572us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1832 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "905/905 [==============================] - 1s 566us/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "905/905 [==============================] - 1s 563us/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1393 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "905/905 [==============================] - 0s 539us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1820 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2437 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1913 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1667 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1629 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "905/905 [==============================] - 1s 558us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1193 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "905/905 [==============================] - 1s 557us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1222 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1703 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1910 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1428 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1791 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "905/905 [==============================] - 1s 564us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1315 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1852 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1734 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1765 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1730 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1397 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1756 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.2189 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1585 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1417 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1676 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1675 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1700 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1357 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1446 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1523 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1691 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "905/905 [==============================] - 0s 537us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1491 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1414 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "905/905 [==============================] - 0s 540us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1378 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1314 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1329 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "905/905 [==============================] - 0s 540us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1479 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "905/905 [==============================] - 0s 543us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1099 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1367 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "905/905 [==============================] - 0s 537us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1589 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "905/905 [==============================] - 0s 538us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1113 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "905/905 [==============================] - 1s 555us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1214 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "905/905 [==============================] - 1s 556us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "905/905 [==============================] - 0s 548us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1377 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1720 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1593 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1178 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1571 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "905/905 [==============================] - 1s 560us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "905/905 [==============================] - 0s 549us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1658 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1774 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "905/905 [==============================] - 1s 554us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1581 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "905/905 [==============================] - 1s 567us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1723 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "905/905 [==============================] - 1s 559us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1427 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "905/905 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "905/905 [==============================] - 0s 547us/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "905/905 [==============================] - 0s 552us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "905/905 [==============================] - 1s 553us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1471 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "905/905 [==============================] - 0s 550us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1357 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "905/905 [==============================] - 0s 535us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1807 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "905/905 [==============================] - 0s 541us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "905/905 [==============================] - 0s 532us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1096 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "905/905 [==============================] - 0s 542us/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "905/905 [==============================] - 0s 544us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "905/905 [==============================] - 0s 545us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1209 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1244 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "905/905 [==============================] - 0s 546us/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.021015886693948032, RMSE: 0.14496857140065922\n",
      "Test Set- Score: 0.14614055765436051, RMSE: 0.3822833473411581\n"
     ]
    }
   ],
   "source": [
    "#test with 5 days sequence 1 day future point\n",
    "seq_length = 5\n",
    "fut_point = 1\n",
    "train_split = 0.85\n",
    "neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'more_features_real.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(new_df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Now, we attempt to tune hyperparameters of the model.\n",
    "\n",
    "First, we will look at number of neurons.  For all of these first trials, we will use a sequence length of thirty \n",
    "and a future point of five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.1296 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1641 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1728 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1824 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1828 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1783 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1677 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1751 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1945 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1916 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1940 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1953 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2077 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2207 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2406 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2477 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2619 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2623 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2670 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2601 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2832 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3034 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2826 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2872 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3131 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3282 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3569 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3689 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3759 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3731 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3512 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3536 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3741 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3656 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.3874 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.3477 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3516 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.4027 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.4191 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3646 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3540 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3642 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3815 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3711 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3332 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3709 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3345 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3111 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3137 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2818 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3278 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3079 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3246 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2523 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2654 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2540 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2687 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2304 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2343 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1899 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1961 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1410 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1583 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1083 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0064\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0342 - val_acc: 0.0064\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0282 - val_acc: 0.0064\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0268 - val_acc: 0.0064\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0064\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0064\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0064\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0946 - val_acc: 0.0064\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0064\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0064\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0064\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0618 - val_acc: 0.0064\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0340 - val_acc: 0.0064\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0064\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1130 - val_acc: 0.0064\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0227 - val_acc: 0.0064\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0203 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0449 - val_acc: 0.0064\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0235 - val_acc: 0.0064\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0229 - val_acc: 0.0064\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0349 - val_acc: 0.0064\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0204 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0249 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0246 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0064\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0400 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0692 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0396 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0328 - val_acc: 0.0064\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0471 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0356 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0328 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0972 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1962 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1602 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0304 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0647 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0400 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0792 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0514 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0590 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0862 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0787 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0678 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0064\n",
      "Epoch 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0791 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0700 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0521 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1413 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0651 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0695 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0562 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0954 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0471 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1257 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1261 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1205 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2689 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1561 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0248 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0486 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0455 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1590 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2347 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0418 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0242 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0961 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1907 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1452 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1779 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1193 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2114 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2526 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.2083 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1640 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1432 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1499 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1560 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1291 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1861 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0737 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0952 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1064 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.011277323450821523, RMSE: 0.10619474304701491\n",
      "Test Set- Score: 0.06465379343084666, RMSE: 0.25427110223312177\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0320 - acc: 0.0011 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1729 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1781 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1824 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1921 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2006 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2024 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2015 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2022 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1999 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1962 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2103 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1732 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1815 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2122 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2144 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2318 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2395 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2216 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2194 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2337 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2616 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2670 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2628 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2573 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2683 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2612 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2628 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2582 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2975 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3401 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3290 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3358 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3349 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.3413 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2800 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3197 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3500 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3447 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3480 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3552 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3533 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3417 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3451 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.3401 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3385 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.3293 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3337 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3511 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3607 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3493 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3446 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3203 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2964 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3036 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3037 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2999 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.3023 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2435 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2357 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2440 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2599 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2488 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2586 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.3181 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2583 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2493 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2552 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2510 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2296 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1959 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1965 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1634 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1351 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1239 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0064\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0605 - val_acc: 0.0064\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0064\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0064\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0064\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1778 - val_acc: 0.0064\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0064\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0995 - val_acc: 0.0064\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2231 - val_acc: 0.0064\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1403 - val_acc: 0.0064\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1131 - val_acc: 0.0064\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0847 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0544 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0064\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.3627 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0702 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0841 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1927 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1825 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1684 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2174 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1379 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0677 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1077 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0833 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.3550 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2233 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1245 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1468 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1952 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0064\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1356 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2059 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0750 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1508 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1688 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.2757 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1771 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1203 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1101 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1867 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0263 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.4702 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0956 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0834 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0448 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1439 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0219 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1235 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0260 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0168 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0349 - val_acc: 0.0064\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0458 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1590 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0208 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0972 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0633 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0259 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0424 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0791 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0386 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0250 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0418 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0552 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0249 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0205 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0457 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0743 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 297/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0064\n",
      "Training Set- Score: 0.007928202011121007, RMSE: 0.08904045154378434\n",
      "Test Set- Score: 0.036964372772237526, RMSE: 0.19226120974402905\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 3ms/step - loss: 0.0418 - acc: 0.0011 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.0011 - val_loss: 0.1362 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1315 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1301 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1280 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1280 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1376 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1314 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1365 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1416 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1332 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1586 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1513 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1395 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1278 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1423 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1362 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1400 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1374 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1447 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1301 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1333 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 998us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 991us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 995us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1461 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1523 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1538 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1440 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1594 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1722 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1234 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1510 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1391 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1439 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1424 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1525 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1551 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1426 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1649 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1479 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1782 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1761 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1294 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1658 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0617 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1421 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1365 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1322 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1234 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 982us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1123 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1279 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0474 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0565 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0455 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0365 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0254 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0253 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0282 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0276 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0233 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0234 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0236 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0064\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0647 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1078 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1658 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0777 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0770 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0759 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2133 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1956 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1328 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0524 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1121 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0726 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1951 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2122 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2166 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2138 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2077 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1361 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1649 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1844 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2200 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1205 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2309 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2328 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2145 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1889 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1507 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2256 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2665 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1589 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2757 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1777 - val_acc: 0.0064\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1428 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.2448 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.4884 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0839 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1916 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1162 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1980 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1195 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1652 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2649 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1883 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2436 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2020 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2997 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1146 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0799 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1944 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1493 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2218 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2624 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1378 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1351 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0753 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1300 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1886 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1338 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2660 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.2084 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1416 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1408 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1469 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1710 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1521 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1991 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1790 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1543 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1715 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1075 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1471 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1517 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1551 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1694 - val_acc: 0.0064\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1052 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1309 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0064\n",
      "Training Set- Score: 0.010154810512008575, RMSE: 0.10077107974021403\n",
      "Test Set- Score: 0.038823068141937256, RMSE: 0.1970357027087661\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0410 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.0011 - val_loss: 0.1669 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1727 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 998us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1766 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1847 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 992us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1926 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1952 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.2018 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2071 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.2099 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2048 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.2069 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2096 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2243 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2252 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2297 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2252 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2303 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2381 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2220 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2214 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2310 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2341 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2417 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2412 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2379 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2425 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2409 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2487 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2630 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2616 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2352 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2436 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2497 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2455 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2571 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2619 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2468 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2455 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2545 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2317 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2571 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2492 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2487 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2655 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2363 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2191 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2222 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 972us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2173 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 989us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2369 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2365 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2261 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2249 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2128 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2262 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2043 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2371 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2290 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2229 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2409 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2510 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2488 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2325 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2192 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2383 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2421 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2158 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2168 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2156 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2093 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2138 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1868 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2442 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2470 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2160 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2272 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2169 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2297 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2335 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2205 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2171 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2427 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2190 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2760 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2462 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2032 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1954 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2121 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2055 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2395 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1933 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2271 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1948 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1803 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2143 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2190 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2096 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2255 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1812 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.2097 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1677 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2010 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1754 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2007 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2233 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2063 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1877 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2001 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1757 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1915 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2204 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.2251 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1851 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1460 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1603 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1346 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1173 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1068 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1016 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1014 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0666 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0933 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0684 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 991us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0362 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0289 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0284 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0262 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0482 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0263 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0267 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0394 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0345 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0245 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0269 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0256 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0282 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0315 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0328 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0403 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0342 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0305 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0324 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0319 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0300 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0307 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0223 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0342 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0246 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0268 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0231 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0343 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0291 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0380 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0227 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0283 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0264 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0220 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0378 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0288 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0287 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0284 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0259 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0351 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0277 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0275 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1350 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0305 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0227 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 995us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0255 - val_acc: 0.0064\n",
      "Training Set- Score: 0.0062098498303944675, RMSE: 0.07880260040375868\n",
      "Test Set- Score: 0.018896806499232418, RMSE: 0.13746565570800737\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 3s 4ms/step - loss: 0.0619 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 852us/step - loss: 0.0153 - acc: 0.0011 - val_loss: 0.1937 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 908us/step - loss: 0.0093 - acc: 0.0011 - val_loss: 0.1847 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.1751 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1640 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1533 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 900us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 885us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 828us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1177 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1203 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 724us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 824us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1055 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 832us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1062 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 812us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 849us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1006 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1010 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 709us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 732us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0839 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0770 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0763 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0781 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0689 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0719 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0787 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0742 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0704 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0664 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0841 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0752 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 873us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 890us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 903us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0767 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 883us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0749 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 864us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 857us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 782us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0800 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0794 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0827 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0886 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1237 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0794 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0998 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0890 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0852 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 827us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0766 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 794us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0917 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0716 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0837 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0653 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 802us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0366 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0421 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0322 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0423 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 802us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0339 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0398 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0393 - val_acc: 0.0064\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 768us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0387 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 897us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0455 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 898us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0448 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0516 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0556 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0400 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0350 - val_acc: 0.0064\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0307 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0331 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0297 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0304 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0315 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 825us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 828us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 905us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 864us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 882us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 824us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 833us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0301 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0489 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 872us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 910us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0371 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 927us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 809us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 840us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 850us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0418 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 827us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0358 - val_acc: 0.0064\n",
      "Training Set- Score: 0.00840558975827522, RMSE: 0.09168200345910434\n",
      "Test Set- Score: 0.02098413115448278, RMSE: 0.1448590043955942\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 4s 4ms/step - loss: 0.0643 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0140 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0103 - acc: 0.0011 - val_loss: 0.0648 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 850us/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 862us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 872us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0856 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 862us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 846us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0782 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 893us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 880us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 904us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0599 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 828us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 832us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0562 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0541 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 873us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 837us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 842us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 864us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0558 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0557 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0513 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0517 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 813us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0581 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0500 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0425 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0502 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0566 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0488 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 869us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 818us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 825us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 800us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0750 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0770 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 903us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0668 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 883us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 900us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1072 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1074 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 881us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 890us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 883us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1037 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 849us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1407 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1486 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1511 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1434 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1442 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1698 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1583 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1372 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 874us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1429 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 833us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1495 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1462 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1264 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1515 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1556 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 771us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1650 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1463 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1558 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1510 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1172 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1361 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1255 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1001 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1110 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0963 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1163 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 854us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1249 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 858us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1233 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1267 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 797us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1562 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 792us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1156 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1400 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1530 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1341 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1306 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1323 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1194 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 794us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1373 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1441 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1451 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1211 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1062 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0977 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 837us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 918us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 915us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 865us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1144 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1238 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1223 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 817us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 879us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 795us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1027 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1041 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 843us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 901us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 906us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 892us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 865us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1054 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0946 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 876us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1022 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 934us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 912us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 887us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0758 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 871us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0796 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 824us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0678 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 842us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 891us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0648 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 922us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 870us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0655 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0429 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 838us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0743 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 779us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0654 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0683 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 782us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0677 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0689 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 852us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 848us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0606 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0467 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 806us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0485 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0365 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 820us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0343 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0382 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0064\n",
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Training Set- Score: 0.008468011232952658, RMSE: 0.09202179759683386\n",
      "Test Set- Score: 0.029004056330608284, RMSE: 0.17030577303957808\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Empty 'DataFrame': no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-438a79f7d9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Neuron Lengths'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train Scores'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Neuron Lengths'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Train Scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, y, **kwds)\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lifespan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m         \"\"\"\n\u001b[0;32m-> 3090\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2939\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2941\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   1975\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1802\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             raise TypeError('Empty {0!r}: no numeric data to '\n\u001b[0;32m--> 373\u001b[0;31m                             'plot'.format(numeric_data.__class__.__name__))\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Empty 'DataFrame': no numeric data to plot"
     ]
    }
   ],
   "source": [
    "#look at number of neurons\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "#neurons = [256, 256, 32]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "neuron_lengths = [[256, 256, 32], [256, 256, 16], [128, 128, 32], [128, 128, 16], [64, 64, 32], [64, 64, 16]]\n",
    "\n",
    "#create lists to store results\n",
    "neurons = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for neuron_length in neuron_lengths:\n",
    "    neurons.append(f\"{neuron_length}\")\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neuron_length, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Neuron Lengths': neurons, 'Train Scores': train_scores})\n",
    "\n",
    "results.plot.bar(x = 'Neuron Lengths', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neuron Lengths</th>\n",
       "      <th>Train Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256, 256, 32]</td>\n",
       "      <td>[0.011277323450821523, 0.0009615384615384616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[256, 256, 16]</td>\n",
       "      <td>[0.007928202011121007, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[128, 128, 32]</td>\n",
       "      <td>[0.010154810512008575, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[128, 128, 16]</td>\n",
       "      <td>[0.0062098498303944675, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[64, 64, 32]</td>\n",
       "      <td>[0.00840558975827522, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[64, 64, 16]</td>\n",
       "      <td>[0.008468011232952658, 0.0019230769230769232]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neuron Lengths                                    Train Scores\n",
       "0  [256, 256, 32]   [0.011277323450821523, 0.0009615384615384616]\n",
       "1  [256, 256, 16]   [0.007928202011121007, 0.0019230769230769232]\n",
       "2  [128, 128, 32]   [0.010154810512008575, 0.0019230769230769232]\n",
       "3  [128, 128, 16]  [0.0062098498303944675, 0.0019230769230769232]\n",
       "4    [64, 64, 32]    [0.00840558975827522, 0.0019230769230769232]\n",
       "5    [64, 64, 16]   [0.008468011232952658, 0.0019230769230769232]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/300\n",
      "884/884 [==============================] - 4s 5ms/step - loss: 0.0746 - acc: 0.0000e+00 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.0011 - val_loss: 0.1161 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.1175 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1180 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1147 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1242 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1544 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1503 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1467 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1489 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1566 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1596 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1516 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1547 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1504 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1415 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1437 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1776 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1839 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2109 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1984 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1882 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1891 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1946 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2026 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2167 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2401 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "884/884 [==============================] - 1s 1000us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2388 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2353 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2300 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2421 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2198 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2081 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2064 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2023 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2228 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2311 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2636 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2629 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2511 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2326 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2977 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2507 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2297 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2235 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2046 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1873 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1984 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1819 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1871 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1862 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2326 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2401 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2260 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1810 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1752 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1454 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1879 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1803 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1574 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1542 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "884/884 [==============================] - 1s 952us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "884/884 [==============================] - 1s 980us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "884/884 [==============================] - 1s 958us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "884/884 [==============================] - 1s 973us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "884/884 [==============================] - 1s 971us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0746 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 104/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 109/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 110/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0477 - val_acc: 0.0064\n",
      "Epoch 111/300\n",
      "884/884 [==============================] - 1s 929us/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 112/300\n",
      "884/884 [==============================] - 1s 935us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0395 - val_acc: 0.0064\n",
      "Epoch 113/300\n",
      "884/884 [==============================] - 1s 932us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 114/300\n",
      "884/884 [==============================] - 1s 921us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0346 - val_acc: 0.0064\n",
      "Epoch 115/300\n",
      "884/884 [==============================] - 1s 948us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 116/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 117/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 118/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 954us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 120/300\n",
      "884/884 [==============================] - 1s 970us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 121/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0064\n",
      "Epoch 122/300\n",
      "884/884 [==============================] - 1s 930us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 123/300\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0314 - val_acc: 0.0064\n",
      "Epoch 124/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0312 - val_acc: 0.0064\n",
      "Epoch 125/300\n",
      "884/884 [==============================] - 1s 954us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0296 - val_acc: 0.0064\n",
      "Epoch 126/300\n",
      "884/884 [==============================] - 1s 953us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0341 - val_acc: 0.0064\n",
      "Epoch 127/300\n",
      "884/884 [==============================] - 1s 953us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 128/300\n",
      "884/884 [==============================] - 1s 952us/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0064\n",
      "Epoch 129/300\n",
      "884/884 [==============================] - 1s 987us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0285 - val_acc: 0.0064\n",
      "Epoch 130/300\n",
      "884/884 [==============================] - 1s 945us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0251 - val_acc: 0.0064\n",
      "Epoch 131/300\n",
      "884/884 [==============================] - 1s 930us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0242 - val_acc: 0.0064\n",
      "Epoch 132/300\n",
      "884/884 [==============================] - 1s 969us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0280 - val_acc: 0.0064\n",
      "Epoch 133/300\n",
      "884/884 [==============================] - 1s 949us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0064\n",
      "Epoch 134/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0270 - val_acc: 0.0064\n",
      "Epoch 135/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0258 - val_acc: 0.0064\n",
      "Epoch 136/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0574 - val_acc: 0.0064\n",
      "Epoch 137/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0368 - val_acc: 0.0064\n",
      "Epoch 138/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0443 - val_acc: 0.0064\n",
      "Epoch 139/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 140/300\n",
      "884/884 [==============================] - 1s 966us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0064\n",
      "Epoch 141/300\n",
      "884/884 [==============================] - 1s 954us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 142/300\n",
      "884/884 [==============================] - 1s 974us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1036 - val_acc: 0.0064\n",
      "Epoch 143/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0064\n",
      "Epoch 144/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 145/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 146/300\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0064\n",
      "Epoch 147/300\n",
      "884/884 [==============================] - 1s 971us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0575 - val_acc: 0.0064\n",
      "Epoch 148/300\n",
      "884/884 [==============================] - 1s 953us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0064\n",
      "Epoch 149/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1588 - val_acc: 0.0064\n",
      "Epoch 150/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0064\n",
      "Epoch 151/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0064\n",
      "Epoch 152/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.1227 - val_acc: 0.0064\n",
      "Epoch 153/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0747 - val_acc: 0.0064\n",
      "Epoch 154/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0064\n",
      "Epoch 155/300\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 156/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1344 - val_acc: 0.0064\n",
      "Epoch 157/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1120 - val_acc: 0.0064\n",
      "Epoch 158/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0064\n",
      "Epoch 159/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0348 - val_acc: 0.0064\n",
      "Epoch 160/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0864 - val_acc: 0.0064\n",
      "Epoch 161/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0446 - val_acc: 0.0064\n",
      "Epoch 162/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1324 - val_acc: 0.0064\n",
      "Epoch 163/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0064\n",
      "Epoch 164/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0961 - val_acc: 0.0064\n",
      "Epoch 165/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0064\n",
      "Epoch 166/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0847 - val_acc: 0.0064\n",
      "Epoch 167/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0064\n",
      "Epoch 168/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Epoch 169/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 170/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0290 - val_acc: 0.0064\n",
      "Epoch 171/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0593 - val_acc: 0.0064\n",
      "Epoch 172/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 173/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0064\n",
      "Epoch 174/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0064\n",
      "Epoch 175/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0878 - val_acc: 0.0064\n",
      "Epoch 176/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1064 - val_acc: 0.0064\n",
      "Epoch 177/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0526 - val_acc: 0.0064\n",
      "Epoch 178/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1232 - val_acc: 0.0064\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1702 - val_acc: 0.0064\n",
      "Epoch 180/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1670 - val_acc: 0.0064\n",
      "Epoch 181/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0623 - val_acc: 0.0064\n",
      "Epoch 182/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0064\n",
      "Epoch 183/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0064\n",
      "Epoch 184/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0064\n",
      "Epoch 185/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0064\n",
      "Epoch 186/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1127 - val_acc: 0.0064\n",
      "Epoch 187/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0064\n",
      "Epoch 188/300\n",
      "884/884 [==============================] - 1s 990us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 189/300\n",
      "884/884 [==============================] - 1s 994us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 190/300\n",
      "884/884 [==============================] - 1s 968us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0064\n",
      "Epoch 191/300\n",
      "884/884 [==============================] - 1s 993us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 192/300\n",
      "884/884 [==============================] - 1s 980us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 193/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0064\n",
      "Epoch 194/300\n",
      "884/884 [==============================] - 1s 970us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0064\n",
      "Epoch 195/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0064\n",
      "Epoch 196/300\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1070 - val_acc: 0.0064\n",
      "Epoch 197/300\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0064\n",
      "Epoch 198/300\n",
      "884/884 [==============================] - 1s 963us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0352 - val_acc: 0.0064\n",
      "Epoch 199/300\n",
      "884/884 [==============================] - 1s 956us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1018 - val_acc: 0.0064\n",
      "Epoch 200/300\n",
      "884/884 [==============================] - 1s 951us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0064\n",
      "Epoch 201/300\n",
      "884/884 [==============================] - 1s 961us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0064\n",
      "Epoch 202/300\n",
      "884/884 [==============================] - 1s 973us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0064\n",
      "Epoch 203/300\n",
      "884/884 [==============================] - 1s 995us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1585 - val_acc: 0.0064\n",
      "Epoch 204/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2362 - val_acc: 0.0064\n",
      "Epoch 205/300\n",
      "884/884 [==============================] - 1s 997us/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1196 - val_acc: 0.0064\n",
      "Epoch 206/300\n",
      "884/884 [==============================] - 1s 977us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1490 - val_acc: 0.0064\n",
      "Epoch 207/300\n",
      "884/884 [==============================] - 1s 988us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0064\n",
      "Epoch 208/300\n",
      "884/884 [==============================] - 1s 973us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1364 - val_acc: 0.0064\n",
      "Epoch 209/300\n",
      "884/884 [==============================] - 1s 961us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1746 - val_acc: 0.0064\n",
      "Epoch 210/300\n",
      "884/884 [==============================] - 1s 955us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1810 - val_acc: 0.0064\n",
      "Epoch 211/300\n",
      "884/884 [==============================] - 1s 970us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1745 - val_acc: 0.0064\n",
      "Epoch 212/300\n",
      "884/884 [==============================] - 1s 996us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1448 - val_acc: 0.0064\n",
      "Epoch 213/300\n",
      "884/884 [==============================] - 1s 992us/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1056 - val_acc: 0.0064\n",
      "Epoch 214/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0064\n",
      "Epoch 215/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1117 - val_acc: 0.0064\n",
      "Epoch 216/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1549 - val_acc: 0.0064\n",
      "Epoch 217/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1869 - val_acc: 0.0064\n",
      "Epoch 218/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1472 - val_acc: 0.0064\n",
      "Epoch 219/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1780 - val_acc: 0.0064\n",
      "Epoch 220/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1748 - val_acc: 0.0064\n",
      "Epoch 221/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0064\n",
      "Epoch 222/300\n",
      "884/884 [==============================] - 1s 984us/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0815 - val_acc: 0.0064\n",
      "Epoch 223/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0064\n",
      "Epoch 224/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2400 - val_acc: 0.0064\n",
      "Epoch 225/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0064\n",
      "Epoch 226/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1188 - val_acc: 0.0064\n",
      "Epoch 227/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1848 - val_acc: 0.0064\n",
      "Epoch 228/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1977 - val_acc: 0.0064\n",
      "Epoch 229/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1201 - val_acc: 0.0064\n",
      "Epoch 230/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1362 - val_acc: 0.0064\n",
      "Epoch 231/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0064\n",
      "Epoch 232/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0064\n",
      "Epoch 233/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0064\n",
      "Epoch 234/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0064\n",
      "Epoch 235/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0064\n",
      "Epoch 236/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0064\n",
      "Epoch 237/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1290 - val_acc: 0.0064\n",
      "Epoch 238/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0064\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.1122 - val_acc: 0.0064\n",
      "Epoch 240/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0919 - val_acc: 0.0064\n",
      "Epoch 241/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0064\n",
      "Epoch 242/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0334 - val_acc: 0.0064\n",
      "Epoch 243/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0461 - val_acc: 0.0064\n",
      "Epoch 244/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0515 - val_acc: 0.0064\n",
      "Epoch 245/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0553 - val_acc: 0.0064\n",
      "Epoch 246/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0064\n",
      "Epoch 247/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0064\n",
      "Epoch 248/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0504 - val_acc: 0.0064\n",
      "Epoch 249/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 250/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 251/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0064\n",
      "Epoch 252/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0613 - val_acc: 0.0064\n",
      "Epoch 253/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 254/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 255/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0064\n",
      "Epoch 256/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1188 - val_acc: 0.0064\n",
      "Epoch 257/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0480 - val_acc: 0.0064\n",
      "Epoch 258/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 259/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0064\n",
      "Epoch 260/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0541 - val_acc: 0.0064\n",
      "Epoch 261/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0064\n",
      "Epoch 262/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 263/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0390 - val_acc: 0.0064\n",
      "Epoch 264/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 265/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0617 - val_acc: 0.0064\n",
      "Epoch 266/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 267/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0355 - val_acc: 0.0064\n",
      "Epoch 268/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0316 - val_acc: 0.0064\n",
      "Epoch 269/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 270/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0349 - val_acc: 0.0064\n",
      "Epoch 271/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0064\n",
      "Epoch 272/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0379 - val_acc: 0.0064\n",
      "Epoch 273/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0302 - val_acc: 0.0064\n",
      "Epoch 274/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0361 - val_acc: 0.0064\n",
      "Epoch 275/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 276/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0404 - val_acc: 0.0064\n",
      "Epoch 277/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 278/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0296 - val_acc: 0.0064\n",
      "Epoch 279/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 280/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0329 - val_acc: 0.0064\n",
      "Epoch 281/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0375 - val_acc: 0.0064\n",
      "Epoch 282/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0064\n",
      "Epoch 283/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0064\n",
      "Epoch 284/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0561 - val_acc: 0.0064\n",
      "Epoch 285/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0318 - val_acc: 0.0064\n",
      "Epoch 286/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 287/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0064\n",
      "Epoch 288/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 289/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0491 - val_acc: 0.0064\n",
      "Epoch 290/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0313 - val_acc: 0.0064\n",
      "Epoch 291/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0294 - val_acc: 0.0064\n",
      "Epoch 293/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 294/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 295/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0338 - val_acc: 0.0064\n",
      "Epoch 296/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 297/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 298/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 299/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0460 - val_acc: 0.0064\n",
      "Training Set- Score: 0.009353225429255803, RMSE: 0.09671207488858774\n",
      "Test Set- Score: 0.027158301809559696, RMSE: 0.1647977603293191\n"
     ]
    }
   ],
   "source": [
    "#train model for 128, 128, 16 and visualize\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'low_neurons.h5'\n",
    "y_train3, y_test3, y_train_preds3, y_test_preds3, train_score3, test_score3 = fit_generic_LSTM_model(df, \n",
    "                                                                                                     seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neurons, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "make_results_plot(y_train3, y_test3, y_train_preds3, y_test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there is a bit of randomness in the training scores (likely due to different starting weights and which variables are dropped in dropout layers during fitting).  They seem to score about the same.  As a simpler network seems to work, we will use it (128, 128, 16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Epochs\n",
    "\n",
    "We will look at how the number of epochs affects our error.  The inbuilt fit function in keras has a way of doing this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_history(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, \n",
    "                           validation_split, model_path):\n",
    "    \n",
    "    #get train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_splitter(df, seq_length, fut_point, train_split)\n",
    "    \n",
    "    #get number of features\n",
    "    features = X_train.shape[2]\n",
    "    \n",
    "    #get scalers and normalized data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_scaler, y_scaler = create_scalers_and_normalize(\n",
    "        X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    #create model\n",
    "    model = create_generic_LSTM_model(neurons, dropout, seq_length, features)\n",
    "    \n",
    "    #fit model\n",
    "    history = model.fit(X_train_scaled, y_train_scaled, epochs = epochs, \n",
    "              batch_size = batch_size, validation_split = validation_split, verbose = 1)\n",
    "    \n",
    "    #save model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/750\n",
      "884/884 [==============================] - 5s 5ms/step - loss: 0.0487 - acc: 0.0011 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 2/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 3/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.2213 - val_acc: 0.0000e+00\n",
      "Epoch 4/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.2124 - val_acc: 0.0000e+00\n",
      "Epoch 5/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2224 - val_acc: 0.0000e+00\n",
      "Epoch 6/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2244 - val_acc: 0.0000e+00\n",
      "Epoch 7/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2408 - val_acc: 0.0000e+00\n",
      "Epoch 8/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.2547 - val_acc: 0.0000e+00\n",
      "Epoch 9/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.2304 - val_acc: 0.0000e+00\n",
      "Epoch 10/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.2309 - val_acc: 0.0000e+00\n",
      "Epoch 11/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2461 - val_acc: 0.0000e+00\n",
      "Epoch 12/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2498 - val_acc: 0.0000e+00\n",
      "Epoch 13/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.2729 - val_acc: 0.0000e+00\n",
      "Epoch 14/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.2630 - val_acc: 0.0000e+00\n",
      "Epoch 15/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.2592 - val_acc: 0.0000e+00\n",
      "Epoch 16/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2727 - val_acc: 0.0000e+00\n",
      "Epoch 17/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2791 - val_acc: 0.0000e+00\n",
      "Epoch 18/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2693 - val_acc: 0.0000e+00\n",
      "Epoch 19/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2592 - val_acc: 0.0000e+00\n",
      "Epoch 20/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
      "Epoch 21/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2408 - val_acc: 0.0000e+00\n",
      "Epoch 22/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2156 - val_acc: 0.0000e+00\n",
      "Epoch 23/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2620 - val_acc: 0.0000e+00\n",
      "Epoch 24/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 25/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.2651 - val_acc: 0.0000e+00\n",
      "Epoch 26/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.2717 - val_acc: 0.0000e+00\n",
      "Epoch 27/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2821 - val_acc: 0.0000e+00\n",
      "Epoch 28/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2641 - val_acc: 0.0000e+00\n",
      "Epoch 29/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2510 - val_acc: 0.0000e+00\n",
      "Epoch 30/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2411 - val_acc: 0.0000e+00\n",
      "Epoch 31/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2493 - val_acc: 0.0000e+00\n",
      "Epoch 32/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2762 - val_acc: 0.0000e+00\n",
      "Epoch 33/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2813 - val_acc: 0.0000e+00\n",
      "Epoch 34/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.3045 - val_acc: 0.0000e+00\n",
      "Epoch 35/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3061 - val_acc: 0.0000e+00\n",
      "Epoch 36/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.2984 - val_acc: 0.0000e+00\n",
      "Epoch 37/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3325 - val_acc: 0.0000e+00\n",
      "Epoch 38/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3369 - val_acc: 0.0000e+00\n",
      "Epoch 39/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3085 - val_acc: 0.0000e+00\n",
      "Epoch 40/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.3005 - val_acc: 0.0000e+00\n",
      "Epoch 41/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 42/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 43/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2825 - val_acc: 0.0000e+00\n",
      "Epoch 44/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2809 - val_acc: 0.0000e+00\n",
      "Epoch 45/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.2990 - val_acc: 0.0000e+00\n",
      "Epoch 46/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2639 - val_acc: 0.0000e+00\n",
      "Epoch 47/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2696 - val_acc: 0.0000e+00\n",
      "Epoch 48/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2961 - val_acc: 0.0000e+00\n",
      "Epoch 49/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.3205 - val_acc: 0.0000e+00\n",
      "Epoch 50/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3250 - val_acc: 0.0000e+00\n",
      "Epoch 51/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.3046 - val_acc: 0.0000e+00\n",
      "Epoch 52/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2853 - val_acc: 0.0000e+00\n",
      "Epoch 53/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 54/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2927 - val_acc: 0.0000e+00\n",
      "Epoch 55/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2837 - val_acc: 0.0000e+00\n",
      "Epoch 56/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2804 - val_acc: 0.0000e+00\n",
      "Epoch 57/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2699 - val_acc: 0.0000e+00\n",
      "Epoch 58/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2654 - val_acc: 0.0000e+00\n",
      "Epoch 59/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.2490 - val_acc: 0.0000e+00\n",
      "Epoch 60/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2549 - val_acc: 0.0000e+00\n",
      "Epoch 61/750\n",
      "884/884 [==============================] - 1s 943us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.2659 - val_acc: 0.0000e+00\n",
      "Epoch 62/750\n",
      "884/884 [==============================] - 1s 966us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 63/750\n",
      "884/884 [==============================] - 1s 974us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.3044 - val_acc: 0.0000e+00\n",
      "Epoch 64/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2723 - val_acc: 0.0000e+00\n",
      "Epoch 65/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2764 - val_acc: 0.0000e+00\n",
      "Epoch 66/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2507 - val_acc: 0.0000e+00\n",
      "Epoch 67/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2200 - val_acc: 0.0000e+00\n",
      "Epoch 68/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2041 - val_acc: 0.0000e+00\n",
      "Epoch 69/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1894 - val_acc: 0.0000e+00\n",
      "Epoch 70/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.2070 - val_acc: 0.0000e+00\n",
      "Epoch 71/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.2246 - val_acc: 0.0000e+00\n",
      "Epoch 72/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2278 - val_acc: 0.0000e+00\n",
      "Epoch 73/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2547 - val_acc: 0.0000e+00\n",
      "Epoch 74/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 75/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.2426 - val_acc: 0.0000e+00\n",
      "Epoch 76/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.2101 - val_acc: 0.0000e+00\n",
      "Epoch 77/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2287 - val_acc: 0.0000e+00\n",
      "Epoch 78/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.2614 - val_acc: 0.0000e+00\n",
      "Epoch 79/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2368 - val_acc: 0.0000e+00\n",
      "Epoch 80/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0000e+00\n",
      "Epoch 81/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1861 - val_acc: 0.0000e+00\n",
      "Epoch 82/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2093 - val_acc: 0.0000e+00\n",
      "Epoch 83/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2625 - val_acc: 0.0000e+00\n",
      "Epoch 84/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2902 - val_acc: 0.0000e+00\n",
      "Epoch 85/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2423 - val_acc: 0.0000e+00\n",
      "Epoch 86/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2390 - val_acc: 0.0000e+00\n",
      "Epoch 87/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.2470 - val_acc: 0.0000e+00\n",
      "Epoch 88/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.2572 - val_acc: 0.0000e+00\n",
      "Epoch 89/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.2572 - val_acc: 0.0000e+00\n",
      "Epoch 90/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1920 - val_acc: 0.0000e+00\n",
      "Epoch 91/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1977 - val_acc: 0.0000e+00\n",
      "Epoch 92/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1989 - val_acc: 0.0000e+00\n",
      "Epoch 93/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1905 - val_acc: 0.0000e+00\n",
      "Epoch 94/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1753 - val_acc: 0.0000e+00\n",
      "Epoch 95/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 96/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1696 - val_acc: 0.0000e+00\n",
      "Epoch 97/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
      "Epoch 98/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 99/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 100/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 101/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 102/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0808 - val_acc: 0.0000e+00\n",
      "Epoch 103/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 104/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 105/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 106/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0469 - val_acc: 0.0064\n",
      "Epoch 107/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0619 - val_acc: 0.0000e+00\n",
      "Epoch 108/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0440 - val_acc: 0.0064\n",
      "Epoch 109/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0426 - val_acc: 0.0064\n",
      "Epoch 110/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0525 - val_acc: 0.0064\n",
      "Epoch 111/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0506 - val_acc: 0.0064\n",
      "Epoch 112/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0337 - val_acc: 0.0064\n",
      "Epoch 113/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 114/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0326 - val_acc: 0.0064\n",
      "Epoch 115/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0397 - val_acc: 0.0064\n",
      "Epoch 116/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 117/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0279 - val_acc: 0.0064\n",
      "Epoch 118/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0308 - val_acc: 0.0064\n",
      "Epoch 119/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 120/750\n",
      "884/884 [==============================] - 1s 999us/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0064\n",
      "Epoch 121/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0238 - val_acc: 0.0064\n",
      "Epoch 122/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0250 - val_acc: 0.0064\n",
      "Epoch 123/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0384 - val_acc: 0.0064\n",
      "Epoch 124/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0311 - val_acc: 0.0064\n",
      "Epoch 125/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0376 - val_acc: 0.0064\n",
      "Epoch 126/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
      "Epoch 127/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0299 - val_acc: 0.0064\n",
      "Epoch 128/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0308 - val_acc: 0.0064\n",
      "Epoch 129/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0273 - val_acc: 0.0064\n",
      "Epoch 130/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0212 - val_acc: 0.0064\n",
      "Epoch 131/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0200 - val_acc: 0.0064\n",
      "Epoch 132/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0220 - val_acc: 0.0064\n",
      "Epoch 133/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0191 - val_acc: 0.0064\n",
      "Epoch 134/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0203 - val_acc: 0.0064\n",
      "Epoch 135/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0214 - val_acc: 0.0064\n",
      "Epoch 136/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 137/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0228 - val_acc: 0.0064\n",
      "Epoch 138/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.0011 - val_loss: 0.0217 - val_acc: 0.0064\n",
      "Epoch 139/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0325 - val_acc: 0.0064\n",
      "Epoch 140/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 141/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0690 - val_acc: 0.0064\n",
      "Epoch 142/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0490 - val_acc: 0.0064\n",
      "Epoch 143/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 144/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0064\n",
      "Epoch 145/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0064\n",
      "Epoch 146/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0064\n",
      "Epoch 147/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0064\n",
      "Epoch 148/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0064\n",
      "Epoch 149/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0064\n",
      "Epoch 150/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0064\n",
      "Epoch 151/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0922 - val_acc: 0.0064\n",
      "Epoch 152/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0064\n",
      "Epoch 153/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0064\n",
      "Epoch 154/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0064\n",
      "Epoch 155/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.1166 - val_acc: 0.0064\n",
      "Epoch 156/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 157/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.1311 - val_acc: 0.0064\n",
      "Epoch 158/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1266 - val_acc: 0.0064\n",
      "Epoch 159/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0268 - val_acc: 0.0064\n",
      "Epoch 160/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0243 - val_acc: 0.0064\n",
      "Epoch 161/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0230 - val_acc: 0.0064\n",
      "Epoch 162/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0344 - val_acc: 0.0064\n",
      "Epoch 163/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.0011 - val_loss: 0.0209 - val_acc: 0.0064\n",
      "Epoch 164/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 165/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0281 - val_acc: 0.0064\n",
      "Epoch 166/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0239 - val_acc: 0.0064\n",
      "Epoch 167/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0456 - val_acc: 0.0064\n",
      "Epoch 168/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0252 - val_acc: 0.0064\n",
      "Epoch 169/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 170/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 171/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0278 - val_acc: 0.0064\n",
      "Epoch 172/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0238 - val_acc: 0.0064\n",
      "Epoch 173/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0261 - val_acc: 0.0064\n",
      "Epoch 174/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 175/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 176/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 177/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 178/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 179/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
      "Epoch 180/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 181/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.0011 - val_loss: 0.0246 - val_acc: 0.0064\n",
      "Epoch 182/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 183/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 184/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0272 - val_acc: 0.0064\n",
      "Epoch 185/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 186/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0274 - val_acc: 0.0064\n",
      "Epoch 187/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0306 - val_acc: 0.0064\n",
      "Epoch 188/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0383 - val_acc: 0.0064\n",
      "Epoch 189/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0458 - val_acc: 0.0000e+00\n",
      "Epoch 190/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0292 - val_acc: 0.0064\n",
      "Epoch 191/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0293 - val_acc: 0.0064\n",
      "Epoch 192/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 193/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 194/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0381 - val_acc: 0.0064\n",
      "Epoch 195/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0064\n",
      "Epoch 196/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 197/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0335 - val_acc: 0.0064\n",
      "Epoch 198/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.0011 - val_loss: 0.0357 - val_acc: 0.0064\n",
      "Epoch 199/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0310 - val_acc: 0.0064\n",
      "Epoch 200/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0385 - val_acc: 0.0064\n",
      "Epoch 201/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 202/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0353 - val_acc: 0.0064\n",
      "Epoch 203/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0298 - val_acc: 0.0064\n",
      "Epoch 204/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 205/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Epoch 206/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0392 - val_acc: 0.0064\n",
      "Epoch 207/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0064\n",
      "Epoch 208/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 209/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0327 - val_acc: 0.0064\n",
      "Epoch 210/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 211/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0354 - val_acc: 0.0064\n",
      "Epoch 212/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0333 - val_acc: 0.0064\n",
      "Epoch 213/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 214/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0842 - val_acc: 0.0064\n",
      "Epoch 215/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0064\n",
      "Epoch 216/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0805 - val_acc: 0.0064\n",
      "Epoch 217/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0064\n",
      "Epoch 218/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0064\n",
      "Epoch 219/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0064\n",
      "Epoch 220/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0468 - val_acc: 0.0064\n",
      "Epoch 221/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0064\n",
      "Epoch 222/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1244 - val_acc: 0.0064\n",
      "Epoch 223/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.1798 - val_acc: 0.0064\n",
      "Epoch 224/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1303 - val_acc: 0.0064\n",
      "Epoch 225/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.1731 - val_acc: 0.0064\n",
      "Epoch 226/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.2251 - val_acc: 0.0064\n",
      "Epoch 227/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0064\n",
      "Epoch 228/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0064\n",
      "Epoch 229/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 230/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0064\n",
      "Epoch 231/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0064\n",
      "Epoch 232/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.0522 - val_acc: 0.0064\n",
      "Epoch 233/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0064\n",
      "Epoch 234/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.2353 - val_acc: 0.0064\n",
      "Epoch 235/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0671 - val_acc: 0.0064\n",
      "Epoch 236/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0064\n",
      "Epoch 237/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0064\n",
      "Epoch 238/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0064\n",
      "Epoch 239/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0939 - val_acc: 0.0064\n",
      "Epoch 240/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 241/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 242/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0374 - val_acc: 0.0064\n",
      "Epoch 243/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0759 - val_acc: 0.0064\n",
      "Epoch 244/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0064\n",
      "Epoch 245/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 246/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0428 - val_acc: 0.0064\n",
      "Epoch 247/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0330 - val_acc: 0.0064\n",
      "Epoch 248/750\n",
      "884/884 [==============================] - 1s 998us/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0336 - val_acc: 0.0064\n",
      "Epoch 249/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0434 - val_acc: 0.0064\n",
      "Epoch 250/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0347 - val_acc: 0.0064\n",
      "Epoch 251/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 252/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0064\n",
      "Epoch 253/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0064\n",
      "Epoch 254/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0535 - val_acc: 0.0064\n",
      "Epoch 255/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0482 - val_acc: 0.0064\n",
      "Epoch 256/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0989 - val_acc: 0.0064\n",
      "Epoch 257/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0064\n",
      "Epoch 258/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0064\n",
      "Epoch 259/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0064\n",
      "Epoch 260/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0064\n",
      "Epoch 261/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0064\n",
      "Epoch 262/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0064\n",
      "Epoch 263/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0667 - val_acc: 0.0064\n",
      "Epoch 264/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0064\n",
      "Epoch 265/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0543 - val_acc: 0.0064\n",
      "Epoch 266/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0633 - val_acc: 0.0064\n",
      "Epoch 267/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0407 - val_acc: 0.0064\n",
      "Epoch 268/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0370 - val_acc: 0.0064\n",
      "Epoch 269/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0332 - val_acc: 0.0064\n",
      "Epoch 270/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0305 - val_acc: 0.0064\n",
      "Epoch 271/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0364 - val_acc: 0.0064\n",
      "Epoch 272/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0464 - val_acc: 0.0064\n",
      "Epoch 273/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 274/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 275/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n",
      "Epoch 276/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0064\n",
      "Epoch 277/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 278/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.0011 - val_loss: 0.0483 - val_acc: 0.0064\n",
      "Epoch 279/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 280/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0367 - val_acc: 0.0064\n",
      "Epoch 281/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0551 - val_acc: 0.0064\n",
      "Epoch 282/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 283/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0064\n",
      "Epoch 284/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 285/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 286/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0853 - val_acc: 0.0064\n",
      "Epoch 287/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0475 - val_acc: 0.0064\n",
      "Epoch 288/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 289/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0637 - val_acc: 0.0064\n",
      "Epoch 290/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0064\n",
      "Epoch 291/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 292/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0640 - val_acc: 0.0064\n",
      "Epoch 293/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0609 - val_acc: 0.0064\n",
      "Epoch 294/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0505 - val_acc: 0.0064\n",
      "Epoch 295/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0064\n",
      "Epoch 296/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0436 - val_acc: 0.0064\n",
      "Epoch 297/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0064\n",
      "Epoch 298/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0691 - val_acc: 0.0064\n",
      "Epoch 299/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0408 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0064\n",
      "Epoch 301/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 302/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0064\n",
      "Epoch 303/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0064\n",
      "Epoch 304/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0665 - val_acc: 0.0064\n",
      "Epoch 305/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0478 - val_acc: 0.0064\n",
      "Epoch 306/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0064\n",
      "Epoch 307/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0064\n",
      "Epoch 308/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0479 - val_acc: 0.0064\n",
      "Epoch 309/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 310/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0517 - val_acc: 0.0064\n",
      "Epoch 311/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0572 - val_acc: 0.0064\n",
      "Epoch 312/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0064\n",
      "Epoch 313/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0466 - val_acc: 0.0064\n",
      "Epoch 314/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0064\n",
      "Epoch 315/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 316/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0389 - val_acc: 0.0064\n",
      "Epoch 317/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0064\n",
      "Epoch 318/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0377 - val_acc: 0.0064\n",
      "Epoch 319/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 320/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0064\n",
      "Epoch 321/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0554 - val_acc: 0.0064\n",
      "Epoch 322/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0360 - val_acc: 0.0064\n",
      "Epoch 323/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0608 - val_acc: 0.0064\n",
      "Epoch 324/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0463 - val_acc: 0.0064\n",
      "Epoch 325/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 326/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0064\n",
      "Epoch 327/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0490 - val_acc: 0.0064\n",
      "Epoch 328/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0320 - val_acc: 0.0064\n",
      "Epoch 329/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0337 - val_acc: 0.0064\n",
      "Epoch 330/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0351 - val_acc: 0.0064\n",
      "Epoch 331/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 332/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0487 - val_acc: 0.0064\n",
      "Epoch 333/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 334/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0492 - val_acc: 0.0064\n",
      "Epoch 335/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0064\n",
      "Epoch 336/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 337/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 338/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 339/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0391 - val_acc: 0.0064\n",
      "Epoch 340/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0499 - val_acc: 0.0064\n",
      "Epoch 341/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.0011 - val_loss: 0.0676 - val_acc: 0.0064\n",
      "Epoch 342/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0447 - val_acc: 0.0064\n",
      "Epoch 343/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0411 - val_acc: 0.0064\n",
      "Epoch 344/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0064\n",
      "Epoch 345/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0064\n",
      "Epoch 346/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1022 - val_acc: 0.0064\n",
      "Epoch 347/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0064\n",
      "Epoch 348/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0611 - val_acc: 0.0064\n",
      "Epoch 349/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 350/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.0011 - val_loss: 0.0685 - val_acc: 0.0064\n",
      "Epoch 351/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0323 - val_acc: 0.0064\n",
      "Epoch 352/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 353/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 354/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1487 - val_acc: 0.0064\n",
      "Epoch 355/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 356/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0429 - val_acc: 0.0064\n",
      "Epoch 357/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.2296 - val_acc: 0.0064\n",
      "Epoch 358/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0631 - val_acc: 0.0064\n",
      "Epoch 359/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0064\n",
      "Epoch 360/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 361/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0064\n",
      "Epoch 362/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0530 - val_acc: 0.0064\n",
      "Epoch 363/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1088 - val_acc: 0.0064\n",
      "Epoch 364/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0852 - val_acc: 0.0064\n",
      "Epoch 365/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0875 - val_acc: 0.0064\n",
      "Epoch 366/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1504 - val_acc: 0.0064\n",
      "Epoch 367/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1716 - val_acc: 0.0064\n",
      "Epoch 368/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1383 - val_acc: 0.0064\n",
      "Epoch 369/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.0011 - val_loss: 0.0409 - val_acc: 0.0064\n",
      "Epoch 370/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0453 - val_acc: 0.0064\n",
      "Epoch 371/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0548 - val_acc: 0.0064\n",
      "Epoch 372/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0064\n",
      "Epoch 373/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0737 - val_acc: 0.0064\n",
      "Epoch 374/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0402 - val_acc: 0.0064\n",
      "Epoch 375/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1004 - val_acc: 0.0064\n",
      "Epoch 376/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1087 - val_acc: 0.0064\n",
      "Epoch 377/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0720 - val_acc: 0.0064\n",
      "Epoch 378/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 379/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1000 - val_acc: 0.0064\n",
      "Epoch 380/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0596 - val_acc: 0.0064\n",
      "Epoch 381/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0064\n",
      "Epoch 382/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
      "Epoch 383/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0064\n",
      "Epoch 384/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0495 - val_acc: 0.0000e+00\n",
      "Epoch 385/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0416 - val_acc: 0.0064\n",
      "Epoch 386/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0064\n",
      "Epoch 387/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0064\n",
      "Epoch 388/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0853 - val_acc: 0.0064\n",
      "Epoch 389/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1118 - val_acc: 0.0064\n",
      "Epoch 390/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.3276 - val_acc: 0.0000e+00\n",
      "Epoch 391/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0064\n",
      "Epoch 392/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1776 - val_acc: 0.0064\n",
      "Epoch 393/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.1679 - val_acc: 0.0064\n",
      "Epoch 394/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1509 - val_acc: 0.0064\n",
      "Epoch 395/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0064\n",
      "Epoch 396/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1496 - val_acc: 0.0064\n",
      "Epoch 397/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.2419 - val_acc: 0.0064\n",
      "Epoch 398/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.3176 - val_acc: 0.0000e+00\n",
      "Epoch 399/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.1740 - val_acc: 0.0064\n",
      "Epoch 400/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0486 - val_acc: 0.0064\n",
      "Epoch 401/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0359 - val_acc: 0.0064\n",
      "Epoch 402/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0814 - val_acc: 0.0064\n",
      "Epoch 403/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 404/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0648 - val_acc: 0.0064\n",
      "Epoch 405/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0589 - val_acc: 0.0064\n",
      "Epoch 406/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0636 - val_acc: 0.0064\n",
      "Epoch 407/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0433 - val_acc: 0.0064\n",
      "Epoch 408/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0446 - val_acc: 0.0064\n",
      "Epoch 409/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0313 - val_acc: 0.0064\n",
      "Epoch 410/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1795 - val_acc: 0.0000e+00\n",
      "Epoch 411/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.0011 - val_loss: 0.1135 - val_acc: 0.0000e+00\n",
      "Epoch 412/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0317 - val_acc: 0.0064\n",
      "Epoch 413/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0064\n",
      "Epoch 414/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 415/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 416/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.0011 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 417/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0295 - val_acc: 0.0064\n",
      "Epoch 418/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0401 - val_acc: 0.0064\n",
      "Epoch 419/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.0247 - val_acc: 0.0064\n",
      "Epoch 420/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0445 - val_acc: 0.0064\n",
      "Epoch 421/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0935 - val_acc: 0.0064\n",
      "Epoch 422/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.0011 - val_loss: 0.1053 - val_acc: 0.0064\n",
      "Epoch 423/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 424/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0596 - val_acc: 0.0000e+00\n",
      "Epoch 425/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0628 - val_acc: 0.0064\n",
      "Epoch 426/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0496 - val_acc: 0.0064\n",
      "Epoch 427/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 428/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0744 - val_acc: 0.0064\n",
      "Epoch 429/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0879 - val_acc: 0.0064\n",
      "Epoch 430/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0064\n",
      "Epoch 431/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0064\n",
      "Epoch 432/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0064\n",
      "Epoch 433/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0711 - val_acc: 0.0064\n",
      "Epoch 434/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0948 - val_acc: 0.0064\n",
      "Epoch 435/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1229 - val_acc: 0.0064\n",
      "Epoch 436/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0926 - val_acc: 0.0064\n",
      "Epoch 437/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0064\n",
      "Epoch 438/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0510 - val_acc: 0.0064\n",
      "Epoch 439/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1250 - val_acc: 0.0064\n",
      "Epoch 440/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0064\n",
      "Epoch 441/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1085 - val_acc: 0.0064\n",
      "Epoch 442/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0849 - val_acc: 0.0064\n",
      "Epoch 443/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1252 - val_acc: 0.0064\n",
      "Epoch 444/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1813 - val_acc: 0.0064\n",
      "Epoch 445/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0991 - val_acc: 0.0000e+00\n",
      "Epoch 446/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1294 - val_acc: 0.0064\n",
      "Epoch 447/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0660 - val_acc: 0.0064\n",
      "Epoch 448/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 449/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1450 - val_acc: 0.0064\n",
      "Epoch 450/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1571 - val_acc: 0.0064\n",
      "Epoch 451/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.0011 - val_loss: 0.1130 - val_acc: 0.0064\n",
      "Epoch 452/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.0669 - val_acc: 0.0064\n",
      "Epoch 453/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1034 - val_acc: 0.0064\n",
      "Epoch 454/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1739 - val_acc: 0.0064\n",
      "Epoch 455/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.2252 - val_acc: 0.0064\n",
      "Epoch 456/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.0011 - val_loss: 0.0980 - val_acc: 0.0064\n",
      "Epoch 457/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1601 - val_acc: 0.0064\n",
      "Epoch 458/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0944 - val_acc: 0.0064\n",
      "Epoch 459/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0934 - val_acc: 0.0064\n",
      "Epoch 460/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.3171 - val_acc: 0.0000e+00\n",
      "Epoch 461/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0064\n",
      "Epoch 462/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.2127 - val_acc: 0.0064\n",
      "Epoch 463/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1646 - val_acc: 0.0064\n",
      "Epoch 464/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1630 - val_acc: 0.0064\n",
      "Epoch 465/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0568 - val_acc: 0.0064\n",
      "Epoch 466/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0064\n",
      "Epoch 467/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0862 - val_acc: 0.0064\n",
      "Epoch 468/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1474 - val_acc: 0.0064\n",
      "Epoch 469/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.0011 - val_loss: 0.1291 - val_acc: 0.0064\n",
      "Epoch 470/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0064\n",
      "Epoch 471/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1328 - val_acc: 0.0064\n",
      "Epoch 472/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1029 - val_acc: 0.0064\n",
      "Epoch 473/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1275 - val_acc: 0.0064\n",
      "Epoch 474/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0064\n",
      "Epoch 475/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.2502 - val_acc: 0.0000e+00\n",
      "Epoch 476/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2186 - val_acc: 0.0000e+00\n",
      "Epoch 477/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0064\n",
      "Epoch 478/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.1536 - val_acc: 0.0064\n",
      "Epoch 479/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0064\n",
      "Epoch 480/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0481 - val_acc: 0.0064\n",
      "Epoch 481/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0447 - val_acc: 0.0064\n",
      "Epoch 482/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0905 - val_acc: 0.0064\n",
      "Epoch 483/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0064\n",
      "Epoch 484/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0327 - val_acc: 0.0064\n",
      "Epoch 485/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0064\n",
      "Epoch 486/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1059 - val_acc: 0.0064\n",
      "Epoch 487/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0987 - val_acc: 0.0064\n",
      "Epoch 488/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1145 - val_acc: 0.0064\n",
      "Epoch 489/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0064\n",
      "Epoch 490/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.2512 - val_acc: 0.0000e+00\n",
      "Epoch 491/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1758 - val_acc: 0.0064\n",
      "Epoch 492/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0064\n",
      "Epoch 493/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0240 - val_acc: 0.0064\n",
      "Epoch 494/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.0011 - val_loss: 0.1926 - val_acc: 0.0064\n",
      "Epoch 495/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0064\n",
      "Epoch 496/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0064\n",
      "Epoch 497/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0064\n",
      "Epoch 498/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0064\n",
      "Epoch 499/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.0011 - val_loss: 0.1595 - val_acc: 0.0064\n",
      "Epoch 500/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1272 - val_acc: 0.0064\n",
      "Epoch 501/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0406 - val_acc: 0.0064\n",
      "Epoch 502/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0064\n",
      "Epoch 503/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0064\n",
      "Epoch 504/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1528 - val_acc: 0.0064\n",
      "Epoch 505/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0265 - val_acc: 0.0064\n",
      "Epoch 506/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0523 - val_acc: 0.0064\n",
      "Epoch 507/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1179 - val_acc: 0.0064\n",
      "Epoch 508/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1311 - val_acc: 0.0064\n",
      "Epoch 509/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 510/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.1500 - val_acc: 0.0064\n",
      "Epoch 511/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.0011 - val_loss: 0.1239 - val_acc: 0.0064\n",
      "Epoch 512/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0064\n",
      "Epoch 513/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1281 - val_acc: 0.0064\n",
      "Epoch 514/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0664 - val_acc: 0.0064\n",
      "Epoch 515/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0853 - val_acc: 0.0064\n",
      "Epoch 516/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0064\n",
      "Epoch 517/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1401 - val_acc: 0.0064\n",
      "Epoch 518/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0064\n",
      "Epoch 519/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1194 - val_acc: 0.0064\n",
      "Epoch 520/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0064\n",
      "Epoch 521/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0889 - val_acc: 0.0064\n",
      "Epoch 522/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0064\n",
      "Epoch 523/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.1348 - val_acc: 0.0064\n",
      "Epoch 524/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0816 - val_acc: 0.0064\n",
      "Epoch 525/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0430 - val_acc: 0.0064\n",
      "Epoch 526/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0732 - val_acc: 0.0064\n",
      "Epoch 527/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0444 - val_acc: 0.0064\n",
      "Epoch 528/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0617 - val_acc: 0.0064\n",
      "Epoch 529/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.1284 - val_acc: 0.0064\n",
      "Epoch 530/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1138 - val_acc: 0.0064\n",
      "Epoch 531/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0518 - val_acc: 0.0064\n",
      "Epoch 532/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0380 - val_acc: 0.0064\n",
      "Epoch 533/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1009 - val_acc: 0.0064\n",
      "Epoch 534/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0064\n",
      "Epoch 535/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0509 - val_acc: 0.0064\n",
      "Epoch 536/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0644 - val_acc: 0.0064\n",
      "Epoch 537/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0064\n",
      "Epoch 538/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0427 - val_acc: 0.0064\n",
      "Epoch 539/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 540/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0571 - val_acc: 0.0064\n",
      "Epoch 542/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0484 - val_acc: 0.0064\n",
      "Epoch 543/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0410 - val_acc: 0.0064\n",
      "Epoch 544/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0064\n",
      "Epoch 545/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.0011 - val_loss: 0.0721 - val_acc: 0.0064\n",
      "Epoch 546/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0904 - val_acc: 0.0064\n",
      "Epoch 547/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0064\n",
      "Epoch 548/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0999 - val_acc: 0.0064\n",
      "Epoch 549/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1083 - val_acc: 0.0064\n",
      "Epoch 550/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1154 - val_acc: 0.0064\n",
      "Epoch 551/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0064\n",
      "Epoch 552/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0064\n",
      "Epoch 553/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.1098 - val_acc: 0.0064\n",
      "Epoch 554/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0923 - val_acc: 0.0064\n",
      "Epoch 555/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.0011 - val_loss: 0.0740 - val_acc: 0.0064\n",
      "Epoch 556/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0064\n",
      "Epoch 557/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0064\n",
      "Epoch 558/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0579 - val_acc: 0.0064\n",
      "Epoch 559/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0745 - val_acc: 0.0064\n",
      "Epoch 560/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0528 - val_acc: 0.0064\n",
      "Epoch 561/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0476 - val_acc: 0.0064\n",
      "Epoch 562/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0612 - val_acc: 0.0064\n",
      "Epoch 563/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0064\n",
      "Epoch 564/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0649 - val_acc: 0.0064\n",
      "Epoch 565/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0570 - val_acc: 0.0064\n",
      "Epoch 566/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0462 - val_acc: 0.0064\n",
      "Epoch 567/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0995 - val_acc: 0.0064\n",
      "Epoch 568/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0699 - val_acc: 0.0064\n",
      "Epoch 569/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0658 - val_acc: 0.0064\n",
      "Epoch 570/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0558 - val_acc: 0.0064\n",
      "Epoch 571/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0064\n",
      "Epoch 572/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 573/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0524 - val_acc: 0.0064\n",
      "Epoch 574/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0439 - val_acc: 0.0064\n",
      "Epoch 575/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.0011 - val_loss: 0.0695 - val_acc: 0.0064\n",
      "Epoch 576/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0672 - val_acc: 0.0064\n",
      "Epoch 577/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0064\n",
      "Epoch 578/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0422 - val_acc: 0.0064\n",
      "Epoch 579/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0556 - val_acc: 0.0064\n",
      "Epoch 580/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.0011 - val_loss: 0.0258 - val_acc: 0.0064\n",
      "Epoch 581/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 582/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0238 - val_acc: 0.0064\n",
      "Epoch 583/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0521 - val_acc: 0.0064\n",
      "Epoch 584/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0697 - val_acc: 0.0064\n",
      "Epoch 585/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0579 - val_acc: 0.0064\n",
      "Epoch 586/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0413 - val_acc: 0.0064\n",
      "Epoch 587/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0064\n",
      "Epoch 588/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0815 - val_acc: 0.0064\n",
      "Epoch 589/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0611 - val_acc: 0.0064\n",
      "Epoch 590/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0624 - val_acc: 0.0064\n",
      "Epoch 591/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0501 - val_acc: 0.0064\n",
      "Epoch 592/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0399 - val_acc: 0.0064\n",
      "Epoch 593/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0372 - val_acc: 0.0064\n",
      "Epoch 594/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0414 - val_acc: 0.0064\n",
      "Epoch 595/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0498 - val_acc: 0.0064\n",
      "Epoch 596/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0064\n",
      "Epoch 597/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0064\n",
      "Epoch 598/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0627 - val_acc: 0.0064\n",
      "Epoch 599/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0601 - val_acc: 0.0064\n",
      "Epoch 600/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0064\n",
      "Epoch 601/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0064\n",
      "Epoch 602/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0064\n",
      "Epoch 603/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1342 - val_acc: 0.0064\n",
      "Epoch 604/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1106 - val_acc: 0.0064\n",
      "Epoch 605/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0585 - val_acc: 0.0064\n",
      "Epoch 606/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0612 - val_acc: 0.0064\n",
      "Epoch 607/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 608/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.1048 - val_acc: 0.0064\n",
      "Epoch 609/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 610/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0938 - val_acc: 0.0064\n",
      "Epoch 611/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0730 - val_acc: 0.0064\n",
      "Epoch 612/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0588 - val_acc: 0.0064\n",
      "Epoch 613/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0064\n",
      "Epoch 614/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0064\n",
      "Epoch 615/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0064\n",
      "Epoch 616/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 617/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.0011 - val_loss: 0.0881 - val_acc: 0.0064\n",
      "Epoch 618/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 619/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 620/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0858 - val_acc: 0.0064\n",
      "Epoch 621/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1102 - val_acc: 0.0000e+00\n",
      "Epoch 622/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.0011 - val_loss: 0.0451 - val_acc: 0.0064\n",
      "Epoch 623/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0761 - val_acc: 0.0064\n",
      "Epoch 624/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0650 - val_acc: 0.0064\n",
      "Epoch 625/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1282 - val_acc: 0.0064\n",
      "Epoch 626/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.0972 - val_acc: 0.0064\n",
      "Epoch 627/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0064\n",
      "Epoch 628/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.2032 - val_acc: 0.0064\n",
      "Epoch 629/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0789 - val_acc: 0.0064\n",
      "Epoch 630/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0064\n",
      "Epoch 631/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0420 - val_acc: 0.0064\n",
      "Epoch 632/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1058 - val_acc: 0.0064\n",
      "Epoch 633/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0064\n",
      "Epoch 634/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1091 - val_acc: 0.0064\n",
      "Epoch 635/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.2292 - val_acc: 0.0000e+00\n",
      "Epoch 636/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0412 - val_acc: 0.0064\n",
      "Epoch 637/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0618 - val_acc: 0.0064\n",
      "Epoch 638/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0577 - val_acc: 0.0064\n",
      "Epoch 639/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0000e+00\n",
      "Epoch 640/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 641/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0064\n",
      "Epoch 642/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.2109 - val_acc: 0.0000e+00\n",
      "Epoch 643/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 644/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 645/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1433 - val_acc: 0.0000e+00\n",
      "Epoch 646/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 647/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8981e-04 - acc: 0.0011 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
      "Epoch 648/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0000e+00\n",
      "Epoch 649/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0629 - val_acc: 0.0000e+00\n",
      "Epoch 650/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0622 - val_acc: 0.0064\n",
      "Epoch 651/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 652/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 653/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0064\n",
      "Epoch 654/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0988 - val_acc: 0.0064\n",
      "Epoch 655/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0638 - val_acc: 0.0064\n",
      "Epoch 656/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0565 - val_acc: 0.0064\n",
      "Epoch 657/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0493 - val_acc: 0.0064\n",
      "Epoch 658/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0064\n",
      "Epoch 659/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0756 - val_acc: 0.0064\n",
      "Epoch 660/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
      "Epoch 661/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0514 - val_acc: 0.0064\n",
      "Epoch 662/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
      "Epoch 663/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 664/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1305 - val_acc: 0.0000e+00\n",
      "Epoch 665/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0965 - val_acc: 0.0064\n",
      "Epoch 666/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0064\n",
      "Epoch 667/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0895 - val_acc: 0.0000e+00\n",
      "Epoch 668/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 669/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1710 - val_acc: 0.0000e+00\n",
      "Epoch 670/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0985 - val_acc: 0.0000e+00\n",
      "Epoch 671/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.0011 - val_loss: 0.0992 - val_acc: 0.0000e+00\n",
      "Epoch 672/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 673/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1046 - val_acc: 0.0000e+00\n",
      "Epoch 674/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.6144e-04 - acc: 0.0011 - val_loss: 0.1211 - val_acc: 0.0000e+00\n",
      "Epoch 675/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.2095 - val_acc: 0.0000e+00\n",
      "Epoch 676/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.2117 - val_acc: 0.0000e+00\n",
      "Epoch 677/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1923 - val_acc: 0.0000e+00\n",
      "Epoch 678/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1525 - val_acc: 0.0000e+00\n",
      "Epoch 679/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.3842e-04 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0064\n",
      "Epoch 680/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2786e-04 - acc: 0.0011 - val_loss: 0.0878 - val_acc: 0.0000e+00\n",
      "Epoch 681/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.2281 - val_acc: 0.0000e+00\n",
      "Epoch 682/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1905 - val_acc: 0.0000e+00\n",
      "Epoch 683/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8407e-04 - acc: 0.0011 - val_loss: 0.1899 - val_acc: 0.0000e+00\n",
      "Epoch 684/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.9047e-04 - acc: 0.0011 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
      "Epoch 685/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2445e-04 - acc: 0.0011 - val_loss: 0.2294 - val_acc: 0.0000e+00\n",
      "Epoch 686/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0459 - val_acc: 0.0064\n",
      "Epoch 687/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 688/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0405 - val_acc: 0.0064\n",
      "Epoch 689/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.0328e-04 - acc: 0.0011 - val_loss: 0.0417 - val_acc: 0.0064\n",
      "Epoch 690/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.4178e-04 - acc: 0.0011 - val_loss: 0.1798 - val_acc: 0.0000e+00\n",
      "Epoch 691/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.4521e-04 - acc: 0.0011 - val_loss: 0.1883 - val_acc: 0.0000e+00\n",
      "Epoch 692/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9814e-04 - acc: 0.0011 - val_loss: 0.2263 - val_acc: 0.0000e+00\n",
      "Epoch 693/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1625 - val_acc: 0.0000e+00\n",
      "Epoch 694/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.0925 - val_acc: 0.0064\n",
      "Epoch 695/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.9964e-04 - acc: 0.0011 - val_loss: 0.0538 - val_acc: 0.0064\n",
      "Epoch 696/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.7760e-04 - acc: 0.0011 - val_loss: 0.0893 - val_acc: 0.0000e+00\n",
      "Epoch 697/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.5698e-04 - acc: 0.0011 - val_loss: 0.0630 - val_acc: 0.0064\n",
      "Epoch 698/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.7964e-04 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0064\n",
      "Epoch 699/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8366e-04 - acc: 0.0011 - val_loss: 0.2153 - val_acc: 0.0000e+00\n",
      "Epoch 700/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 701/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.5448e-04 - acc: 0.0011 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
      "Epoch 702/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9695e-04 - acc: 0.0011 - val_loss: 0.1200 - val_acc: 0.0000e+00\n",
      "Epoch 703/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.3115e-04 - acc: 0.0011 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
      "Epoch 704/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.7888e-04 - acc: 0.0011 - val_loss: 0.0583 - val_acc: 0.0064\n",
      "Epoch 705/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8490e-04 - acc: 0.0011 - val_loss: 0.1358 - val_acc: 0.0000e+00\n",
      "Epoch 706/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9015e-04 - acc: 0.0011 - val_loss: 0.1843 - val_acc: 0.0000e+00\n",
      "Epoch 707/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.8740e-04 - acc: 0.0011 - val_loss: 0.1470 - val_acc: 0.0000e+00\n",
      "Epoch 708/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.9509e-04 - acc: 0.0011 - val_loss: 0.0856 - val_acc: 0.0000e+00\n",
      "Epoch 709/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.6185e-04 - acc: 0.0011 - val_loss: 0.2212 - val_acc: 0.0000e+00\n",
      "Epoch 710/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0064\n",
      "Epoch 711/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8333e-04 - acc: 0.0011 - val_loss: 0.0540 - val_acc: 0.0064\n",
      "Epoch 712/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.1888e-04 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
      "Epoch 713/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2312e-04 - acc: 0.0011 - val_loss: 0.0979 - val_acc: 0.0000e+00\n",
      "Epoch 714/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4068e-04 - acc: 0.0011 - val_loss: 0.1299 - val_acc: 0.0000e+00\n",
      "Epoch 715/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.2691e-04 - acc: 0.0011 - val_loss: 0.1248 - val_acc: 0.0000e+00\n",
      "Epoch 716/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.6039e-04 - acc: 0.0011 - val_loss: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 717/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.8021e-04 - acc: 0.0011 - val_loss: 0.0808 - val_acc: 0.0064\n",
      "Epoch 718/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.0035e-04 - acc: 0.0011 - val_loss: 0.0575 - val_acc: 0.0064\n",
      "Epoch 719/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5192e-04 - acc: 0.0011 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 720/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.0503e-04 - acc: 0.0011 - val_loss: 0.0937 - val_acc: 0.0064\n",
      "Epoch 721/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.1417e-04 - acc: 0.0011 - val_loss: 0.0773 - val_acc: 0.0064\n",
      "Epoch 722/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.7059e-04 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0064\n",
      "Epoch 723/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.3322e-04 - acc: 0.0011 - val_loss: 0.1928 - val_acc: 0.0000e+00\n",
      "Epoch 724/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8498e-04 - acc: 0.0011 - val_loss: 0.2225 - val_acc: 0.0000e+00\n",
      "Epoch 725/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.7481e-04 - acc: 0.0011 - val_loss: 0.0861 - val_acc: 0.0000e+00\n",
      "Epoch 726/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.9699e-04 - acc: 0.0011 - val_loss: 0.1270 - val_acc: 0.0000e+00\n",
      "Epoch 727/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.7096e-04 - acc: 0.0011 - val_loss: 0.2337 - val_acc: 0.0000e+00\n",
      "Epoch 728/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.5755e-04 - acc: 0.0011 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 729/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.2755e-04 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 730/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.9105e-04 - acc: 0.0011 - val_loss: 0.1551 - val_acc: 0.0000e+00\n",
      "Epoch 731/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4742e-04 - acc: 0.0011 - val_loss: 0.2728 - val_acc: 0.0000e+00\n",
      "Epoch 732/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5589e-04 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 733/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5149e-04 - acc: 0.0011 - val_loss: 0.1208 - val_acc: 0.0000e+00\n",
      "Epoch 734/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.5401e-04 - acc: 0.0011 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
      "Epoch 735/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.6362e-04 - acc: 0.0011 - val_loss: 0.1990 - val_acc: 0.0000e+00\n",
      "Epoch 736/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.5525e-04 - acc: 0.0011 - val_loss: 0.2068 - val_acc: 0.0000e+00\n",
      "Epoch 737/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.1232e-04 - acc: 0.0011 - val_loss: 0.1245 - val_acc: 0.0000e+00\n",
      "Epoch 738/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.6138e-04 - acc: 0.0011 - val_loss: 0.2785 - val_acc: 0.0000e+00\n",
      "Epoch 739/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4701e-04 - acc: 0.0011 - val_loss: 0.1460 - val_acc: 0.0000e+00\n",
      "Epoch 740/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8677e-04 - acc: 0.0011 - val_loss: 0.2767 - val_acc: 0.0000e+00\n",
      "Epoch 741/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.3100e-04 - acc: 0.0011 - val_loss: 0.2556 - val_acc: 0.0000e+00\n",
      "Epoch 742/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.9881e-04 - acc: 0.0011 - val_loss: 0.2026 - val_acc: 0.0000e+00\n",
      "Epoch 743/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 7.9943e-04 - acc: 0.0011 - val_loss: 0.2111 - val_acc: 0.0000e+00\n",
      "Epoch 744/750\n",
      "884/884 [==============================] - 1s 998us/step - loss: 8.4887e-04 - acc: 0.0011 - val_loss: 0.2149 - val_acc: 0.0000e+00\n",
      "Epoch 745/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 9.1897e-04 - acc: 0.0011 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 746/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.2436 - val_acc: 0.0000e+00\n",
      "Epoch 747/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.0011 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 748/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8291e-04 - acc: 0.0011 - val_loss: 0.2478 - val_acc: 0.0000e+00\n",
      "Epoch 749/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.8625e-04 - acc: 0.0011 - val_loss: 0.2457 - val_acc: 0.0000e+00\n",
      "Epoch 750/750\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 8.4249e-04 - acc: 0.0011 - val_loss: 0.2507 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#do so\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 750\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "dropout = 0.2\n",
    "model_path = 'epoch_test.h5'\n",
    "history = see_history(df, seq_length, fut_point, train_split, neurons, dropout, epochs, batch_size, validation_split,\n",
    "                     model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.21773967786859244,\n",
       "  0.2040790221056877,\n",
       "  0.22132996956889445,\n",
       "  0.21240177932075965,\n",
       "  0.2223886466370179,\n",
       "  0.22437996913989386,\n",
       "  0.24079938614979768,\n",
       "  0.2546698502623118,\n",
       "  0.23038051009942323,\n",
       "  0.2308641295784559,\n",
       "  0.24606414750600472,\n",
       "  0.24976456375458303,\n",
       "  0.27292584092953265,\n",
       "  0.2629669033564054,\n",
       "  0.2592347495448895,\n",
       "  0.27268831584698117,\n",
       "  0.2791194201279909,\n",
       "  0.26932291992199725,\n",
       "  0.2592453255485266,\n",
       "  0.24635906995106965,\n",
       "  0.2407879168406511,\n",
       "  0.2156013117577785,\n",
       "  0.26200704677746844,\n",
       "  0.29046001380834824,\n",
       "  0.26513622567439693,\n",
       "  0.27171278324646825,\n",
       "  0.28213503670233947,\n",
       "  0.2641317162376184,\n",
       "  0.2509617331700447,\n",
       "  0.24109248320261636,\n",
       "  0.2492522929723446,\n",
       "  0.27621900939788574,\n",
       "  0.28133344592956394,\n",
       "  0.3044768877518483,\n",
       "  0.30608795487727875,\n",
       "  0.29841735252203083,\n",
       "  0.3325141666409297,\n",
       "  0.3369232662595235,\n",
       "  0.3085466865927745,\n",
       "  0.30053871545272,\n",
       "  0.29048702388237685,\n",
       "  0.28513279136938924,\n",
       "  0.2825379404119956,\n",
       "  0.2809236962825824,\n",
       "  0.298991658557684,\n",
       "  0.2638520118899835,\n",
       "  0.2695878490041464,\n",
       "  0.296056044789461,\n",
       "  0.3205490251764273,\n",
       "  0.32498846623377925,\n",
       "  0.30456874557794666,\n",
       "  0.285302266287498,\n",
       "  0.29236612889247066,\n",
       "  0.2927302853801312,\n",
       "  0.2837032245901915,\n",
       "  0.28040547305956864,\n",
       "  0.26988356293011934,\n",
       "  0.26535299745125646,\n",
       "  0.2490237136490834,\n",
       "  0.25489834762918645,\n",
       "  0.26590692691313916,\n",
       "  0.2800975888967514,\n",
       "  0.30442478507757187,\n",
       "  0.27228513474647814,\n",
       "  0.27644309057639194,\n",
       "  0.25073397780458134,\n",
       "  0.2200302599141231,\n",
       "  0.20414514237871537,\n",
       "  0.18935077312665108,\n",
       "  0.2070402949093244,\n",
       "  0.22462464773502105,\n",
       "  0.22778031487877554,\n",
       "  0.2547214545118503,\n",
       "  0.2706220243603755,\n",
       "  0.24263946654704902,\n",
       "  0.21014025788276625,\n",
       "  0.22868265775151742,\n",
       "  0.26135082905873275,\n",
       "  0.23676186924179396,\n",
       "  0.17391583543175307,\n",
       "  0.1860732576594903,\n",
       "  0.20927433526286712,\n",
       "  0.2624668845763573,\n",
       "  0.2902399257589609,\n",
       "  0.24230532329051924,\n",
       "  0.2389742486560956,\n",
       "  0.24696859048727232,\n",
       "  0.2571670737786171,\n",
       "  0.2571620125419054,\n",
       "  0.19199943074431175,\n",
       "  0.19769963660301307,\n",
       "  0.19894849337064302,\n",
       "  0.19053507338349635,\n",
       "  0.17529467741648355,\n",
       "  0.1463657234532711,\n",
       "  0.16962145975767037,\n",
       "  0.1254235538534629,\n",
       "  0.09913737718493511,\n",
       "  0.12248845073657158,\n",
       "  0.11858456171093842,\n",
       "  0.08739605899422596,\n",
       "  0.08077840635982844,\n",
       "  0.08037397026633605,\n",
       "  0.08479933784558223,\n",
       "  0.06797701650514053,\n",
       "  0.04690207775013569,\n",
       "  0.06185063117971787,\n",
       "  0.043983601606809176,\n",
       "  0.042631383603199936,\n",
       "  0.05251030671672943,\n",
       "  0.050630503214704685,\n",
       "  0.033686268859757826,\n",
       "  0.042040991716277905,\n",
       "  0.03256679784196118,\n",
       "  0.03966395236933843,\n",
       "  0.03541062858242255,\n",
       "  0.02793747243972925,\n",
       "  0.030793169919305887,\n",
       "  0.03535431924347694,\n",
       "  0.02718501466398056,\n",
       "  0.023785947523533534,\n",
       "  0.02496870185654515,\n",
       "  0.038379865913436964,\n",
       "  0.031148844541838534,\n",
       "  0.03764598458432234,\n",
       "  0.054292042763569415,\n",
       "  0.02986823593099148,\n",
       "  0.030845567249716856,\n",
       "  0.02725625611268557,\n",
       "  0.02119299614181121,\n",
       "  0.019964760318637278,\n",
       "  0.02198022621898697,\n",
       "  0.019139170091455944,\n",
       "  0.02031320152589335,\n",
       "  0.02143512629211331,\n",
       "  0.022988847128521554,\n",
       "  0.022845440185987033,\n",
       "  0.021688605312449045,\n",
       "  0.03254200644695606,\n",
       "  0.044401345643191,\n",
       "  0.06904701969753473,\n",
       "  0.04902646713890135,\n",
       "  0.04785852586755004,\n",
       "  0.08483548498211,\n",
       "  0.09269595790940982,\n",
       "  0.0906207670386021,\n",
       "  0.1018763206517085,\n",
       "  0.08634224383590314,\n",
       "  0.13103921014146927,\n",
       "  0.08350161792567143,\n",
       "  0.09217153164820793,\n",
       "  0.09055773240442459,\n",
       "  0.09291042167788897,\n",
       "  0.09195678146221699,\n",
       "  0.11655936686274333,\n",
       "  0.07396987825632095,\n",
       "  0.13106398991285226,\n",
       "  0.12661282164164078,\n",
       "  0.026847208205323953,\n",
       "  0.024342430325654838,\n",
       "  0.022973444587431658,\n",
       "  0.03437572445433874,\n",
       "  0.020870009150642615,\n",
       "  0.029983969420218505,\n",
       "  0.028088180204996697,\n",
       "  0.023929101797059562,\n",
       "  0.045568702169335805,\n",
       "  0.025161140729697086,\n",
       "  0.029614553661443867,\n",
       "  0.03533399776101877,\n",
       "  0.027775314278327502,\n",
       "  0.023808856345474336,\n",
       "  0.026138981368440468,\n",
       "  0.04150448273867369,\n",
       "  0.08012834377586842,\n",
       "  0.03230716661812785,\n",
       "  0.03214682451186654,\n",
       "  0.06753305746958806,\n",
       "  0.0537026665913753,\n",
       "  0.03471090415349373,\n",
       "  0.02458154351916164,\n",
       "  0.03196269310175035,\n",
       "  0.038075149178695984,\n",
       "  0.027174182009333983,\n",
       "  0.0368879960778241,\n",
       "  0.027370740617744815,\n",
       "  0.03060771194167244,\n",
       "  0.038275330154320754,\n",
       "  0.04575790810542038,\n",
       "  0.02917799750008644,\n",
       "  0.029343157714137282,\n",
       "  0.03574128546274434,\n",
       "  0.037243018225313,\n",
       "  0.038070992805445805,\n",
       "  0.04022858217836191,\n",
       "  0.03298251740992642,\n",
       "  0.033484485848114275,\n",
       "  0.035714336581384905,\n",
       "  0.031047210551034182,\n",
       "  0.03848744480488583,\n",
       "  0.03321384403926249,\n",
       "  0.03534654911177663,\n",
       "  0.029845739792411525,\n",
       "  0.04110163841874172,\n",
       "  0.04526920472749342,\n",
       "  0.03918192088484573,\n",
       "  0.068018882535398,\n",
       "  0.04109079892842624,\n",
       "  0.03269289168290412,\n",
       "  0.03740630195571635,\n",
       "  0.03544855426447705,\n",
       "  0.03334549058061571,\n",
       "  0.044428964551442705,\n",
       "  0.08422487670890032,\n",
       "  0.09371287449716757,\n",
       "  0.0804708725354897,\n",
       "  0.05485280881373164,\n",
       "  0.08312752591565442,\n",
       "  0.07014023073805639,\n",
       "  0.04678733248072557,\n",
       "  0.08443027583715053,\n",
       "  0.12441478378306596,\n",
       "  0.17980177867680025,\n",
       "  0.1302503309188745,\n",
       "  0.1730529515980146,\n",
       "  0.22506423495136774,\n",
       "  0.11689342477191718,\n",
       "  0.05590399138581676,\n",
       "  0.033162158752719946,\n",
       "  0.056764943686385565,\n",
       "  0.09284857445611404,\n",
       "  0.052215630224404425,\n",
       "  0.07118716946420953,\n",
       "  0.23525988950561255,\n",
       "  0.06714133861570214,\n",
       "  0.07265697336660172,\n",
       "  0.07828007875464092,\n",
       "  0.11345930290050231,\n",
       "  0.09394628933081642,\n",
       "  0.039145895232183814,\n",
       "  0.04171127712545104,\n",
       "  0.03738911081559192,\n",
       "  0.07594771517249636,\n",
       "  0.07597199343861295,\n",
       "  0.0480658055927891,\n",
       "  0.04281592465793857,\n",
       "  0.03303138450838816,\n",
       "  0.03361925567524173,\n",
       "  0.04340786819991011,\n",
       "  0.03468471600745733,\n",
       "  0.037242333142039105,\n",
       "  0.04019603092605487,\n",
       "  0.11063733030683719,\n",
       "  0.05352619903472563,\n",
       "  0.04824128908176835,\n",
       "  0.09892054960036124,\n",
       "  0.05997907366149892,\n",
       "  0.05970514693464606,\n",
       "  0.07441400321654211,\n",
       "  0.08594287945650136,\n",
       "  0.08130809966212091,\n",
       "  0.04948130214157013,\n",
       "  0.0666720217678887,\n",
       "  0.07211592043630588,\n",
       "  0.05426359496031625,\n",
       "  0.06334618401403229,\n",
       "  0.04065114020919188,\n",
       "  0.03695004576076873,\n",
       "  0.03321962447789235,\n",
       "  0.030459993853209875,\n",
       "  0.03636936788471081,\n",
       "  0.04635667353152083,\n",
       "  0.04170886554325429,\n",
       "  0.04062526997847435,\n",
       "  0.04075809255337868,\n",
       "  0.05471915560655105,\n",
       "  0.06847627631699045,\n",
       "  0.04832056545628569,\n",
       "  0.03665348439692305,\n",
       "  0.03674174287619117,\n",
       "  0.05509696365931095,\n",
       "  0.047491677571088076,\n",
       "  0.05375134458359426,\n",
       "  0.04810933734720143,\n",
       "  0.04748346180153581,\n",
       "  0.08533622806844039,\n",
       "  0.04745308020247672,\n",
       "  0.04814938866557219,\n",
       "  0.0637190200221271,\n",
       "  0.05415795653915176,\n",
       "  0.042950923584449366,\n",
       "  0.06400160526092617,\n",
       "  0.060897341021933615,\n",
       "  0.05051073325702395,\n",
       "  0.058256169816908926,\n",
       "  0.04355449833644506,\n",
       "  0.08119238541724208,\n",
       "  0.06909609058847985,\n",
       "  0.040842940421918265,\n",
       "  0.05630783394026833,\n",
       "  0.046257376682777435,\n",
       "  0.08647502111032224,\n",
       "  0.08449696872431116,\n",
       "  0.06647669600967604,\n",
       "  0.04782192797686618,\n",
       "  0.046165982189659886,\n",
       "  0.04373833965151929,\n",
       "  0.04790021837927783,\n",
       "  0.037210934228287675,\n",
       "  0.05165850981855048,\n",
       "  0.0571784751656919,\n",
       "  0.07452102767255826,\n",
       "  0.04658508616595123,\n",
       "  0.05820390890137507,\n",
       "  0.06218558106905757,\n",
       "  0.038946138062060646,\n",
       "  0.05542309551189343,\n",
       "  0.03774533548559516,\n",
       "  0.04810736063891687,\n",
       "  0.053827560399300776,\n",
       "  0.05544524710291089,\n",
       "  0.03604578887088559,\n",
       "  0.06084193548378654,\n",
       "  0.04632877201462785,\n",
       "  0.07395696437034087,\n",
       "  0.043263617891054124,\n",
       "  0.049040114208578296,\n",
       "  0.032035182373454936,\n",
       "  0.03369702327733812,\n",
       "  0.03506870702123986,\n",
       "  0.0419698992314247,\n",
       "  0.048746232313509934,\n",
       "  0.041272741802132286,\n",
       "  0.049157037471349425,\n",
       "  0.07247554756796513,\n",
       "  0.04505788171902681,\n",
       "  0.0415782715456608,\n",
       "  0.04271102540242749,\n",
       "  0.03907701290714053,\n",
       "  0.049870839748436056,\n",
       "  0.06759816316816096,\n",
       "  0.04473045657579906,\n",
       "  0.04110706408914083,\n",
       "  0.0835979893648376,\n",
       "  0.07723467038848843,\n",
       "  0.10220622531592082,\n",
       "  0.07849688929481766,\n",
       "  0.06105176328370968,\n",
       "  0.04165385737537573,\n",
       "  0.06845360885684688,\n",
       "  0.03225256199351488,\n",
       "  0.04438654487379468,\n",
       "  0.06720891691004045,\n",
       "  0.14867044458738887,\n",
       "  0.04220190247258124,\n",
       "  0.04286573540705901,\n",
       "  0.22962551599798295,\n",
       "  0.06305348208078589,\n",
       "  0.08827459383517122,\n",
       "  0.06716876668043625,\n",
       "  0.08793429144395468,\n",
       "  0.053048903994166695,\n",
       "  0.10884978306981233,\n",
       "  0.08515850427106787,\n",
       "  0.0874977585596916,\n",
       "  0.15044391842988822,\n",
       "  0.1715943556613265,\n",
       "  0.13832762910244176,\n",
       "  0.04092615198057432,\n",
       "  0.04530837919372015,\n",
       "  0.054795220446510196,\n",
       "  0.06317643054689352,\n",
       "  0.0737002015961573,\n",
       "  0.04024709079366846,\n",
       "  0.10036420638267046,\n",
       "  0.1087498274894479,\n",
       "  0.07203435446493901,\n",
       "  0.041747706870620065,\n",
       "  0.10002328665592732,\n",
       "  0.05956543473383555,\n",
       "  0.11846271778146426,\n",
       "  0.05097441418239704,\n",
       "  0.08585448405490471,\n",
       "  0.04949490231676744,\n",
       "  0.041605027010425545,\n",
       "  0.06816726068082528,\n",
       "  0.11687137038470843,\n",
       "  0.08528033018303223,\n",
       "  0.1118079613512143,\n",
       "  0.3275867477298165,\n",
       "  0.07965151163247916,\n",
       "  0.177631971008407,\n",
       "  0.16786368701081628,\n",
       "  0.1509242779455888,\n",
       "  0.07785355075238606,\n",
       "  0.1495959313156513,\n",
       "  0.2418600083925785,\n",
       "  0.3176341448695614,\n",
       "  0.1740175117380344,\n",
       "  0.04857801684202292,\n",
       "  0.035913038664521314,\n",
       "  0.08139130984170315,\n",
       "  0.07324832902313808,\n",
       "  0.06482694312356986,\n",
       "  0.05891210153603401,\n",
       "  0.06360597378359391,\n",
       "  0.043261573840983406,\n",
       "  0.044638095471339345,\n",
       "  0.031324307147700056,\n",
       "  0.17953273482047594,\n",
       "  0.11345658542062992,\n",
       "  0.03174011153765978,\n",
       "  0.05085409671450273,\n",
       "  0.04761587570493038,\n",
       "  0.06195234106137203,\n",
       "  0.09783595248770255,\n",
       "  0.029527995210045423,\n",
       "  0.04005643577338793,\n",
       "  0.024739055392833855,\n",
       "  0.04448064342618753,\n",
       "  0.09349822383135176,\n",
       "  0.1052715342778426,\n",
       "  0.06696338736667083,\n",
       "  0.05963281957575908,\n",
       "  0.06280012213839935,\n",
       "  0.049558694737079814,\n",
       "  0.04370044883436117,\n",
       "  0.07437413544035874,\n",
       "  0.0878888480604077,\n",
       "  0.07732026333896777,\n",
       "  0.08237463412567592,\n",
       "  0.09151921889338738,\n",
       "  0.07110204795996349,\n",
       "  0.09477412519164574,\n",
       "  0.12292837342008567,\n",
       "  0.09258536860728875,\n",
       "  0.10512815005122086,\n",
       "  0.05096000041335057,\n",
       "  0.12500391910091424,\n",
       "  0.07124946118356326,\n",
       "  0.10854583916564782,\n",
       "  0.0848804441973185,\n",
       "  0.1252327484007065,\n",
       "  0.18129411893777359,\n",
       "  0.09911301302222106,\n",
       "  0.12943206565120283,\n",
       "  0.06601017035352878,\n",
       "  0.07751443437658824,\n",
       "  0.14496003129543403,\n",
       "  0.15705501020718843,\n",
       "  0.11303659175068904,\n",
       "  0.06691453687082498,\n",
       "  0.10341471194838867,\n",
       "  0.17385931867055404,\n",
       "  0.22520024463152274,\n",
       "  0.09804405176486725,\n",
       "  0.16010413557673112,\n",
       "  0.09435156599069253,\n",
       "  0.09335262137345779,\n",
       "  0.317084092933398,\n",
       "  0.134793629631018,\n",
       "  0.21266698971008643,\n",
       "  0.16460132694397217,\n",
       "  0.16301138412493926,\n",
       "  0.05682023318532186,\n",
       "  0.08925561692852241,\n",
       "  0.08623720915653767,\n",
       "  0.14737822268253717,\n",
       "  0.12905956747440192,\n",
       "  0.07143174766156918,\n",
       "  0.13283253298738065,\n",
       "  0.10289551222171539,\n",
       "  0.12750020690071276,\n",
       "  0.15695738047361374,\n",
       "  0.25024604682738966,\n",
       "  0.21857057760159174,\n",
       "  0.13493104374561554,\n",
       "  0.15357873741632852,\n",
       "  0.08065512442053893,\n",
       "  0.048062010548817806,\n",
       "  0.0446759989628425,\n",
       "  0.09054393025162892,\n",
       "  0.14635795526779616,\n",
       "  0.03267868856588999,\n",
       "  0.08590424142013757,\n",
       "  0.10589049288477653,\n",
       "  0.09865796704513904,\n",
       "  0.11452321321345292,\n",
       "  0.16543453559279442,\n",
       "  0.25123543158555645,\n",
       "  0.17584050628237236,\n",
       "  0.08581693690174665,\n",
       "  0.024023829863812678,\n",
       "  0.19258932129312784,\n",
       "  0.07782019894474591,\n",
       "  0.11149079075608498,\n",
       "  0.10092809567084679,\n",
       "  0.14015760592734203,\n",
       "  0.15947031592711425,\n",
       "  0.1272136689378665,\n",
       "  0.04058675661396522,\n",
       "  0.11113717485792361,\n",
       "  0.07833720609927788,\n",
       "  0.15280809860007885,\n",
       "  0.026512114737087335,\n",
       "  0.05227477977482172,\n",
       "  0.11790200618979259,\n",
       "  0.1311264892992301,\n",
       "  0.05768469544366384,\n",
       "  0.14997583522628516,\n",
       "  0.12392233436306317,\n",
       "  0.08577734246276893,\n",
       "  0.128062419879895,\n",
       "  0.06641867181333976,\n",
       "  0.08530527152694188,\n",
       "  0.08030476538130106,\n",
       "  0.14011437273942506,\n",
       "  0.05907582398504019,\n",
       "  0.11941236653962196,\n",
       "  0.07951810946449256,\n",
       "  0.088902019823973,\n",
       "  0.07885777052396382,\n",
       "  0.13482470710117084,\n",
       "  0.08163791274031003,\n",
       "  0.04296970190719152,\n",
       "  0.07315184008807708,\n",
       "  0.044396812812640116,\n",
       "  0.061712659656619415,\n",
       "  0.12842222093007502,\n",
       "  0.11376915893589075,\n",
       "  0.05182161961849301,\n",
       "  0.03801566997590738,\n",
       "  0.10093501176780616,\n",
       "  0.0949764767040809,\n",
       "  0.05085891765805009,\n",
       "  0.06439263397493424,\n",
       "  0.07126743322572647,\n",
       "  0.04274831213152561,\n",
       "  0.10726331283027928,\n",
       "  0.06610928100939745,\n",
       "  0.0570916844627414,\n",
       "  0.04842624145870408,\n",
       "  0.04096502298489213,\n",
       "  0.08768342547596265,\n",
       "  0.07207589238308944,\n",
       "  0.09037427053762934,\n",
       "  0.07835569939552209,\n",
       "  0.09988682549924423,\n",
       "  0.10828137552986543,\n",
       "  0.11540600067625444,\n",
       "  0.1033427873865152,\n",
       "  0.08182261891376513,\n",
       "  0.1098464300067952,\n",
       "  0.09229934067489245,\n",
       "  0.0740330396220088,\n",
       "  0.08062873396258323,\n",
       "  0.08211801671542418,\n",
       "  0.05790154067560648,\n",
       "  0.07453025762851422,\n",
       "  0.05275155934027563,\n",
       "  0.047642737424048856,\n",
       "  0.06116273399824516,\n",
       "  0.07084208774643067,\n",
       "  0.06486401993494767,\n",
       "  0.057040645908086725,\n",
       "  0.046200817689681664,\n",
       "  0.09952317608090547,\n",
       "  0.06989200150546356,\n",
       "  0.06579487516473119,\n",
       "  0.05579398610653021,\n",
       "  0.0897455195394846,\n",
       "  0.11819264407341297,\n",
       "  0.052386011116397686,\n",
       "  0.04386208239847269,\n",
       "  0.0695169808772894,\n",
       "  0.0672383978485297,\n",
       "  0.05907831773257408,\n",
       "  0.04218637620886931,\n",
       "  0.055613454622335926,\n",
       "  0.025813605803518724,\n",
       "  0.04049293501063799,\n",
       "  0.023813839118259076,\n",
       "  0.05208049069803495,\n",
       "  0.06974992385277382,\n",
       "  0.05790141637986287,\n",
       "  0.041297840575377144,\n",
       "  0.09669611187508473,\n",
       "  0.081474899338224,\n",
       "  0.06113945038463825,\n",
       "  0.06237813250090067,\n",
       "  0.05012309594223133,\n",
       "  0.03992902891089519,\n",
       "  0.03721204586327076,\n",
       "  0.04140477761244162,\n",
       "  0.04982214573866282,\n",
       "  0.07538049018535858,\n",
       "  0.05822108447169646,\n",
       "  0.06272092337409656,\n",
       "  0.060097236592227064,\n",
       "  0.06725353611489901,\n",
       "  0.056342886904111274,\n",
       "  0.09841596311292587,\n",
       "  0.13421734484533468,\n",
       "  0.11059255219804935,\n",
       "  0.058453926434501625,\n",
       "  0.06120221239204208,\n",
       "  0.07749135613154906,\n",
       "  0.10478757828091964,\n",
       "  0.04047074708610009,\n",
       "  0.09378258926937214,\n",
       "  0.07296582662428801,\n",
       "  0.058849464337795206,\n",
       "  0.07099764994703807,\n",
       "  0.0775050498927251,\n",
       "  0.08309580314044769,\n",
       "  0.1354571003228044,\n",
       "  0.08805038151928248,\n",
       "  0.16349251931294417,\n",
       "  0.11194181511512934,\n",
       "  0.08583503536497936,\n",
       "  0.11015751131643088,\n",
       "  0.04510166013661104,\n",
       "  0.07609409858018924,\n",
       "  0.06498970100894952,\n",
       "  0.1282381037584482,\n",
       "  0.0972141780389043,\n",
       "  0.11252926184962957,\n",
       "  0.2032374419654027,\n",
       "  0.07886501458974984,\n",
       "  0.10501048993319273,\n",
       "  0.041962964090112694,\n",
       "  0.10582130913359997,\n",
       "  0.08028915806267506,\n",
       "  0.10913548367814375,\n",
       "  0.22923634277704436,\n",
       "  0.04121918147668625,\n",
       "  0.0618070929000775,\n",
       "  0.057658017660753846,\n",
       "  0.09368912849384241,\n",
       "  0.1269650486512826,\n",
       "  0.08918030985081807,\n",
       "  0.21093640395273,\n",
       "  0.183357192012362,\n",
       "  0.13864373883757836,\n",
       "  0.14325992486033684,\n",
       "  0.14447533769103196,\n",
       "  0.11051712677073784,\n",
       "  0.09731999703515799,\n",
       "  0.06292723219555157,\n",
       "  0.0622305774058287,\n",
       "  0.09399747318373276,\n",
       "  0.11150816288322975,\n",
       "  0.0594219411126314,\n",
       "  0.09880498987741959,\n",
       "  0.06381663360083714,\n",
       "  0.05647817344810718,\n",
       "  0.04933190386360272,\n",
       "  0.07169419230941014,\n",
       "  0.07560890062879293,\n",
       "  0.14530494021108517,\n",
       "  0.05143964376587134,\n",
       "  0.12506690544959825,\n",
       "  0.14049363403748244,\n",
       "  0.13052302130903953,\n",
       "  0.09654235371794456,\n",
       "  0.06734664628329949,\n",
       "  0.08946517320015492,\n",
       "  0.07074183072799291,\n",
       "  0.17101671847586447,\n",
       "  0.0985160570543928,\n",
       "  0.09917662498087455,\n",
       "  0.09499473695476086,\n",
       "  0.1046058473487695,\n",
       "  0.1210560058362973,\n",
       "  0.20947699793256247,\n",
       "  0.21174133483033913,\n",
       "  0.19229963183020934,\n",
       "  0.15249636019460666,\n",
       "  0.09269466518591611,\n",
       "  0.08779519414290404,\n",
       "  0.22806212903024295,\n",
       "  0.19045211670872492,\n",
       "  0.1898876189803466,\n",
       "  0.09278055251790927,\n",
       "  0.22943047161858815,\n",
       "  0.04587198793888092,\n",
       "  0.07076545916975309,\n",
       "  0.04045278813021305,\n",
       "  0.0417318857060029,\n",
       "  0.17978698430726162,\n",
       "  0.18826958369941282,\n",
       "  0.22634701306621233,\n",
       "  0.16250884661880824,\n",
       "  0.09245519750775436,\n",
       "  0.05380521442454595,\n",
       "  0.0892981699643991,\n",
       "  0.06301817890161122,\n",
       "  0.08664832875514641,\n",
       "  0.2152708190947007,\n",
       "  0.1202244758605957,\n",
       "  0.16433875692578462,\n",
       "  0.1199647452777777,\n",
       "  0.10328814692986317,\n",
       "  0.05830444247485735,\n",
       "  0.13578140788162366,\n",
       "  0.18428967234033805,\n",
       "  0.14698701695753977,\n",
       "  0.08555590891494201,\n",
       "  0.22117648961452338,\n",
       "  0.0812305587893113,\n",
       "  0.054016211428321324,\n",
       "  0.0779338361074527,\n",
       "  0.09792421729518817,\n",
       "  0.129850034816907,\n",
       "  0.12481112190737174,\n",
       "  0.12062722778855225,\n",
       "  0.0808310581323428,\n",
       "  0.057538363915414385,\n",
       "  0.11334367000903839,\n",
       "  0.0937147779772297,\n",
       "  0.07734281027641816,\n",
       "  0.07272511266936095,\n",
       "  0.19277872804265755,\n",
       "  0.22246330613509202,\n",
       "  0.08606421211973214,\n",
       "  0.12704597814724997,\n",
       "  0.2336750203409256,\n",
       "  0.14882193095026872,\n",
       "  0.20746504066464228,\n",
       "  0.1551330971221129,\n",
       "  0.2728346685568492,\n",
       "  0.11248227853614551,\n",
       "  0.12081643795737854,\n",
       "  0.164761343684334,\n",
       "  0.19897276425781923,\n",
       "  0.20681180480198982,\n",
       "  0.12446101563863265,\n",
       "  0.27850608661388737,\n",
       "  0.1460061832689322,\n",
       "  0.27669583786374485,\n",
       "  0.25560439301606935,\n",
       "  0.20260522810694498,\n",
       "  0.21106693435173768,\n",
       "  0.2149251111998008,\n",
       "  0.20753050010460308,\n",
       "  0.24358563831983468,\n",
       "  0.18335827401815316,\n",
       "  0.24779249689517877,\n",
       "  0.2456943860802895,\n",
       "  0.2507116932135362],\n",
       " 'val_acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.00641025641025641,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'loss': [0.04865558694087272,\n",
       "  0.010815827340325889,\n",
       "  0.007631163707011426,\n",
       "  0.006586509175194065,\n",
       "  0.006235843083960304,\n",
       "  0.006176610074819348,\n",
       "  0.005959122317392227,\n",
       "  0.006303942551608809,\n",
       "  0.0061936873133500775,\n",
       "  0.005975651394626404,\n",
       "  0.0056071177870877995,\n",
       "  0.005778091074688132,\n",
       "  0.005918484463512358,\n",
       "  0.005785123318669753,\n",
       "  0.005550741028394634,\n",
       "  0.005298383201038406,\n",
       "  0.005302979513935374,\n",
       "  0.005261640119201997,\n",
       "  0.005229902849848723,\n",
       "  0.005207403200547889,\n",
       "  0.005054967703373588,\n",
       "  0.005205648180046772,\n",
       "  0.004946514310913658,\n",
       "  0.005425102448267904,\n",
       "  0.005348737808829384,\n",
       "  0.005198238004521547,\n",
       "  0.004933994472009968,\n",
       "  0.005131647637644909,\n",
       "  0.004832836394767146,\n",
       "  0.005002683626985118,\n",
       "  0.00474068181530248,\n",
       "  0.004829950761302834,\n",
       "  0.004891402606443582,\n",
       "  0.004896175137371229,\n",
       "  0.004563891503757616,\n",
       "  0.005070578713576853,\n",
       "  0.0047928295266810314,\n",
       "  0.004748525815421707,\n",
       "  0.004713191492778009,\n",
       "  0.004724177609859413,\n",
       "  0.00493054762609067,\n",
       "  0.004624265467335061,\n",
       "  0.004508516578450462,\n",
       "  0.004416013545276622,\n",
       "  0.004871519861902991,\n",
       "  0.004745487479821724,\n",
       "  0.004724029953090044,\n",
       "  0.004561625129218757,\n",
       "  0.004773808320840964,\n",
       "  0.004644825325528691,\n",
       "  0.0046496469468485175,\n",
       "  0.004781218146593457,\n",
       "  0.004338196234364585,\n",
       "  0.004729462966609459,\n",
       "  0.0046659826819376166,\n",
       "  0.004498369880104901,\n",
       "  0.004521128567719486,\n",
       "  0.004750409452202498,\n",
       "  0.005002947201809058,\n",
       "  0.00473054904676131,\n",
       "  0.004489023265812327,\n",
       "  0.004625062511947293,\n",
       "  0.00442318521372603,\n",
       "  0.0046475686067588865,\n",
       "  0.004312615127332205,\n",
       "  0.004333646093575259,\n",
       "  0.0043124472300998225,\n",
       "  0.004814620174012438,\n",
       "  0.004642279163356955,\n",
       "  0.004646122400813243,\n",
       "  0.00404057834440699,\n",
       "  0.004166018582324232,\n",
       "  0.0043316068932650045,\n",
       "  0.004347648140784707,\n",
       "  0.004754158213094079,\n",
       "  0.004671937630119906,\n",
       "  0.004288028963584436,\n",
       "  0.004134407285938031,\n",
       "  0.004345187184093225,\n",
       "  0.004351860818314067,\n",
       "  0.004816947028681433,\n",
       "  0.004250237478019155,\n",
       "  0.004372760297401863,\n",
       "  0.004280004235262649,\n",
       "  0.00421720127495031,\n",
       "  0.004202892455984564,\n",
       "  0.004212680626744868,\n",
       "  0.004346944976437887,\n",
       "  0.004386331896588409,\n",
       "  0.00444829669186837,\n",
       "  0.0043271671447532075,\n",
       "  0.004327441989212419,\n",
       "  0.0042216389911982535,\n",
       "  0.004138192129258185,\n",
       "  0.004351135050431231,\n",
       "  0.004348762793786723,\n",
       "  0.004024604118399625,\n",
       "  0.004220370977602865,\n",
       "  0.004408691708436783,\n",
       "  0.0040814093023336315,\n",
       "  0.004067911649527391,\n",
       "  0.004166833472720503,\n",
       "  0.004119336664069832,\n",
       "  0.003990673516957064,\n",
       "  0.004009870995611492,\n",
       "  0.0039449380036460325,\n",
       "  0.0041779501814546895,\n",
       "  0.004179052193122347,\n",
       "  0.003955753979471205,\n",
       "  0.004068821050201404,\n",
       "  0.004064993112141528,\n",
       "  0.004183540892960057,\n",
       "  0.0041481356359849685,\n",
       "  0.0040223472414546695,\n",
       "  0.004057151823814503,\n",
       "  0.004023247358401841,\n",
       "  0.004017481437096229,\n",
       "  0.0040173342249175,\n",
       "  0.004221882140137492,\n",
       "  0.003975091749650523,\n",
       "  0.0041169947639057135,\n",
       "  0.0038234389248004864,\n",
       "  0.004061721663551228,\n",
       "  0.004343257519538721,\n",
       "  0.004273276984674763,\n",
       "  0.004021605701139407,\n",
       "  0.004057608386796659,\n",
       "  0.0040379873396854055,\n",
       "  0.0039056344231700197,\n",
       "  0.0037486222709583886,\n",
       "  0.003976117859581882,\n",
       "  0.003991349218876788,\n",
       "  0.0038839598434947734,\n",
       "  0.003754363071839262,\n",
       "  0.003916395377216026,\n",
       "  0.003849170404608568,\n",
       "  0.003798944136018262,\n",
       "  0.004085437610652719,\n",
       "  0.003942987857369613,\n",
       "  0.003936193193355365,\n",
       "  0.003897603851957963,\n",
       "  0.0038737640379005157,\n",
       "  0.003768889629598117,\n",
       "  0.0037058627420437956,\n",
       "  0.0037451924322114,\n",
       "  0.0037280120718297107,\n",
       "  0.004237469719781865,\n",
       "  0.0038241174733645504,\n",
       "  0.0038731038250130224,\n",
       "  0.0037182936996929517,\n",
       "  0.0038194730172009623,\n",
       "  0.004044465101176527,\n",
       "  0.003693037183862601,\n",
       "  0.0036157722863035774,\n",
       "  0.0037796754954694625,\n",
       "  0.003689244451692404,\n",
       "  0.0038559229757923344,\n",
       "  0.0035605039257910185,\n",
       "  0.0036485946244176697,\n",
       "  0.0035752030510910497,\n",
       "  0.003716241636806551,\n",
       "  0.0038375826573580907,\n",
       "  0.003968256106389459,\n",
       "  0.003910729119014754,\n",
       "  0.0035164548964892847,\n",
       "  0.0037180734208334086,\n",
       "  0.0035778120332882147,\n",
       "  0.003807088914348394,\n",
       "  0.0036695994799155994,\n",
       "  0.0036996076309134787,\n",
       "  0.0038492976281185092,\n",
       "  0.0036236620897941323,\n",
       "  0.0037288209781623804,\n",
       "  0.00358576811133669,\n",
       "  0.003937254350093021,\n",
       "  0.0036712110051000282,\n",
       "  0.0037773973203150397,\n",
       "  0.003811416488005969,\n",
       "  0.003725823778785529,\n",
       "  0.0036633435133170355,\n",
       "  0.003871944031311511,\n",
       "  0.0034221748956289495,\n",
       "  0.0035769791527739746,\n",
       "  0.003457790102632674,\n",
       "  0.0035635948189580604,\n",
       "  0.0033964735763442463,\n",
       "  0.003720206754256832,\n",
       "  0.0036001822034664012,\n",
       "  0.003725545746337504,\n",
       "  0.003472248793946267,\n",
       "  0.0033697700085817957,\n",
       "  0.0034864931261984473,\n",
       "  0.0036427566393940156,\n",
       "  0.0036062650757576276,\n",
       "  0.003336547688492553,\n",
       "  0.0033910534780775933,\n",
       "  0.00342143644321693,\n",
       "  0.0036924687346940803,\n",
       "  0.0034794333829161,\n",
       "  0.0035870066987207304,\n",
       "  0.003288627971949823,\n",
       "  0.003510608899352305,\n",
       "  0.003457134192371193,\n",
       "  0.0035769044731351718,\n",
       "  0.0033937160729544395,\n",
       "  0.003474509132798441,\n",
       "  0.0033267571599269077,\n",
       "  0.0033833079958730692,\n",
       "  0.0032539786792010472,\n",
       "  0.0033956483939906997,\n",
       "  0.0034448373293697967,\n",
       "  0.0032296861475544277,\n",
       "  0.0032721079898602014,\n",
       "  0.003463052345937059,\n",
       "  0.003382958332708788,\n",
       "  0.003363788932797866,\n",
       "  0.0033258975175845676,\n",
       "  0.003319546514995632,\n",
       "  0.0035807255895732486,\n",
       "  0.003422670136943325,\n",
       "  0.0034749045413897724,\n",
       "  0.003450672546764035,\n",
       "  0.0033325962048040797,\n",
       "  0.003379264646272988,\n",
       "  0.0033537169499112066,\n",
       "  0.0034965419145174563,\n",
       "  0.0031860667634839657,\n",
       "  0.003317730459152843,\n",
       "  0.003185710168076991,\n",
       "  0.0033025982772838746,\n",
       "  0.003446030818195634,\n",
       "  0.0035656817822097655,\n",
       "  0.0033426421780847182,\n",
       "  0.0033519635676528534,\n",
       "  0.003186674653742108,\n",
       "  0.0031817839881278813,\n",
       "  0.003345041552651252,\n",
       "  0.003475449566320596,\n",
       "  0.0032987258127338474,\n",
       "  0.003451782353517359,\n",
       "  0.0032935282995089957,\n",
       "  0.0034010115762270685,\n",
       "  0.003359007790297,\n",
       "  0.003301895076063424,\n",
       "  0.003275115972140391,\n",
       "  0.0032424015357534136,\n",
       "  0.003126183557387323,\n",
       "  0.003307767386223733,\n",
       "  0.00326949351559903,\n",
       "  0.003149498123422737,\n",
       "  0.0031727565245964137,\n",
       "  0.0031595941573988257,\n",
       "  0.003571316791588769,\n",
       "  0.003284197469764469,\n",
       "  0.003214118456493271,\n",
       "  0.0031758944579817323,\n",
       "  0.0032360967021115225,\n",
       "  0.0031730645447885153,\n",
       "  0.003107629733252849,\n",
       "  0.0032101986040593005,\n",
       "  0.003435690381576842,\n",
       "  0.003144922723142405,\n",
       "  0.0031260811319212298,\n",
       "  0.0031009626962514216,\n",
       "  0.0031266074714027515,\n",
       "  0.0032174439028293165,\n",
       "  0.0033245607641656204,\n",
       "  0.003388366320621374,\n",
       "  0.003366680572449959,\n",
       "  0.003417663385762888,\n",
       "  0.003238125856991065,\n",
       "  0.003087971306814732,\n",
       "  0.003411856523137624,\n",
       "  0.0031024880762047626,\n",
       "  0.0032588897496293305,\n",
       "  0.0032241847587336377,\n",
       "  0.003205306926000509,\n",
       "  0.003394726651185508,\n",
       "  0.0032706388611582473,\n",
       "  0.0031674779199350337,\n",
       "  0.003094631712883711,\n",
       "  0.0031327923514345045,\n",
       "  0.0031770047145933586,\n",
       "  0.0031570965072300235,\n",
       "  0.0032754873201605015,\n",
       "  0.003266251495327143,\n",
       "  0.003154202270620751,\n",
       "  0.0031265961511979276,\n",
       "  0.003174596281755901,\n",
       "  0.00317992977861197,\n",
       "  0.0031963700335894234,\n",
       "  0.003242521838609517,\n",
       "  0.0030846859705613346,\n",
       "  0.0032513899353598308,\n",
       "  0.0031426037531093235,\n",
       "  0.0031790848046001807,\n",
       "  0.0032141377961861467,\n",
       "  0.0032614367909737907,\n",
       "  0.003083322337318667,\n",
       "  0.0031045422524770055,\n",
       "  0.00322439642496643,\n",
       "  0.0031433340132539897,\n",
       "  0.0031450759067423472,\n",
       "  0.003056626693172827,\n",
       "  0.0031059463971981364,\n",
       "  0.0029966154944876472,\n",
       "  0.0032847666569323832,\n",
       "  0.0032393174515657837,\n",
       "  0.0030234852685630995,\n",
       "  0.003158915287507403,\n",
       "  0.002994842216271351,\n",
       "  0.0031397193722949445,\n",
       "  0.0032469879738919066,\n",
       "  0.003019599241891463,\n",
       "  0.0030651211093824645,\n",
       "  0.0031575462938922697,\n",
       "  0.00320660958500638,\n",
       "  0.0031379783037223967,\n",
       "  0.0031172224505892974,\n",
       "  0.0030877096241348468,\n",
       "  0.0030663954905272204,\n",
       "  0.0031633238367129507,\n",
       "  0.003053093384909212,\n",
       "  0.0028915798177782497,\n",
       "  0.002960646461813428,\n",
       "  0.0029490909789903806,\n",
       "  0.0030743367148234565,\n",
       "  0.003058799891205867,\n",
       "  0.0032997131400332867,\n",
       "  0.0027663257548256833,\n",
       "  0.0030534054158988717,\n",
       "  0.0030581869524208263,\n",
       "  0.002922607988237121,\n",
       "  0.0029701757944311223,\n",
       "  0.0028382088073499803,\n",
       "  0.002966363887972624,\n",
       "  0.002925786895601593,\n",
       "  0.0031460023967641916,\n",
       "  0.002981970752526193,\n",
       "  0.003024795140051262,\n",
       "  0.0035304599315164045,\n",
       "  0.0031119727559084267,\n",
       "  0.003083676078706575,\n",
       "  0.003019728434453318,\n",
       "  0.0028530436892450126,\n",
       "  0.0029036046134316407,\n",
       "  0.00281859245530553,\n",
       "  0.003069436226073838,\n",
       "  0.0029173887374798232,\n",
       "  0.003163598833934349,\n",
       "  0.0031488160413112574,\n",
       "  0.0030709534190274876,\n",
       "  0.0030363201536659605,\n",
       "  0.0029820482630063504,\n",
       "  0.003100031133471436,\n",
       "  0.0030032355165555734,\n",
       "  0.0029597267902527866,\n",
       "  0.002928895030878653,\n",
       "  0.0028435292546279156,\n",
       "  0.002883431741365177,\n",
       "  0.0029396103648679558,\n",
       "  0.0030674276235028762,\n",
       "  0.0030205088090235832,\n",
       "  0.0027594491375854653,\n",
       "  0.0028530093514659693,\n",
       "  0.0028830714422653165,\n",
       "  0.002848368694339942,\n",
       "  0.0029532138565850205,\n",
       "  0.0033103995050442706,\n",
       "  0.0031098529277158674,\n",
       "  0.0030532505982702944,\n",
       "  0.0028852050411788854,\n",
       "  0.002890648381422143,\n",
       "  0.0029596635972769145,\n",
       "  0.0029391920440556374,\n",
       "  0.002971486222184352,\n",
       "  0.003020278957769342,\n",
       "  0.00305476988353914,\n",
       "  0.0030169024667386557,\n",
       "  0.0029032086222369343,\n",
       "  0.0028452799946271996,\n",
       "  0.0029879284830873504,\n",
       "  0.002974630378785109,\n",
       "  0.003005594086761658,\n",
       "  0.0029007437474587385,\n",
       "  0.0030001505610967112,\n",
       "  0.0030280949391964062,\n",
       "  0.002805775939592274,\n",
       "  0.002839686374319085,\n",
       "  0.002859199185733477,\n",
       "  0.002738393766266121,\n",
       "  0.0027587383851720806,\n",
       "  0.0029442185753054614,\n",
       "  0.002626689111948755,\n",
       "  0.0029363569769822904,\n",
       "  0.002773689245173025,\n",
       "  0.002942209689334305,\n",
       "  0.00262024770680461,\n",
       "  0.0026726540055850784,\n",
       "  0.0027062529155445114,\n",
       "  0.0026230682056329773,\n",
       "  0.0028113788762867318,\n",
       "  0.002770331816756213,\n",
       "  0.0027069425962578794,\n",
       "  0.0026482489308746896,\n",
       "  0.002830844473650013,\n",
       "  0.00275345105673629,\n",
       "  0.002787033274529578,\n",
       "  0.0027292041230221947,\n",
       "  0.0028435134990520065,\n",
       "  0.0030115772991091416,\n",
       "  0.0028925258813771457,\n",
       "  0.0029155353707897716,\n",
       "  0.002913925057167516,\n",
       "  0.0026013553721990386,\n",
       "  0.002874879211785769,\n",
       "  0.00284220035739951,\n",
       "  0.002647684217005024,\n",
       "  0.0027622862105843573,\n",
       "  0.0025641074698055963,\n",
       "  0.002524693982203689,\n",
       "  0.0027751794223972847,\n",
       "  0.002693724568840538,\n",
       "  0.002589973739066005,\n",
       "  0.0024892279174499113,\n",
       "  0.0025167139647402107,\n",
       "  0.0026610182931149436,\n",
       "  0.002575025179452891,\n",
       "  0.0025227095971802646,\n",
       "  0.0023058143010303983,\n",
       "  0.002645633396233234,\n",
       "  0.0024996706552179826,\n",
       "  0.0024434666442200203,\n",
       "  0.0024474488836776346,\n",
       "  0.0024986572677429715,\n",
       "  0.002413535200910668,\n",
       "  0.0023639341710952884,\n",
       "  0.0024696940722626665,\n",
       "  0.0026361108894514687,\n",
       "  0.0024421236833886187,\n",
       "  0.0024459533165820044,\n",
       "  0.002237477250253925,\n",
       "  0.002454315481825449,\n",
       "  0.002512144610681887,\n",
       "  0.00258949348319541,\n",
       "  0.0023420403028808837,\n",
       "  0.0026519054413153644,\n",
       "  0.002626907769422051,\n",
       "  0.0023903828988702993,\n",
       "  0.002509419068828967,\n",
       "  0.002596831665589259,\n",
       "  0.002480001241491256,\n",
       "  0.0024316743937030233,\n",
       "  0.00238886044352269,\n",
       "  0.0027284127537885944,\n",
       "  0.0026556683569404875,\n",
       "  0.002507960679835526,\n",
       "  0.0023428089790282205,\n",
       "  0.0022893334987543826,\n",
       "  0.002375285264433307,\n",
       "  0.002278582373111429,\n",
       "  0.0025015719881812237,\n",
       "  0.0022293688203692775,\n",
       "  0.002119410010813251,\n",
       "  0.0021589343558272083,\n",
       "  0.002304482638279642,\n",
       "  0.0024452931079086406,\n",
       "  0.002488740585002694,\n",
       "  0.0024818300519231285,\n",
       "  0.002364624511846657,\n",
       "  0.002373542086689046,\n",
       "  0.00223174637996874,\n",
       "  0.002240980047167898,\n",
       "  0.0024001242706712285,\n",
       "  0.002295247685771048,\n",
       "  0.002245771899351606,\n",
       "  0.0024323466073772216,\n",
       "  0.002241139395512236,\n",
       "  0.002200476170993701,\n",
       "  0.0021436108293104495,\n",
       "  0.002084289502027988,\n",
       "  0.0020515687318046773,\n",
       "  0.002051561897013724,\n",
       "  0.00209035400756344,\n",
       "  0.001912794414616919,\n",
       "  0.001976879724992515,\n",
       "  0.0020321292615162706,\n",
       "  0.0019062894430196932,\n",
       "  0.0019666210509103415,\n",
       "  0.002167662914328243,\n",
       "  0.0021130122408709105,\n",
       "  0.0021117984794493242,\n",
       "  0.00210528569380285,\n",
       "  0.002307924238661498,\n",
       "  0.002178504666928792,\n",
       "  0.002036625702709499,\n",
       "  0.001980047529179822,\n",
       "  0.00209581568875093,\n",
       "  0.002402251362969163,\n",
       "  0.0020545501777126845,\n",
       "  0.002112919966188761,\n",
       "  0.0020045164721803023,\n",
       "  0.0020293057780308285,\n",
       "  0.0019612831149958244,\n",
       "  0.0019065465944570518,\n",
       "  0.001828537256208278,\n",
       "  0.0018587210436869935,\n",
       "  0.0020474214823200153,\n",
       "  0.0019435225448642785,\n",
       "  0.002121551720872184,\n",
       "  0.0019896390502303165,\n",
       "  0.0021126296621962236,\n",
       "  0.0018453063655063104,\n",
       "  0.001867881686873397,\n",
       "  0.0018094310308364116,\n",
       "  0.001764221227521338,\n",
       "  0.0017325993167969706,\n",
       "  0.0017867446676891178,\n",
       "  0.0017864191504321756,\n",
       "  0.0016723534664375144,\n",
       "  0.0017790914865050515,\n",
       "  0.001802121962281576,\n",
       "  0.0018630119691691383,\n",
       "  0.0018384790314546874,\n",
       "  0.0019300795545826805,\n",
       "  0.001796847168246613,\n",
       "  0.0019210934258651882,\n",
       "  0.0017976003732717684,\n",
       "  0.0018284772607030102,\n",
       "  0.0017384375704713672,\n",
       "  0.0017176796913956085,\n",
       "  0.0017111645869244884,\n",
       "  0.001644765619479322,\n",
       "  0.001640724472288565,\n",
       "  0.001782584873795071,\n",
       "  0.0016565866524994172,\n",
       "  0.0016257225299291986,\n",
       "  0.001706586494869068,\n",
       "  0.0015936149384329155,\n",
       "  0.0017794170227255757,\n",
       "  0.001772649397618428,\n",
       "  0.0016879472893144413,\n",
       "  0.0017848246998461259,\n",
       "  0.001810158200970771,\n",
       "  0.0018685696987915633,\n",
       "  0.0018299301502577186,\n",
       "  0.0015224117424330627,\n",
       "  0.00155641624758787,\n",
       "  0.0016510357155266526,\n",
       "  0.0015730607129498574,\n",
       "  0.0015674610158672969,\n",
       "  0.0016106382524383959,\n",
       "  0.001726436625736264,\n",
       "  0.0017691035707569703,\n",
       "  0.0017920059359493366,\n",
       "  0.0017293106461137668,\n",
       "  0.0016329647689779622,\n",
       "  0.0016405382109342388,\n",
       "  0.0015642056202124046,\n",
       "  0.0015045178093319564,\n",
       "  0.0016705206852423119,\n",
       "  0.0017040000335056319,\n",
       "  0.0017457280426003813,\n",
       "  0.0013929882057314544,\n",
       "  0.0015879028378796187,\n",
       "  0.0015115122330834356,\n",
       "  0.001522128332229289,\n",
       "  0.0016493502002403275,\n",
       "  0.0015953169583566317,\n",
       "  0.0015089038350699444,\n",
       "  0.0015882154298752411,\n",
       "  0.0016399258784570508,\n",
       "  0.0016075238412692806,\n",
       "  0.0016413609490927932,\n",
       "  0.0017393970613397355,\n",
       "  0.0014734442621823485,\n",
       "  0.0013975147911183098,\n",
       "  0.0014238476582562627,\n",
       "  0.0015143037797900008,\n",
       "  0.0016271896761467014,\n",
       "  0.001473460819496356,\n",
       "  0.0015329365308788432,\n",
       "  0.00146907154466468,\n",
       "  0.0014147363609436276,\n",
       "  0.0014931539055676414,\n",
       "  0.0014578145554676922,\n",
       "  0.0014656973692980422,\n",
       "  0.0014370251415356387,\n",
       "  0.0013812946569705508,\n",
       "  0.0014561193914055758,\n",
       "  0.0014704278653394852,\n",
       "  0.0013535887490730412,\n",
       "  0.0013514185356970757,\n",
       "  0.0014234807371789784,\n",
       "  0.0013763168774022642,\n",
       "  0.0014217126528770405,\n",
       "  0.001314111456919748,\n",
       "  0.0013030416667208547,\n",
       "  0.0015199213790205808,\n",
       "  0.001345886505415402,\n",
       "  0.0012534748656439227,\n",
       "  0.0013297758806850846,\n",
       "  0.0013725420642366035,\n",
       "  0.0013240865725134732,\n",
       "  0.0013308869798591874,\n",
       "  0.0012548105586825857,\n",
       "  0.0012598628782966423,\n",
       "  0.001443995488386146,\n",
       "  0.0013993576651531781,\n",
       "  0.0013011338097586958,\n",
       "  0.0012767254622501418,\n",
       "  0.001310781501992121,\n",
       "  0.0012371344123103096,\n",
       "  0.001185754559274628,\n",
       "  0.0013048390318466797,\n",
       "  0.001287928879328443,\n",
       "  0.001353673199170619,\n",
       "  0.0013047829075459375,\n",
       "  0.0012873568096960898,\n",
       "  0.001269351777924031,\n",
       "  0.0012524866828762366,\n",
       "  0.0014718245536855916,\n",
       "  0.0012355171306252615,\n",
       "  0.001148995796399722,\n",
       "  0.001186575346027935,\n",
       "  0.001285838404126735,\n",
       "  0.001322731928271979,\n",
       "  0.0011605589489380901,\n",
       "  0.0011667267775491757,\n",
       "  0.001040410478515087,\n",
       "  0.0010724193000390587,\n",
       "  0.0012598124754665697,\n",
       "  0.0011764216743519202,\n",
       "  0.0012969480626226079,\n",
       "  0.001209160898774188,\n",
       "  0.0012295160593245836,\n",
       "  0.0011881994846281152,\n",
       "  0.001097214091105631,\n",
       "  0.0011452494762791531,\n",
       "  0.0012902300657358914,\n",
       "  0.0012484477712810713,\n",
       "  0.0011644862055972354,\n",
       "  0.0011276286300819587,\n",
       "  0.0010525910636806244,\n",
       "  0.0011355981238110504,\n",
       "  0.0011600528762578898,\n",
       "  0.0009898074161960866,\n",
       "  0.001126911957870444,\n",
       "  0.001162941624490519,\n",
       "  0.0011807919355589745,\n",
       "  0.0011761647694411253,\n",
       "  0.0011712183071747085,\n",
       "  0.0012036666992579785,\n",
       "  0.001092476579592441,\n",
       "  0.0012188238013805441,\n",
       "  0.0011666797220546803,\n",
       "  0.0011606856483157,\n",
       "  0.0011664073929038927,\n",
       "  0.001155096058295492,\n",
       "  0.0011872400021880056,\n",
       "  0.0012285763021701803,\n",
       "  0.0011881856280442208,\n",
       "  0.0011550739241081261,\n",
       "  0.0011155398473527063,\n",
       "  0.0011051205293448195,\n",
       "  0.0011660829028409666,\n",
       "  0.0012275137410739361,\n",
       "  0.001122831221042007,\n",
       "  0.0010188283415603961,\n",
       "  0.001077404168562972,\n",
       "  0.0011875635683030834,\n",
       "  0.0010902236328498203,\n",
       "  0.0010083801069874232,\n",
       "  0.0009614378303432694,\n",
       "  0.0010181669942819728,\n",
       "  0.0010582774538310808,\n",
       "  0.0010240531955293603,\n",
       "  0.0010234717937076792,\n",
       "  0.0009384196400705607,\n",
       "  0.0009278574630795089,\n",
       "  0.0010055194501406872,\n",
       "  0.001128449837721429,\n",
       "  0.0009840650790017013,\n",
       "  0.000990468055764171,\n",
       "  0.0009244506677182821,\n",
       "  0.0011171862510416437,\n",
       "  0.0010475974674315541,\n",
       "  0.001101677602039001,\n",
       "  0.0009032834581482937,\n",
       "  0.0009417835579831068,\n",
       "  0.0009452141826652091,\n",
       "  0.0008981396640098877,\n",
       "  0.0010833771576961647,\n",
       "  0.00107476267936256,\n",
       "  0.0009996401893008686,\n",
       "  0.000977596813260801,\n",
       "  0.0009569832038479895,\n",
       "  0.0009796358228817044,\n",
       "  0.0008836565710439839,\n",
       "  0.0010236216291818953,\n",
       "  0.000954477384589545,\n",
       "  0.000896953511193007,\n",
       "  0.0008311538261201283,\n",
       "  0.0008788759445105742,\n",
       "  0.0009848969078272987,\n",
       "  0.0008901470876509552,\n",
       "  0.0009874039123096078,\n",
       "  0.000995086841032381,\n",
       "  0.0009618486734465337,\n",
       "  0.0010287610332511063,\n",
       "  0.000883325154006026,\n",
       "  0.0009188775986652164,\n",
       "  0.0009231233386727412,\n",
       "  0.0008406795366936915,\n",
       "  0.0008269140580605834,\n",
       "  0.0008603885640259579,\n",
       "  0.0007802084153117738,\n",
       "  0.0008003468094793954,\n",
       "  0.0008519232951049857,\n",
       "  0.0009050344241302612,\n",
       "  0.0008141744070121707,\n",
       "  0.0008705944924855529,\n",
       "  0.0008332229888896832,\n",
       "  0.0008849836770040552,\n",
       "  0.0008748086428531019,\n",
       "  0.0007969949250130565,\n",
       "  0.0007709635048156511,\n",
       "  0.000757546321071718,\n",
       "  0.000927552018247174,\n",
       "  0.0008910508479762873,\n",
       "  0.0008474184875481875,\n",
       "  0.0008558852348383938,\n",
       "  0.0008514853988719337,\n",
       "  0.0009540090894714267,\n",
       "  0.0009636233375846025,\n",
       "  0.0008552533890988796,\n",
       "  0.0008123220530300658,\n",
       "  0.0008613795041511197,\n",
       "  0.0008470141012811553,\n",
       "  0.0008867677038838893,\n",
       "  0.0007310014395085395,\n",
       "  0.0007988078365886238,\n",
       "  0.0007994323268288333,\n",
       "  0.0008488743823038507,\n",
       "  0.0009189670838571545,\n",
       "  0.0010776957233617614,\n",
       "  0.001092762703168716,\n",
       "  0.000882910425738933,\n",
       "  0.0008862513163320855,\n",
       "  0.0008424859895893453],\n",
       " 'acc': [0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065,\n",
       "  0.0011312217194570137,\n",
       "  0.0011312217615983065]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss history by epoch\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the loss history by reading it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read into dataframe\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048656</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.212402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_acc      loss       acc\n",
       "0  0.217740      0.0  0.048656  0.001131\n",
       "1  0.204079      0.0  0.010816  0.001131\n",
       "2  0.221330      0.0  0.007631  0.001131\n",
       "3  0.212402      0.0  0.006587  0.001131\n",
       "4  0.222389      0.0  0.006236  0.001131"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at columns\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4acfd630>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.plot(y = ['val_loss', 'loss'], title = 'Loss History by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss in general seems to decrease a great deal, but the validation loss is very noisy after about 100 epochs.  We will use 100 epochs going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Amount\n",
    "\n",
    "Now, we consider dropout amount (percentage of weights dropped in each iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 5ms/step - loss: 0.0606 - acc: 0.0011 - val_loss: 0.1111 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 886us/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.0924 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0097 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0085 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 910us/step - loss: 0.0079 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.0901 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 897us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 897us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 914us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0819 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 855us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 923us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 901us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0878 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0909 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0828 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 956us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0823 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 759us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0778 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 712us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0743 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 815us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0805 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0816 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0815 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0824 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 882us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0792 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 907us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0810 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0758 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0742 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 761us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0760 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0771 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 783us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 877us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 720us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0739 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0869 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 813us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0913 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 835us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0839 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 912us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 845us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 860us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 675us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 863us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0832 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0717 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 661us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0748 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 714us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 719us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0952 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 870us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1170 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1126 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1158 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 842us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 932us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 804us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1152 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1204 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1142 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 788us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1352 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 816us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 899us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 880us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 861us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 887us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1318 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.022935218843989646, RMSE: 0.15144378113342802\n",
      "Test Set- Score: 0.1439503347096236, RMSE: 0.379407873810789\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 6ms/step - loss: 0.0550 - acc: 0.0000e+00 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0123 - acc: 0.0011 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.1125 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0078 - acc: 0.0011 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1051 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1183 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0074 - acc: 0.0011 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 719us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1089 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 769us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1005 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0873 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0889 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.0891 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 801us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0888 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 868us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0883 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 772us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 777us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 790us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0714 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0525 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 847us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0597 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0634 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0590 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 791us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 800us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0656 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0563 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0688 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0680 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 718us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0670 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 724us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 878us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0578 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0547 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 838us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 798us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 889us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0768 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 837us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0594 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 750us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0546 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0609 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0662 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0675 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0765 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0780 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0727 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0585 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0555 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0775 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 835us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0735 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0610 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 865us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0682 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.013468831473101791, RMSE: 0.1160552948947259\n",
      "Test Set- Score: 0.07443509574817575, RMSE: 0.2728279599824324\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 5s 6ms/step - loss: 0.1064 - acc: 0.0000e+00 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0166 - acc: 0.0011 - val_loss: 0.0819 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0119 - acc: 0.0011 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0095 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0082 - acc: 0.0011 - val_loss: 0.0813 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0076 - acc: 0.0011 - val_loss: 0.0836 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 808us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0075 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 726us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0942 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.0986 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 813us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 807us/step - loss: 0.0073 - acc: 0.0011 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 852us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.0973 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0949 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 781us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0958 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0886 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 866us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0916 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 867us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0909 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 759us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 727us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.0905 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0906 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0859 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0845 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0835 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0866 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0898 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 723us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 793us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.0895 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.0907 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0920 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.0870 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 789us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0884 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 803us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 829us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 922us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0876 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0896 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 810us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0831 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 814us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0802 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0784 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 859us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 823us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0785 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0777 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 898us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0822 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 822us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0860 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 756us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 700us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 773us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0838 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 780us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0915 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0851 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 844us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0850 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0962 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 691us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1302 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1335 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1626 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 809us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1550 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 851us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.025177637824358848, RMSE: 0.15867462879855382\n",
      "Test Set- Score: 0.15909677938274716, RMSE: 0.3988693763411114\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 7s 7ms/step - loss: 0.0606 - acc: 0.0000e+00 - val_loss: 0.1839 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0121 - acc: 0.0011 - val_loss: 0.1909 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0087 - acc: 0.0011 - val_loss: 0.1858 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0077 - acc: 0.0011 - val_loss: 0.1766 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 938us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 834us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1669 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 909us/step - loss: 0.0069 - acc: 0.0011 - val_loss: 0.1621 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.0011 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 714us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1636 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 811us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1605 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1681 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1576 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1560 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1637 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 794us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1646 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 785us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1693 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1704 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1625 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 925us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1599 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 819us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1495 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 769us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 796us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1424 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 841us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 831us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1481 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1464 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 884us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1287 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1278 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1403 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 774us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1449 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 861us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1422 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 895us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1444 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1407 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 825us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1304 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1320 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1316 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 799us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 718us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 737us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1334 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 869us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1265 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 981us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.1240 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1309 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1353 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1331 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1345 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 776us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 853us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1310 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1381 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 676us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1216 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1285 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 763us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1287 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1212 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 830us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1004 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1054 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1065 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 735us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0970 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 741us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 805us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 753us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.1199 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 724us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1157 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 715us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0965 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 826us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.019156914093316747, RMSE: 0.1384085044110973\n",
      "Test Set- Score: 0.11600389623123666, RMSE: 0.340593447134904\n",
      "Train on 884 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 7s 8ms/step - loss: 0.0794 - acc: 0.0000e+00 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0135 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 675us/step - loss: 0.0099 - acc: 0.0011 - val_loss: 0.1151 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0088 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 1s 775us/step - loss: 0.0081 - acc: 0.0011 - val_loss: 0.1277 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 1s 758us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1266 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 1s 898us/step - loss: 0.0072 - acc: 0.0011 - val_loss: 0.1260 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 1s 716us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1286 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1326 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 1s 748us/step - loss: 0.0065 - acc: 0.0011 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 1s 751us/step - loss: 0.0070 - acc: 0.0011 - val_loss: 0.1367 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 1s 836us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1473 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 1s 821us/step - loss: 0.0066 - acc: 0.0011 - val_loss: 0.1459 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 1s 787us/step - loss: 0.0071 - acc: 0.0011 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0062 - acc: 0.0011 - val_loss: 0.1160 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1184 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 1s 731us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1165 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 1s 728us/step - loss: 0.0064 - acc: 0.0011 - val_loss: 0.1231 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 1s 722us/step - loss: 0.0060 - acc: 0.0011 - val_loss: 0.1336 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0063 - acc: 0.0011 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0068 - acc: 0.0011 - val_loss: 0.1253 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 1s 839us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1246 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 1s 768us/step - loss: 0.0061 - acc: 0.0011 - val_loss: 0.1372 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1337 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1274 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1188 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.1215 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 1s 713us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1225 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 1s 786us/step - loss: 0.0056 - acc: 0.0011 - val_loss: 0.1273 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 1s 755us/step - loss: 0.0058 - acc: 0.0011 - val_loss: 0.1189 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 1s 849us/step - loss: 0.0059 - acc: 0.0011 - val_loss: 0.1098 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 1s 856us/step - loss: 0.0057 - acc: 0.0011 - val_loss: 0.1195 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0054 - acc: 0.0011 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 1s 727us/step - loss: 0.0055 - acc: 0.0011 - val_loss: 0.1268 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1321 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 1s 764us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1230 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1124 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 1s 749us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1132 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 1s 765us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 1s 745us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1011 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 1s 730us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0873 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 1s 725us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 1s 721us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.0984 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0953 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 1s 729us/step - loss: 0.0053 - acc: 0.0011 - val_loss: 0.1037 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.1077 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 1s 732us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0943 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 1s 760us/step - loss: 0.0052 - acc: 0.0011 - val_loss: 0.0821 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0913 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 1s 747us/step - loss: 0.0050 - acc: 0.0011 - val_loss: 0.0865 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0817 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 1s 771us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0977 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 1s 768us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0806 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 1s 767us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0741 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0814 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0049 - acc: 0.0011 - val_loss: 0.0786 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 1s 698us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0712 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0799 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 1s 716us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0857 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 1s 738us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 1s 733us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0908 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0051 - acc: 0.0011 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0738 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0863 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 1s 696us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 1s 744us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1044 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 1s 754us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1032 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0950 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 1s 739us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0897 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0929 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 1s 742us/step - loss: 0.0047 - acc: 0.0011 - val_loss: 0.0959 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 1s 736us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.1035 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 1s 743us/step - loss: 0.0048 - acc: 0.0011 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 1s 711us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0661 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 1s 706us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 1s 734us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0723 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 1s 740us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0728 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 1s 746us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 1s 752us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.0818 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 1s 770us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0834 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 1s 766us/step - loss: 0.0044 - acc: 0.0011 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 1s 784us/step - loss: 0.0046 - acc: 0.0011 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 1s 778us/step - loss: 0.0043 - acc: 0.0011 - val_loss: 0.1047 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 1s 762us/step - loss: 0.0045 - acc: 0.0011 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 1s 757us/step - loss: 0.0042 - acc: 0.0011 - val_loss: 0.0882 - val_acc: 0.0000e+00\n",
      "Training Set- Score: 0.016391489937758217, RMSE: 0.12802925422636116\n",
      "Test Set- Score: 0.09563112388486447, RMSE: 0.30924282349775634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5b7b9470>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at dropout\n",
    "#use training score as metric (should really only score on test set when done.)\n",
    "#set up parameters\n",
    "seq_length = 30\n",
    "fut_point = 5\n",
    "train_split = 0.85\n",
    "neurons = [128, 128, 16]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "validation_split = 0.15\n",
    "model_path = 'dummy_path.h5'\n",
    "\n",
    "#set up variances of neuron size\n",
    "dropout_list = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "#create lists to store results\n",
    "dropouts = []\n",
    "train_scores = []\n",
    "\n",
    "#iterate\n",
    "for dropout in dropout_list:\n",
    "    dropouts.append(dropout)\n",
    "    \n",
    "    train, test, train_preds, test_preds, train_score, test_score = fit_generic_LSTM_model(df, seq_length, \n",
    "                                                                                                     fut_point, \n",
    "                                                                                                     train_split, \n",
    "                                                                                                     neuron_length, \n",
    "                                                                                                     dropout, \n",
    "                                                                                                     epochs, \n",
    "                                                                                                     batch_size,\n",
    "                                                                                                     validation_split, \n",
    "                                                                                                     model_path)\n",
    "    \n",
    "    train_scores.append(train_score[0])\n",
    "    \n",
    "#create dataframe\n",
    "results = pd.DataFrame({'Dropouts': dropouts, 'Train Scores': train_scores})\n",
    "\n",
    "results.plot(x = 'Dropouts', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a578ba6d8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results\n",
    "results.plot(x = 'Dropouts', y = 'Train Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dropout value of 0.30 is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
